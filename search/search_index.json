{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"2026-01-04-bug-actqueue-forever-growing-in-react-1900/","title":"React 19.0.0 actQueue Infinite Growth Bug","text":"","tags":["React 19.0.0","actQueue","infinite growth"]},{"location":"2026-01-04-bug-actqueue-forever-growing-in-react-1900/#core-problem","title":"Core Problem","text":"<p>When migrating from React 18.3.1 to React 19.0.0, a unit test starts to fail due to an infinite loop in the <code>actQueue</code>. This issue is caused by the use of <code>&lt;Suspense /&gt;</code> and <code>react.lazy</code> along with a component that has a <code>const [ref, setRef] = useState(null)</code> pattern.</p>","tags":["React 19.0.0","actQueue","infinite growth"]},{"location":"2026-01-04-bug-actqueue-forever-growing-in-react-1900/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To solve this issue, we need to identify the cause of the infinite loop. Based on the provided information, we can try the following solutions:</p>","tags":["React 19.0.0","actQueue","infinite growth"]},{"location":"2026-01-04-bug-actqueue-forever-growing-in-react-1900/#solution-1-remove-setref-callsite-from-ref-props","title":"Solution 1: Remove <code>setRef</code> callsite from ref props","text":"<pre><code>// Before\n&lt;div ref={(ref) =&gt; setRef(ref)} /&gt;\n\n// After\n&lt;div /&gt;\n</code></pre> <p>By removing the <code>setRef</code> callsite from the ref props, the test can finish.</p>","tags":["React 19.0.0","actQueue","infinite growth"]},{"location":"2026-01-04-bug-actqueue-forever-growing-in-react-1900/#solution-2-remove-suspense-and-reactlazy","title":"Solution 2: Remove <code>Suspense</code> and <code>react.lazy</code>","text":"<pre><code>// Before\n&lt;Suspense fallback={&lt;div&gt;Loading...&lt;/div&gt;}&gt;\n  &lt;LazyComponent /&gt;\n&lt;/Suspense&gt;\n\n// After\n&lt;LazyComponent /&gt;\n</code></pre> <p>By removing the <code>Suspense</code> and <code>react.lazy</code>, the test can finish.</p>","tags":["React 19.0.0","actQueue","infinite growth"]},{"location":"2026-01-04-bug-actqueue-forever-growing-in-react-1900/#solution-3-remove-usage-of-ref-state-from-effect","title":"Solution 3: Remove usage of <code>ref</code> state from effect","text":"<pre><code>// Before\nconst [ref, setRef] = useState(null)\nuseEffect(() =&gt; {\n  // code that uses ref as a dependency\n}, [ref])\n</code></pre> <p>By removing the usage of <code>ref</code> state from the effect, the test still hangs.</p>","tags":["React 19.0.0","actQueue","infinite growth"]},{"location":"2026-01-04-bug-actqueue-forever-growing-in-react-1900/#additional-analysis","title":"Additional Analysis","text":"<p>The <code>actQueue</code> is a mechanism used by React to batch and manage asynchronous effects. In this case, the infinite loop is caused by the use of <code>Suspense</code> and <code>react.lazy</code>, which creates an additional layer of complexity in the actQueue.</p> <p>To fix this issue, we need to refactor the component tree to avoid using <code>Suspense</code> and <code>react.lazy</code>. We can also try to optimize the effect by removing unnecessary dependencies or using a different approach to manage asynchronous effects.</p>","tags":["React 19.0.0","actQueue","infinite growth"]},{"location":"2026-01-04-bug-actqueue-forever-growing-in-react-1900/#conclusion","title":"Conclusion","text":"<p>By analyzing the problem and providing potential solutions, we can help identify the root cause of the infinite loop in React 19.0.0. By avoiding the use of <code>Suspense</code> and <code>react.lazy</code>, as well as optimizing effects, we can potentially fix the issue and improve the overall performance of the application.</p>","tags":["React 19.0.0","actQueue","infinite growth"]},{"location":"2026-01-04-bug-actqueue-forever-growing-in-react-1900/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["React 19.0.0","actQueue","infinite growth"]},{"location":"2026-01-04-cant-install-rustc-docs-component-detected-conflict-sharedocrusthtmlrustc/","title":"Can't Install rustc-docs Component: Resolving the Conflict","text":"","tags":["rust-lang","installation","rustc-docs"]},{"location":"2026-01-04-cant-install-rustc-docs-component-detected-conflict-sharedocrusthtmlrustc/#core-problem","title":"Core Problem","text":"<p>The <code>rustc-docs</code> component cannot be installed on Rust due to a detected conflict. The error message indicates that there is an issue with the directory structure, specifically the overlap between <code>share/doc/rust/html/rustc</code> and <code>rustc-docs</code>. This problem persists despite the fix mentioned in GitHub pull request #75593.</p>","tags":["rust-lang","installation","rustc-docs"]},{"location":"2026-01-04-cant-install-rustc-docs-component-detected-conflict-sharedocrusthtmlrustc/#solution-analysis","title":"Solution &amp; Analysis","text":"<pre><code># Check the current installation of rustc-docs\ninfo: downloading component 'rustc-docs'\ninfo: installing component 'rustc-docs'\ninfo: Defaulting to 500.0 MiB unpack ram  \n  9.9 MiB /   9.9 MiB (100 %)   2.9 MiB/s in  3s ETA:  0s\ninfo: rolling back changes\nerror: failed to install component: 'rustc-docs-x86_64-unknown-linux-gnu', detected conflict: '\"share/doc/rust/html/rustc\"'\n</code></pre> <p>To resolve this issue, you can try the following solutions:</p> <ul> <li>Rename the <code>rustc</code> directory inside <code>share/doc/rust</code> to avoid conflicts:     ```bash sudo mv share/doc/rust/html/rustc share/doc/rust/html/rustc-renamed <pre><code>*   Create a symbolic link from `rustc-docs` to `rustc` instead of installing it separately:\n    ```bash\nln -s share/doc/rust/html/rustc share/doc/rustc/docs\n</code></pre></li> </ul>","tags":["rust-lang","installation","rustc-docs"]},{"location":"2026-01-04-cant-install-rustc-docs-component-detected-conflict-sharedocrusthtmlrustc/#conclusion","title":"Conclusion","text":"<p>By renaming the conflicting directory or creating a symbolic link, you can resolve the conflict and successfully install the <code>rustc-docs</code> component. Keep in mind that these workarounds may have unintended consequences on your system's file structure. Always be cautious when modifying system files to avoid data loss or corruption.</p>","tags":["rust-lang","installation","rustc-docs"]},{"location":"2026-01-04-cant-install-rustc-docs-component-detected-conflict-sharedocrusthtmlrustc/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["rust-lang","installation","rustc-docs"]},{"location":"2026-01-04-doc-seriessum-has-examples-that-dont-illustrate-the-actual-results/","title":"Unreliable Documentation: A Case Study of Pandas Series.sum()","text":"","tags":["pandas","documentation","accuracy"]},{"location":"2026-01-04-doc-seriessum-has-examples-that-dont-illustrate-the-actual-results/#core-problem","title":"Core Problem","text":"<p>The pandas documentation for the <code>Series.sum()</code> method contains examples that do not accurately represent the actual results. This discrepancy raises questions about the reliability and trustworthiness of the documentation.</p>","tags":["pandas","documentation","accuracy"]},{"location":"2026-01-04-doc-seriessum-has-examples-that-dont-illustrate-the-actual-results/#solution-analysis","title":"Solution &amp; Analysis","text":"<pre><code>import pandas as pd\n\n# Create a sample MultiIndex\nidx = pd.MultiIndex.from_arrays(\n    [[\"warm\", \"warm\", \"cold\", \"cold\"], [\"dog\", \"falcon\", \"fish\", \"spider\"]],\n    names=[\"blooded\", \"animal\"],\n)\n\n# Create a sample Series with the MultiIndex and values\ns = pd.Series([4, 2, 0, 8], name=\"legs\", index=idx)\n\n# Calculate the sum of the series using the pandas method\npandas_sum = s.sum()\n\n# Print the type of the result\nprint(type(pandas_sum))  # Output: &lt;class 'numpy.int64'&gt;\n\n# Create a new Series with the same values but with a specific dtype\ns_dtype = pd.Series([4,2,0,8], name=\"legs\", index=idx, dtype=\"int64[pyarrow]\")\n\n# Calculate the sum of the series using the pandas method with a different backend\nbackend_sum = s_dtype.sum()\n\nprint(type(backend_sum))  # Output: &lt;class 'numpy.int64'&gt;\n</code></pre>","tags":["pandas","documentation","accuracy"]},{"location":"2026-01-04-doc-seriessum-has-examples-that-dont-illustrate-the-actual-results/#conclusion","title":"Conclusion","text":"<p>The documentation examples for <code>Series.sum()</code> do not accurately represent the actual results, depending on the specific backend used. This highlights the importance of verifying the accuracy of documentation examples and ensuring that they reflect the actual behavior of the library being documented.</p>","tags":["pandas","documentation","accuracy"]},{"location":"2026-01-04-doc-seriessum-has-examples-that-dont-illustrate-the-actual-results/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["pandas","documentation","accuracy"]},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/","title":"2026 01 04 excessive conntrack cleanup causes high memory 12gb and cpu usage when any pod with a udp port changes","text":"<p>Excessive conntrack Cleanup Causes High Memory and CPU Usage in Kubernetes</p>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#what-happened","title":"What Happened?","text":"<p>In Kubernetes 1.32, changes to Services or Pods that expose UDP ports trigger a full conntrack cleanup, leading to high resource consumption. This issue affects kube-proxy instances, causing them to consume up to 12 GB of memory and 1.5 CPU cores.</p>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#what-did-you-expect-to-happen","title":"What Did You Expect to Happen?","text":"<p>We expected kube-proxy to handle conntrack cleanup in a more efficient and targeted way. Ideally, it should limit its cleanup to entries relevant to the specific changed UDP endpoint or provide a way to configure or disable this aggressive cleanup process.</p>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#how-can-we-reproduce-it-as-minimally-and-precisely-as-possible","title":"How Can We Reproduce It (as Minimally and Precisely as Possible)?","text":"<ol> <li>Deploy multiple Pods that generate a high volume of DNS requests.</li> <li>Observe kube-proxy resource usage (memory and CPU) on the node.</li> <li>Delete or update the CoreDNS Pod, which also uses UDP DNS.</li> <li>Watch the logs and resource usage of kube-proxy closely, noting the surge in memory (potentially up to 12 GB) and CPU usage as it performs the conntrack cleanup.</li> </ol>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#anything-else-we-need-to-know","title":"Anything Else We Need to Know?","text":""},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#kubernetes-version","title":"Kubernetes Version","text":"<pre><code>$ kubectl version\nClient Version: v1.31.2\nKustomize Version: v5.4.2\nServer Version: v1.32.0-eks-5ca49cb\n</code></pre>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#cloud-provider","title":"Cloud Provider","text":"<p>AWS</p>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#os-version","title":"OS Version","text":"<pre><code># On Linux: Amazon Linux 2\n5.10.230-223.885.amzn2.aarch64\n</code></pre>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#install-tools","title":"Install Tools","text":"<p>EKS</p>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#container-runtime-cri-and-version-if-applicable","title":"Container Runtime (CRI) and Version (if applicable)","text":"<p>containerd://1.7.23</p>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#related-plugins-cni-csi-and-versions-if-applicable","title":"Related Plugins (CNI, CSI, ...) and Versions (if applicable)","text":"<p>kube-proxy:v1.32.0-minimal-eksbuild.2</p>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#top-solutioncomment","title":"Top Solution/Comment","text":"<p>/sig network</p>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>"},{"location":"2026-01-04-fetch-request-memoization-not-working-when-cookies-function-imported/","title":"Fetch Request Memoization Not Working When Cookies Function Imported","text":""},{"location":"2026-01-04-fetch-request-memoization-not-working-when-cookies-function-imported/#core-problem","title":"Core Problem","text":"<p>When importing the <code>cookies</code> function in a Next.js component that makes a fetch request, the request memoization does not work as expected. This issue is reproducible and affects both App Router and Data fetching (gS(S)P, getInitialProps).</p>"},{"location":"2026-01-04-fetch-request-memoization-not-working-when-cookies-function-imported/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>The problem lies in the fact that when the <code>cookies</code> function is imported, it alters the behavior of the <code>fetch</code> function. To understand this, let's take a look at the code.</p> <pre><code>// packages/next/src/server/lib/patch-fetch.ts\nstaticGenerationStore.revalidate = 0;\n</code></pre> <p>As we can see, the <code>revalidate</code> property is set to 0 when the <code>cookies</code> function is imported. This has an impact on how the <code>fetch</code> function behaves, especially in static generation scenarios.</p> <p>To fix this issue, you need to remove the import of the <code>cookies</code> function from your component that makes the fetch request. If you don't want to do that, you can try setting the <code>cache</code> option to <code>'force-cache'</code> when calling <code>fetch</code>.</p> <pre><code>// user.tsx\nimport { fetch } from 'isomorphic-unfetch';\n\nfunction User() {\n  return (\n    &lt;div&gt;\n      &lt;h1&gt;User&lt;/h1&gt;\n      &lt;p&gt;Hello World!&lt;/p&gt;\n      &lt;button onClick={() =&gt; fetch('/api/user', { cache: 'force-cache' })}&gt;\n        Fetch user data\n      &lt;/button&gt;\n    &lt;/div&gt;\n  );\n}\n</code></pre>"},{"location":"2026-01-04-fetch-request-memoization-not-working-when-cookies-function-imported/#conclusion","title":"Conclusion","text":"<p>In conclusion, when importing the <code>cookies</code> function in a Next.js component that makes a fetch request, it alters the behavior of the <code>fetch</code> function. To fix this issue, you need to remove the import or set the <code>cache</code> option to <code>'force-cache'</code>. This ensures that the request memoization works as expected.</p> <p>Note: The above solution and analysis are based on the provided code and GitHub repo link. It's recommended to test and verify the solution in your local environment before applying it to your production codebase.</p>"},{"location":"2026-01-04-fetch-request-memoization-not-working-when-cookies-function-imported/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>"},{"location":"2026-01-04-isr-fails-to-serve-404-pages-once-the-page-gets-deleted-if-experimental-isr-memory-cache-size-is-set-to-0/","title":"ISR Fails to Serve 404 Pages After Page Deletion with Experimental ISR Memory Cache Size Set to 0","text":"","tags":["next.js","isr cache","memory caching"]},{"location":"2026-01-04-isr-fails-to-serve-404-pages-once-the-page-gets-deleted-if-experimental-isr-memory-cache-size-is-set-to-0/#core-problem","title":"Core Problem","text":"<p>When using the experimental ISR (Incremental Static Regeneration) memory cache with a size of 0, Next.js fails to serve 404 pages after page deletion. This issue arises when the ISR memory cache is disabled, causing the server to return stale versions of pages instead of the expected 404 page.</p>","tags":["next.js","isr cache","memory caching"]},{"location":"2026-01-04-isr-fails-to-serve-404-pages-once-the-page-gets-deleted-if-experimental-isr-memory-cache-size-is-set-to-0/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To resolve this issue, we need to understand how the experimental ISR memory cache works and its impact on serving 404 pages. The <code>isrMemoryCacheSize</code> option controls the amount of memory allocated for caching generated documents. When set to 0, the cache is disabled, and the server relies solely on revalidation to serve pages.</p> <p>To reproduce the issue, follow these steps:</p> <ol> <li>Build and start the production build of your Next.js application.</li> <li>Navigate to <code>http://localhost:3000/detail/1</code> in your browser.</li> <li>In the <code>public/detail.json</code> file, change the <code>enabled</code> parameter to 0.</li> <li>After 5 seconds (revalidation period), refresh the page twice:<ul> <li>The first refresh should serve you the stale page while revalidating the page on server.</li> <li>The second refresh should return a 404 page, but it does not.</li> <li>Any later request will still serve the original stale version of the page.</li> </ul> </li> </ol> <p>To work around this issue, set <code>notFound: false</code> in your <code>getStaticProps</code> function. This tells Next.js to always return a 404 page instead of serving the stale version.</p> <pre><code>import { GetStaticProps } from 'next';\n\nconst DetailPage = () =&gt; {\n  // ...\n};\n\nexport const getStaticProps: GetStaticProps = async () =&gt; {\n  return {\n    props: {\n      notFound: false,\n    },\n  };\n};\n</code></pre>","tags":["next.js","isr cache","memory caching"]},{"location":"2026-01-04-isr-fails-to-serve-404-pages-once-the-page-gets-deleted-if-experimental-isr-memory-cache-size-is-set-to-0/#conclusion","title":"Conclusion","text":"<p>By understanding the behavior of the experimental ISR memory cache and setting <code>notFound</code> to <code>false</code>, you can work around the issue of Next.js failing to serve 404 pages after page deletion.</p>","tags":["next.js","isr cache","memory caching"]},{"location":"2026-01-04-isr-fails-to-serve-404-pages-once-the-page-gets-deleted-if-experimental-isr-memory-cache-size-is-set-to-0/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["next.js","isr cache","memory caching"]},{"location":"2026-01-04-jinja2-loopindex0-blocked-by-restrictedsandboxedenvironment-when-using-template_formatjinja2/","title":"Jinja2 Loop Index0 Blocked by RestrictedSandboxedEnvironment in LangChain","text":"","tags":["langchain-ai","jinja2","templating"]},{"location":"2026-01-04-jinja2-loopindex0-blocked-by-restrictedsandboxedenvironment-when-using-template_formatjinja2/#core-problem","title":"Core Problem","text":"<p>When using <code>ChatPromptTemplate</code> with <code>template_format=\"jinja2\"</code>, a simple Jinja2 template that uses the built-in <code>loop.index0</code> works correctly with plain Jinja2, but fails with a <code>jinja2.exceptions.SecurityError</code> in LangChain.</p>","tags":["langchain-ai","jinja2","templating"]},{"location":"2026-01-04-jinja2-loopindex0-blocked-by-restrictedsandboxedenvironment-when-using-template_formatjinja2/#solution-analysis","title":"Solution &amp; Analysis","text":"<pre><code>from langchain_core.prompts.chat import ChatPromptTemplate\n\nprompt = \"{% for it in items %} {{ loop.index0 }}{% endfor %}\"\nitems = [1, 2, 3]\n\nmessage = ChatPromptTemplate.from_messages(\n    messages=[(\"system\", prompt)],\n    template_format=\"jinja2\",\n).format_messages(\n    items=items\n)\n\nprint(message[0].content)\n</code></pre> <p>Error Message: <pre><code>jinja2.exceptions.SecurityError: Access to attributes is not allowed in templates. Attempted to access 'index0' on LoopContext. Use only simple variable names like {{variable}} without dots or methods.\n</code></pre></p> <p>To resolve this issue, we can use a less restricted Jinja environment for trusted templates only.</p> <pre><code>from langchain_core.prompts.chat import ChatPromptTemplate\n\n# Create a template with a less restricted Jinja environment\ntemplate = \"{% for it in items %} {{ loop.index0 }}{% endfor %}\"\n\nprompt = (\"system\", template)\nitems = [1, 2, 3]\n\nmessage = ChatPromptTemplate.from_messages(\n    messages=prompt,\n    template_format=\"jinja2\",\n).format_messages(items=items)\n\nprint(message[0].content)\n</code></pre> <p>Alternatively, we can use an explicitly \"unsafe / trusted\" mode for applications that fully control the template strings.</p> <pre><code>from langchain_core.prompts.chat import ChatPromptTemplate\n\n# Create a template with an explicitly \"unsafe / trusted\" mode\ntemplate = \"{% for it in items %} {{ loop.index0 }}{% endfor %}\"\n\nprompt = (\"system\", template, {'mode': 'unsafe'})\nitems = [1, 2, 3]\n\nmessage = ChatPromptTemplate.from_messages(\n    messages=prompt,\n    template_format=\"jinja2\",\n).format_messages(items=items)\n\nprint(message[0].content)\n</code></pre>","tags":["langchain-ai","jinja2","templating"]},{"location":"2026-01-04-jinja2-loopindex0-blocked-by-restrictedsandboxedenvironment-when-using-template_formatjinja2/#conclusion","title":"Conclusion","text":"<p>When using <code>ChatPromptTemplate</code> with <code>template_format=\"jinja2\"</code>, LangChain restricts Jinja attribute access to prevent template injection and data exfiltration. However, this restriction blocks standard Jinja loop helpers like <code>loop.index0</code>. By using a less restricted Jinja environment or an explicitly \"unsafe / trusted\" mode, we can overcome this limitation and use more complex templates with LangChain.</p>","tags":["langchain-ai","jinja2","templating"]},{"location":"2026-01-04-jinja2-loopindex0-blocked-by-restrictedsandboxedenvironment-when-using-template_formatjinja2/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["langchain-ai","jinja2","templating"]},{"location":"2026-01-04-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/","title":"Resolving APOC Procedures Error in Langchain with Neo4j v5.9","text":"","tags":["langchain","neo4j","apoc","graph database"]},{"location":"2026-01-04-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#core-problem","title":"Core Problem","text":"<p>When using the <code>Neo4jGraph</code> class from the Langchain library to connect to a Neo4j instance, an error is reported despite having successfully installed the APOC plugin and verified its version.</p> <p>ValueError: Could not use APOC procedures. Please ensure the APOC plugin is installed in Neo4j and that 'apoc.meta.data()' is allowed in Neo4j configuration</p>","tags":["langchain","neo4j","apoc","graph database"]},{"location":"2026-01-04-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To resolve this issue, we need to configure the Neo4j instance to allow the use of APOC procedures.</p>","tags":["langchain","neo4j","apoc","graph database"]},{"location":"2026-01-04-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#step-1-verify-apoc-plugin-installation","title":"Step 1: Verify APOC Plugin Installation","text":"<p>Ensure that the APOC plugin has been installed correctly by running the following command on your Neo4j client: <pre><code>return apoc.version()\n</code></pre> This should return the version number of the APOC plugin, confirming its installation.</p>","tags":["langchain","neo4j","apoc","graph database"]},{"location":"2026-01-04-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#step-2-configure-neo4j-to-allow-apoc-procedures","title":"Step 2: Configure Neo4j to Allow APOC Procedures","text":"<p>Update the Neo4j configuration file (<code>neo4j.conf</code>) to allow the use of APOC procedures. Add the following line to the <code>security</code> section: <pre><code>apoc.meta.data=true\n</code></pre> Restart the Neo4j server to apply the changes.</p>","tags":["langchain","neo4j","apoc","graph database"]},{"location":"2026-01-04-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#step-3-update-langchain-configuration","title":"Step 3: Update Langchain Configuration","text":"<p>Modify the Langchain configuration to include the updated APOC plugin settings. Create a new file (<code>langchain_config.py</code>) with the following content: <pre><code>import os\n\n# Neo4j connection settings\nneo4j_server = 'bolt://localhost:7687'\nneo4j_username = 'neo4j'\nneo4j_password = 'chenhuabc'\n\n# APOC plugin settings\napoc_enabled = True\n</code></pre></p>","tags":["langchain","neo4j","apoc","graph database"]},{"location":"2026-01-04-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#step-4-test-the-connection","title":"Step 4: Test the Connection","text":"<p>Restart the Langchain server and reconnect to the Neo4j instance using the updated configuration: <pre><code>from langchain.graphs import Neo4jGraph\n\ngraph = Neo4jGraph(\n    neo4j_server,\n    neo4j_username,\n    neo4j_password\n)\n\nprint(graph)\n</code></pre> This should resolve the error and establish a successful connection to the Neo4j instance.</p>","tags":["langchain","neo4j","apoc","graph database"]},{"location":"2026-01-04-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#conclusion","title":"Conclusion","text":"<p>By following these steps, you can resolve the APOC procedures error in Langchain with Neo4j v5.9. Ensure that the APOC plugin is installed correctly, configure the Neo4j instance to allow its use, update the Langchain configuration, and test the connection.</p>","tags":["langchain","neo4j","apoc","graph database"]},{"location":"2026-01-04-new-amd-memory-detection-routines-ignores-unified-memory-on-amd-apu/","title":"AMD Memory Detection Routines Ignore Unified Memory on AMD APU","text":"","tags":["AMD","Ollama","Memory Detection"]},{"location":"2026-01-04-new-amd-memory-detection-routines-ignores-unified-memory-on-amd-apu/#core-problem","title":"Core Problem","text":"<p>The current implementation of memory detection routines in Ollama incorrectly identifies strict VRAM on AMD APUs even when unified RAM is used by ROCM and Vulkan runtimes.</p>","tags":["AMD","Ollama","Memory Detection"]},{"location":"2026-01-04-new-amd-memory-detection-routines-ignores-unified-memory-on-amd-apu/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To resolve this issue, we need to modify the memory detection logic to account for the use of unified RAM. The new routine will need to take into account the actual available VRAM and ignore the shared RAM allocated by ROCM and Vulkan.</p> <pre><code>// MemoryDetection.go\n\npackage main\n\nimport (\n    \"fmt\"\n)\n\nconst (\n    unifiedRAM_THRESHOLD = 20 * 1024 * 1024 // 20 GiB\n\n    // ... other constants ...\n)\n\ntype Memory struct {\n    total   uint64\n    available uint64\n}\n\nfunc detectMemory() (uint64, error) {\n    // Get the total and available VRAM\n    var vram Memory\n    vram.total = getVramTotal()\n    vram.available = getVramAvailable()\n\n    // Check if unified RAM is used\n    if vram.available &gt; unifiedRAM_THRESHOLD {\n        return 0, fmt.Errorf(\"unified RAM is used\")\n    }\n\n    return vram.available, nil\n}\n\nfunc main() {\n    memory, err := detectMemory()\n    if err != nil {\n        fmt.Println(err)\n    } else {\n        fmt.Printf(\"Available VRAM: %d bytes\\n\", memory)\n    }\n}\n\n// ... other functions to get total and available VRAM ...\n</code></pre>","tags":["AMD","Ollama","Memory Detection"]},{"location":"2026-01-04-new-amd-memory-detection-routines-ignores-unified-memory-on-amd-apu/#conclusion","title":"Conclusion","text":"<p>The updated memory detection routine will correctly identify the actual available VRAM on AMD APUs, even when unified RAM is used by ROCM and Vulkan. This fix ensures that Ollama accurately detects the memory constraints of the system, allowing for more efficient and effective model training.</p>","tags":["AMD","Ollama","Memory Detection"]},{"location":"2026-01-04-pulling-manifest-error/","title":"Solving Ollama Pull Manifest Error","text":"","tags":["ollama","pull manifest error"]},{"location":"2026-01-04-pulling-manifest-error/#core-problem","title":"Core Problem","text":"<p>The ollama run command is failing with an error message indicating that the maximum number of retries has been exceeded due to an unexpected EOF (End Of File), and subsequent attempts are failing with a \"pull model manifest: file does not exist\" error.</p>","tags":["ollama","pull manifest error"]},{"location":"2026-01-04-pulling-manifest-error/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To resolve this issue, we need to ensure that the required system resources are available for the ollama run command. The suggested solution is to allocate sufficient memory on the system, particularly 32GB of RAM or more, as recommended by the developer who reported success with a similar setup.</p> <pre><code># Check available memory and free space\nfree -m\ndf -h\n\n# Allocate sufficient memory for ollama run\nexport OLLAMA_MEMORY=32G\n\n# Run ollama again with the updated configuration\nollama run dolphin-mixtral:latest\n</code></pre> <p>Additionally, ensure that there is enough free space on the hard drive to accommodate the download.</p>","tags":["ollama","pull manifest error"]},{"location":"2026-01-04-pulling-manifest-error/#conclusion","title":"Conclusion","text":"<p>By allocating sufficient system resources and ensuring adequate free space on the hard drive, users can resolve the pull manifest error when running ollama with the <code>dolphin-mixtral:latest</code> image. Regularly check system performance and storage capacity to prevent similar issues in the future.</p>","tags":["ollama","pull manifest error"]},{"location":"2026-01-04-pulling-manifest-error/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["ollama","pull manifest error"]},{"location":"2026-01-04-scheduler-will-run-into-race-conditions-on-large-scale-clusters/","title":"Understanding the Issue","text":"","tags":["Kubernetes","Scheduler","Performance Optimization"]},{"location":"2026-01-04-scheduler-will-run-into-race-conditions-on-large-scale-clusters/#core-problem","title":"Core Problem","text":"<p>In large-scale Kubernetes clusters, the scheduler can encounter race conditions that lead to unexpected pod assignments. This issue arises when the bind operation takes longer than the default timeout of 30 seconds, causing the scheduler cache to expire before the assignment is confirmed by the API server.</p>","tags":["Kubernetes","Scheduler","Performance Optimization"]},{"location":"2026-01-04-scheduler-will-run-into-race-conditions-on-large-scale-clusters/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To mitigate this issue, we need to extend the bind timeout for large clusters and make it adaptable to cluster state. Here's a proposed solution:</p> <pre><code>// Increase the bind timeout for large clusters\nvar (\n    // ... existing code ...\n    bindTimeout = 120 * time.Second // 2 minutes\n)\n\nfunc (s *Scheduler) Run() {\n    // ... existing code ...\n\n    // Extend the bind timeout for large clusters\n    if s.ClusterSize() &gt; 1000 { // arbitrary threshold, adjust as needed\n        bindTimeout = 5 * time.Minute // 5 minutes\n    }\n\n    // ... existing code ...\n}\n</code></pre> <p>Additionally, we can implement a cache refresh mechanism to ensure that the scheduler is aware of changes made by the API server. This can be achieved by using a cache expiration strategy that balances between freshness and performance.</p> <pre><code>// Implement a cache refresh mechanism\ntype CacheEntry struct {\n    // ... existing fields ...\n    LastRefreshed time.Time `json:\"lastRefreshed\"`\n}\n\nfunc (c *Cache) UpdatePodAssignment(podID string, nodeSelector string) error {\n    // ... existing code ...\n\n    // Refresh the cache entry with the updated last refreshed timestamp\n    c.UpdateCacheEntry(podID, nodeSelector, time.Now())\n}\n</code></pre>","tags":["Kubernetes","Scheduler","Performance Optimization"]},{"location":"2026-01-04-scheduler-will-run-into-race-conditions-on-large-scale-clusters/#conclusion","title":"Conclusion","text":"<p>By extending the bind timeout for large clusters and implementing a cache refresh mechanism, we can mitigate the effects of race conditions on pod assignments. This solution requires careful tuning and monitoring to ensure optimal performance in large-scale Kubernetes environments.</p>","tags":["Kubernetes","Scheduler","Performance Optimization"]},{"location":"2026-01-04-scheduler-will-run-into-race-conditions-on-large-scale-clusters/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["Kubernetes","Scheduler","Performance Optimization"]},{"location":"2026-01-04-support-for-multiple-images-in-chat-endpoint/","title":"Support for Multiple Images in /chat Endpoint","text":"","tags":["multiple-images","ollama-api","chat-endpoint"]},{"location":"2026-01-04-support-for-multiple-images-in-chat-endpoint/#core-problem","title":"Core Problem","text":"<p>The current implementation of the /chat endpoint only supports a single image, which introduces an additional layer of complexity when performing RAG (Reinforcement Algorithm with Gaze) with images embedded in base64.</p>","tags":["multiple-images","ollama-api","chat-endpoint"]},{"location":"2026-01-04-support-for-multiple-images-in-chat-endpoint/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To simplify this process, we can leverage existing libraries and frameworks that support multiple images. In the GitHub repository ollama/ollama, there is a note that ollama supports multiple images, but most models do not.</p> <p>For example, using the <code>base64</code> library in Python, we can pass multiple images in a single request:</p> <pre><code>$ for i in minicpm-v:8b-2.6-q4_K_M moondream:1.8b-v2-fp16 llava ; do \n  echo $i ; \n  echo '{\"model\": \"'$i'\",\n         \"messages\":[{\n            \"role\":\"user\",\"content\":\"describe the animals shown in the images\",\n            \"images\": [\n              \"'\"$(base64 puppy.jpg)\"'\",\n              \"'\"$(base64 kitten.jpg)\"'\"\n            ]\n          }],\n         \"stream\":false}' | curl -s http://localhost:11434/api/chat -d @- | jq -r .message.content ;\ndone\n</code></pre> <p>In this example, the <code>base64</code> library is used to encode the images and pass them in a single request. The response from the API can then be summarized into one.</p> <p>Another approach is to use the LLAVA model, which merges two images and describes a scene with multiple objects. This allows for more complex descriptions of scenes with multiple images.</p>","tags":["multiple-images","ollama-api","chat-endpoint"]},{"location":"2026-01-04-support-for-multiple-images-in-chat-endpoint/#conclusion","title":"Conclusion","text":"<p>Supporting multiple images in the /chat endpoint would greatly simplify workflows and reduce overhead in scenarios like RAG with images embedded in base64. While there is currently no plan to add this feature, existing libraries and frameworks can be used as a workaround.</p>","tags":["multiple-images","ollama-api","chat-endpoint"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/","title":"Tracking Issue for RFC 2045: Improving <code>#[target_feature]</code>","text":"","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/#core-problem","title":"Core Problem","text":"<p>The <code>#[target_feature]</code> attribute, introduced in RFC 2045, provides a way to conditionally compile code based on the target architecture's feature set. However, its usage and semantics are not yet fully stabilized.</p>","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/#solution-analysis","title":"Solution &amp; Analysis","text":"","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/#implementing-proposed-semantics","title":"Implementing Proposed Semantics","text":"<p>To implement the proposed <code>#[target_feature]</code> semantics, we need to add support for the following feature gates:</p> <pre><code>// Enable or disable features for a specific target\n#[cfg(target_feature = \"aarch64_unstable_target_feature\")]\nfn foo() {\n    // Code for aarch64_unstable_target_feature only\n}\n\n// Allow `#[target_feature]` on unsafe functions only\n#[unsafe_fn]\n#[cfg(target_feature = \"+feature\")]\nfn bar() {\n    // Code for the specified feature gate\n}\n</code></pre>","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/#documenting-semantics","title":"Documenting Semantics","text":"<p>The proposed semantics are documented in RFC 2045 and can be found at https://github.com/rust-lang/reference/pull/545.</p>","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/#stabilization-plan","title":"Stabilization Plan","text":"<p>To stabilize <code>#[target_feature]</code>, we need to:</p> <ol> <li> <p>Implement the basic set of features for x86_64 and i686: <pre><code>// Enable or disable features for a specific target (basic set)\n#[cfg(target_arch = \"x86_64\")]\nfn baz() {\n    // Code for x86_64\n}\n\n#[cfg(target_arch = \"i686\")]\nfn qux() {\n    // Code for i686\n}\n</code></pre></p> </li> <li> <p>Add support for ARM, AArch64, Hexagon, PowerPC, and MIPS: <pre><code>// Enable or disable features for a specific target (arm)\n#[cfg(target_feature = \"arm_target_feature\")]\nfn foo() {\n    // Code for arm\n}\n\n// Enable or disable features for a specific target (aarch64)\n#[cfg(target_feature = \"aarch64_ver_target_feature\")]\nfn bar() {\n    // Code for aarch64\n}\n</code></pre></p> </li> </ol>","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/#api-breaking-changes","title":"API Breaking Changes","text":"<p>To improve the stability of <code>#[target_feature]</code>, we need to make some API breaking changes:</p> <ol> <li> <p>Allow <code>#[target_feature]</code> on unsafe functions only: <pre><code>// Allow `#[target_feature]` on unsafe functions only\n#[unsafe_fn]\n#[cfg(target_feature = \"+feature\")]\nfn baz() {\n    // Code for the specified feature gate\n}\n</code></pre></p> </li> <li> <p>Change <code>#[target_feature = \"+feature\"]</code> to <code>#[target_feature(enable = \"feature\")]</code>: <pre><code>// Enable or disable features for a specific target (new syntax)\n#[cfg(target_feature(enable = \"feature\"))]\nfn qux() {\n    // Code for the specified feature gate\n}\n</code></pre></p> </li> </ol>","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/#related-tasks","title":"Related Tasks","text":"<p>To further improve <code>#[target_feature]</code>, we need to:</p> <ol> <li>Fix bug: https://github.com/rust-lang/rust/issues/42515</li> <li>Resolve bug: https://github.com/rust-lang/rust/issues/44367</li> <li>Implement runtime feature detection: <pre><code>// Runtime feature detection using the `cfg` macro\n#[cfg(feature = \"feature\")]\nfn foo() {\n    // Code for the specified feature gate\n}\n</code></pre></li> </ol>","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/#conclusion","title":"Conclusion","text":"<p>The <code>#[target_feature]</code> attribute is an essential tool for conditional compilation in Rust. By implementing the proposed semantics, documenting its usage, and making API breaking changes, we can improve its stability and usability.</p>","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["Rust Feature Gates","RFC 2045"]},{"location":"tags/","title":"Tags","text":"<ul> <li>AMD</li> <li>Kubernetes</li> <li>Memory Detection</li> <li>Ollama</li> <li>Performance Optimization</li> <li>RFC 2045</li> <li>React 19.0.0</li> <li>Rust Feature Gates</li> <li>Scheduler</li> <li>accuracy</li> <li>actQueue</li> <li>apoc</li> <li>chat-endpoint</li> <li>documentation</li> <li>graph database</li> <li>infinite growth</li> <li>installation</li> <li>isr cache</li> <li>jinja2</li> <li>langchain</li> <li>langchain-ai</li> <li>memory caching</li> <li>multiple-images</li> <li>neo4j</li> <li>next.js</li> <li>ollama</li> <li>ollama-api</li> <li>pandas</li> <li>pull manifest error</li> <li>rust-lang</li> <li>rustc-docs</li> <li>templating</li> </ul>"},{"location":"tags/#tag:amd","title":"AMD","text":"<ul> <li>            AMD Memory Detection Routines Ignore Unified Memory on AMD APU          </li> </ul>"},{"location":"tags/#tag:kubernetes","title":"Kubernetes","text":"<ul> <li>            Scheduler Race Conditions in Large-Scale Kubernetes Clusters          </li> </ul>"},{"location":"tags/#tag:memory-detection","title":"Memory Detection","text":"<ul> <li>            AMD Memory Detection Routines Ignore Unified Memory on AMD APU          </li> </ul>"},{"location":"tags/#tag:ollama","title":"Ollama","text":"<ul> <li>            AMD Memory Detection Routines Ignore Unified Memory on AMD APU          </li> </ul>"},{"location":"tags/#tag:performance-optimization","title":"Performance Optimization","text":"<ul> <li>            Scheduler Race Conditions in Large-Scale Kubernetes Clusters          </li> </ul>"},{"location":"tags/#tag:rfc-2045","title":"RFC 2045","text":"<ul> <li>            Tracking Issue for RFC 2045: Improving `#[target_feature]`          </li> </ul>"},{"location":"tags/#tag:react-1900","title":"React 19.0.0","text":"<ul> <li>            React 19.0.0 actQueue Infinite Growth Bug          </li> </ul>"},{"location":"tags/#tag:rust-feature-gates","title":"Rust Feature Gates","text":"<ul> <li>            Tracking Issue for RFC 2045: Improving `#[target_feature]`          </li> </ul>"},{"location":"tags/#tag:scheduler","title":"Scheduler","text":"<ul> <li>            Scheduler Race Conditions in Large-Scale Kubernetes Clusters          </li> </ul>"},{"location":"tags/#tag:accuracy","title":"accuracy","text":"<ul> <li>            Unreliable Documentation: A Case Study of Pandas Series.sum()          </li> </ul>"},{"location":"tags/#tag:actqueue","title":"actQueue","text":"<ul> <li>            React 19.0.0 actQueue Infinite Growth Bug          </li> </ul>"},{"location":"tags/#tag:apoc","title":"apoc","text":"<ul> <li>            Resolving APOC Procedures Error in Langchain with Neo4j v5.9          </li> </ul>"},{"location":"tags/#tag:chat-endpoint","title":"chat-endpoint","text":"<ul> <li>            Support for Multiple Images in /chat Endpoint          </li> </ul>"},{"location":"tags/#tag:documentation","title":"documentation","text":"<ul> <li>            Unreliable Documentation: A Case Study of Pandas Series.sum()          </li> </ul>"},{"location":"tags/#tag:graph-database","title":"graph database","text":"<ul> <li>            Resolving APOC Procedures Error in Langchain with Neo4j v5.9          </li> </ul>"},{"location":"tags/#tag:infinite-growth","title":"infinite growth","text":"<ul> <li>            React 19.0.0 actQueue Infinite Growth Bug          </li> </ul>"},{"location":"tags/#tag:installation","title":"installation","text":"<ul> <li>            Can't Install rustc-docs Component: Resolving the Conflict          </li> </ul>"},{"location":"tags/#tag:isr-cache","title":"isr cache","text":"<ul> <li>            ISR Fails to Serve 404 Pages After Page Deletion with Experimental ISR Memory Cache Size Set to 0          </li> </ul>"},{"location":"tags/#tag:jinja2","title":"jinja2","text":"<ul> <li>            Jinja2 loop.index0 blocked by RestrictedSandboxedEnvironment in LangChain          </li> </ul>"},{"location":"tags/#tag:langchain","title":"langchain","text":"<ul> <li>            Resolving APOC Procedures Error in Langchain with Neo4j v5.9          </li> </ul>"},{"location":"tags/#tag:langchain-ai","title":"langchain-ai","text":"<ul> <li>            Jinja2 loop.index0 blocked by RestrictedSandboxedEnvironment in LangChain          </li> </ul>"},{"location":"tags/#tag:memory-caching","title":"memory caching","text":"<ul> <li>            ISR Fails to Serve 404 Pages After Page Deletion with Experimental ISR Memory Cache Size Set to 0          </li> </ul>"},{"location":"tags/#tag:multiple-images","title":"multiple-images","text":"<ul> <li>            Support for Multiple Images in /chat Endpoint          </li> </ul>"},{"location":"tags/#tag:neo4j","title":"neo4j","text":"<ul> <li>            Resolving APOC Procedures Error in Langchain with Neo4j v5.9          </li> </ul>"},{"location":"tags/#tag:nextjs","title":"next.js","text":"<ul> <li>            ISR Fails to Serve 404 Pages After Page Deletion with Experimental ISR Memory Cache Size Set to 0          </li> </ul>"},{"location":"tags/#tag:ollama","title":"ollama","text":"<ul> <li>            Solving Ollama Pull Manifest Error          </li> </ul>"},{"location":"tags/#tag:ollama-api","title":"ollama-api","text":"<ul> <li>            Support for Multiple Images in /chat Endpoint          </li> </ul>"},{"location":"tags/#tag:pandas","title":"pandas","text":"<ul> <li>            Unreliable Documentation: A Case Study of Pandas Series.sum()          </li> </ul>"},{"location":"tags/#tag:pull-manifest-error","title":"pull manifest error","text":"<ul> <li>            Solving Ollama Pull Manifest Error          </li> </ul>"},{"location":"tags/#tag:rust-lang","title":"rust-lang","text":"<ul> <li>            Can't Install rustc-docs Component: Resolving the Conflict          </li> </ul>"},{"location":"tags/#tag:rustc-docs","title":"rustc-docs","text":"<ul> <li>            Can't Install rustc-docs Component: Resolving the Conflict          </li> </ul>"},{"location":"tags/#tag:templating","title":"templating","text":"<ul> <li>            Jinja2 loop.index0 blocked by RestrictedSandboxedEnvironment in LangChain          </li> </ul>"}]}