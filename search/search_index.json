{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to ISSUE WEB SEARCH","text":"<p>This site collects technical notes and trending topics automatically generated by our AI agent.</p>"},{"location":"#latest-updates","title":"Latest Updates","text":"<p>Check the sidebar for the latest generated content.</p> <p>Last updated: 2026-01-02</p>"},{"location":"2026-01-02-django-model-with-foreign-key-onto-settingsauth_user_model-fails-when-app-is-incorporated-into-other-app-using-postgres/","title":"2026 01 02 django model with foreign key onto settingsauth user model fails when app is incorporated into other app using postgres","text":""},{"location":"2026-01-02-django-model-with-foreign-key-onto-settingsauth_user_model-fails-when-app-is-incorporated-into-other-app-using-postgres/#django-model-with-foreign-key-to-settingsauth_user_model-fails-when-incorporated-into-another-app-using-postgres","title":"Django Model with Foreign Key to Settings.AUTH_USER_MODEL Fails When Incorporated into Another App Using Postgres","text":""},{"location":"2026-01-02-django-model-with-foreign-key-onto-settingsauth_user_model-fails-when-app-is-incorporated-into-other-app-using-postgres/#core-problem","title":"Core Problem","text":"<p>When incorporating a Django app with a foreign key to <code>settings.AUTH_USER_MODEL</code> into another app using Postgres, the migration fails due to null values in the <code>owner_id</code> column of the survey table.</p>"},{"location":"2026-01-02-django-model-with-foreign-key-onto-settingsauth_user_model-fails-when-app-is-incorporated-into-other-app-using-postgres/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To resolve this issue, we need to understand why the <code>owner_id</code> column is being created as deferrable and then added with a constraint that makes it immediate. This is happening because Django is using a different approach to handle foreign keys on Postgres compared to SQLite.</p> <p>In Django 3.2 and later, when you define a foreign key to <code>settings.AUTH_USER_MODEL</code>, the migration will create a deferrable constraint for the <code>owner_id</code> column. This means that the constraint will be applied after the data is inserted into the table, rather than during the creation of the table.</p> <p>However, when you run the migrations with Postgres, Django expects the constraint to be immediate, meaning it should be applied during the creation of the table.</p> <p>To fix this issue, we need to explicitly specify that the <code>owner_id</code> column should be created as immediate. We can do this by modifying our model to use the <code>db_constraint=False</code> argument when defining the foreign key.</p> <pre><code># models.py\n\nfrom django.contrib.auth.models import User\nfrom django.db import models\n\nclass Survey(models.Model):\n    owner = models.ForeignKey(User, on_delete=models.CASCADE, db_constraint=False)\n</code></pre> <p>By setting <code>db_constraint=False</code>, we're telling Django not to create a constraint for the <code>owner_id</code> column. This will allow us to avoid the null value issue when running migrations with Postgres.</p>"},{"location":"2026-01-02-django-model-with-foreign-key-onto-settingsauth_user_model-fails-when-app-is-incorporated-into-other-app-using-postgres/#conclusion","title":"Conclusion","text":"<p>In summary, when incorporating a Django app with a foreign key to <code>settings.AUTH_USER_MODEL</code> into another app using Postgres, we need to explicitly specify that the <code>owner_id</code> column should be created as immediate. By doing so, we can avoid the null value issue and ensure that our migrations run smoothly.</p> <pre><code># manage.py migrate\n</code></pre> <p>By applying these changes, you should be able to resolve the issue and successfully run your migrations with Postgres.</p>"},{"location":"2026-01-02-llm-inference-returns-non-deterministic-output-despite-fixed-seed-and-temperature-during-production-runs-closed/","title":"LLM Inference Non-Determinism: Understanding the Sources and Mitigating Solutions","text":"","tags":["Large Language Models","Deterministic Output","PyTorch","LLM Inference"]},{"location":"2026-01-02-llm-inference-returns-non-deterministic-output-despite-fixed-seed-and-temperature-during-production-runs-closed/#core-problem","title":"Core Problem","text":"<p>Repeated inference calls with the same prompt produce slightly different outputs, even when using fixed random seeds and generation parameters. This issue occurs despite thorough verification of the model version used, disabling streaming responses, and setting temperature to 0 and top_p to 1.0.</p>","tags":["Large Language Models","Deterministic Output","PyTorch","LLM Inference"]},{"location":"2026-01-02-llm-inference-returns-non-deterministic-output-despite-fixed-seed-and-temperature-during-production-runs-closed/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>The non-deterministic output in LLM inference can be attributed to several factors: - Stochastic Weight Initialization: Many large language models are initialized with stochastic weights, which introduces randomness during training. - Internal Model Variants: During inference, the model might draw from internal variant distributions, leading to subtle differences in output.</p> <p>To mitigate non-deterministic output, consider the following solutions:</p>","tags":["Large Language Models","Deterministic Output","PyTorch","LLM Inference"]},{"location":"2026-01-02-llm-inference-returns-non-deterministic-output-despite-fixed-seed-and-temperature-during-production-runs-closed/#1-stochastic-weight-initialization","title":"1. Stochastic Weight Initialization","text":"<p>Ensure that the same random seed is used for weight initialization in both training and testing phases.</p> <pre><code>import torch\n\n# Initialize weights with a fixed seed\nrandom.seed(42)\ntorch.manual_seed(42)\n\n# Initialize model parameters with stochastic weights\nmodel = LargeLanguageModel()\nfor param in model.parameters():\n    if param.requires_grad:\n        param.data.normal_(mean=0.0, std=0.02)\n</code></pre>","tags":["Large Language Models","Deterministic Output","PyTorch","LLM Inference"]},{"location":"2026-01-02-llm-inference-returns-non-deterministic-output-despite-fixed-seed-and-temperature-during-production-runs-closed/#2-internal-model-variants","title":"2. Internal Model Variants","text":"<p>Implement techniques to control internal variant distributions during inference:</p> <pre><code>import torch\n\n# Create a deterministic internal state\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\ndef generate(prompt):\n    # Initialize internal state to ensure reproducibility\n    model.internal_state = torch.zeros_like(model.state_dict())\n\n    # Generate response using the same internal state for each inference call\n    output = model.generate(prompt, temperature=0, top_p=1.0)\n    return output\n</code></pre>","tags":["Large Language Models","Deterministic Output","PyTorch","LLM Inference"]},{"location":"2026-01-02-llm-inference-returns-non-deterministic-output-despite-fixed-seed-and-temperature-during-production-runs-closed/#conclusion","title":"Conclusion","text":"<p>By understanding the sources of non-deterministic output in LLM inference and implementing techniques to control stochastic weight initialization and internal model variants, you can guarantee deterministic output during production runs. Always verify that your model is generating consistent results by using the same random seeds and configuration parameters across different tests.</p>","tags":["Large Language Models","Deterministic Output","PyTorch","LLM Inference"]},{"location":"2026-01-02-ovr-classification-not-working-on-mnist-dataset-closed/","title":"Understanding OVR Classification Issues with MNIST Dataset","text":"","tags":["Multiclass classification","One-vs-Rest (OVR) classifier","MNIST dataset"]},{"location":"2026-01-02-ovr-classification-not-working-on-mnist-dataset-closed/#core-problem","title":"Core Problem","text":"<p>Classification models using the One-vs-Rest (OVR) approach for multiclass problems, such as the MNIST dataset, can exhibit unexpected behavior when predicting class labels. In this scenario, images uploaded into the model are consistently classified as class 7, even full white or full black images, which were previously correctly classified as class 5.</p>","tags":["Multiclass classification","One-vs-Rest (OVR) classifier","MNIST dataset"]},{"location":"2026-01-02-ovr-classification-not-working-on-mnist-dataset-closed/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>The issue lies in the way OVR classifiers handle the classes and their boundaries. By design, OVR models train a separate classifier for each possible pair of classes against a common baseline (usually the majority class). This approach can lead to issues when dealing with datasets where the classes are not well-separated or have overlapping boundaries.</p> <p>In this specific case, it seems that the MNIST dataset's classes might be too loosely defined, causing the OVR classifier to misinterpret the input images. The model is trained on a balanced set of classes (0-9), but during prediction, it may not fully understand the subtleties between some of these classes.</p> <p>To address this issue, consider the following adjustments:</p> <ol> <li>Data Preprocessing: Before feeding data into the OVR classifier, apply additional preprocessing steps to enhance class separation and model interpretability.</li> <li>Class Balancing: If possible, balance the training data for each pair of classes to improve the overall performance of the model.</li> <li>Hyperparameter Tuning: Experiment with different hyperparameters for the OVR classifier to find optimal settings that better suit your dataset.</li> </ol> <p>Here's an updated code snippet incorporating some of these suggestions:</p> <pre><code>from sklearn.datasets import fetch_openml\nimport numpy as np\n\nmnist = fetch_openml('mnist_784', as_frame=False)\nX, y = mnist.data, mnist.target\n\n# Applying class balancing to improve model performance\nclass_balance = {}\nfor label in np.unique(y):\n    class_balance[label] = len(y[y == label])\n\nbalanced_y = []\nfor i, l in enumerate(y):\n    if l not in class_balance:\n        continue\n    balanced_y.append(class_balance[l])\n    y[i] = l\n\nX_train, X_test, y_train, y_test = X[:60000], X[60000:], np.array(balanced_y)[:60000], np.array(balanced_y)[60000:]\n\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import SVC\n\n# Applying a small amount of data augmentation to enhance class separation\ndef augment_data(img):\n    aug_img = img.copy()\n    aug_img[img &lt; 128] *= 1.2\n    return aug_img\n\novr_clf = OneVsRestClassifier(SVC(random_state=42))\novr_clf.fit(X_train, y_train)\n\nfrom google.colab import files\n\nuploaded = files.upload()\n\nfilename = next(iter(uploaded))\n\nimg = Image.open(filename).convert(\"L\")\naug_img = augment_data(img)\nimg_array = np.array(aug_img)\nimg_array = img_array.reshape(1, 784)\n\nprint(img_array)\novr_clf.predict(img_array)\n</code></pre>","tags":["Multiclass classification","One-vs-Rest (OVR) classifier","MNIST dataset"]},{"location":"2026-01-02-ovr-classification-not-working-on-mnist-dataset-closed/#conclusion","title":"Conclusion","text":"<p>By understanding the fundamental principles of OVR classification and applying targeted adjustments to your dataset and preprocessing steps, you can improve the accuracy and reliability of your multiclass classification models. Regularly monitor model performance on both training and test data to ensure that these modifications are effective in addressing specific issues.</p>","tags":["Multiclass classification","One-vs-Rest (OVR) classifier","MNIST dataset"]},{"location":"2026-01-02-pandas-last-3-weeks-same-day-average-in-groups/","title":"2026 01 02 pandas last 3 weeks same day average in groups","text":""},{"location":"2026-01-02-pandas-last-3-weeks-same-day-average-in-groups/#a-practical-approach-to-calculating-same-day-averages-over-the-last-3-weeks-in-pandas","title":"A Practical Approach to Calculating Same-Day Averages Over the Last 3 Weeks in Pandas","text":""},{"location":"2026-01-02-pandas-last-3-weeks-same-day-average-in-groups/#core-problem","title":"Core Problem","text":"<p>You have a dataset with a column of groups, dates, day of the week, and some data columns. You want to calculate the same-day average from the last 3 weeks for each date in each group, handling missing values and edge cases.</p>"},{"location":"2026-01-02-pandas-last-3-weeks-same-day-average-in-groups/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To solve this problem, you can use the pandas library's built-in functionality for time series operations. Here's an example code snippet:</p> <pre><code>import pandas as pd\n\n# Sample data\ndf = pd.DataFrame({\n    'Group': [\n        'Group 1', 'Group 2', 'Group 1', 'Group 2', 'Group 2', 'Group 1', 'Group 1', 'Group 2',\n        'Group 1', 'Group 2', 'Group 1', 'Group 2', 'Group 1', 'Group 2', 'Group 1', 'Group 2',\n        'Group 2', 'Group 1', 'Group 2', 'Group 1', 'Group 2', 'Group 1', 'Group 2', 'Group 1',\n        'Group 2', 'Group 1', 'Group 2', 'Group 2', 'Group 1', 'Group 2', 'Group 1', 'Group 2',\n        'Group 1', 'Group 2', 'Group 1', 'Group 2', 'Group 1', 'Group 2', 'Group 2', 'Group 1',\n        'Group 2', 'Group 1', 'Group 2', 'Group 1', 'Group 2', 'Group 1', 'Group 2', 'Group 1',\n        'Group 2'],\n    'Date': [\n        '2025-06-26 00:00:00', '2025-06-26 00:00:00', '2025-06-27 00:00:00', '2025-06-27 00:00:00',\n        '2025-06-28 00:00:00', '2025-06-29 00:00:00', '2025-06-30 00:00:00', '2025-06-30 00:00:00',\n        '2025-07-01 00:00:00', '2025-07-01 00:00:00', '2025-07-02 00:00:00', '2025-07-02 00:00:00',\n        '2025-07-03 00:00:00', '2025-07-03 00:00:00', '2025-07-04 00:00:00', '2025-07-04 00:00:00',\n        '2025-07-05 00:00:00', '2025-07-07 00:00:00', '2025-07-07 00:00:00', '2025-07-08 00:00:00',\n        '2025-07-08 00:00:00', '2025-07-09 00:00:00', '2025-07-09 00:00:00', '2025-07-10 00:00:00',\n        '2025-07-10 00:00:00', '2025-07-11 00:00:00', '2025-07-11 00:00:00', '2025-07-12 00:00:00',\n        '2025-07-14 00:00:00', '2025-07-14 00:00:00', '2025-07-15 00:00:00', '2025-07-15 00:00:00',\n        '2025-07-16 00:00:00', '2025-07-16 00:00:00', '2025-07-17 00:00:00', '2025-07-17 00:00:00',\n        '2025-07-18 00:00:00', '2025-07-18 00:00:00', '2025-07-19 00:00:00', '2025-07-21 00:00:00',\n        '2025-07-21 00:00:00', '2025-07-22 00:00:00', '2025-07-22 00:00:00', '2025-07-23 00:00:00',\n        '2025-07-23 00:00:00', '2025-07-24 00:00:00', '2025-07-24 00:00:00', '2025-07-25 00:00:00',\n        '2025-07-25 00:00:00'],\n    'Weekday': [\n        3, 3, 4, 4, 5, 6, 0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 0, 0,\n        1, 1, 2, 2, 3, 3, 4, 4, 5, 0, 0, 1, 1, 2, 2, 3, 3, 4, 4],\n    'Data 1': [\n        69, 33, 42, 38, 7, 1, 60, 37, 45, 31, 66, 30, 61, 29, 36, 41, 9, 27, 44, 29, 34, 46, 36,\n        55, 34, 29, 40, 8, 62, 49, 26, 30, 51, 31, 57, 36, 40, 49, 11, 65, 37, 50, 34, 38, 35, 70,\n        25, 27, 42],\n    'Data 2': [\n        7, 8, 4, 9, 3, 0, 6, 5, 3, 3, 11, 6, 10, 1, 6, 4, 0, 1, 6, 6, 5, 4, 2, 7, 1, 4, 5, 1, 3, 4,\n        0, 6, 4, 1, 7, 1, 8, 7, 0, 4, 9, 4, 4, 3, 2, 1, 5, 4, 7],\n    'Data 1 L4W Av': [\n        np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan,\n        np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, 51.33, 63.33, 39.667, 41.0, 25.33, 27.33,\n        47.33, 55.0, 33.667, 38.33, 39.33, 53.33, 37.33, 33.0, 29.0, 17.667, 31.667, 42.33, 43.667,\n        34.667, 29.33, 41.667, 46.667, 51.667, 36.667, 33.33, 34.667, 34.0, 33.0, 52.0, 34.667, 33.33],\n    'Data 2 L4W Av': [\n        np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan,\n        np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, 8.0, 7.667, 6.0, 4.0, 3.33, 2.0,\n        3.33, 4.0, 5.33, 4.0, 4.33, 3.0, 4.0, 3.67, 5.0, 4.0, 6.0, 3.0, 2.0]\n})\n\n# Convert 'Date' column to datetime type\ndf['Date'] = pd.to_datetime(df['Date'])\n\n# Create a new column 'Weekend' indicating weekends (Sat/Sun)\ndf['Weekend'] = df['Date'].dt.weekday.isin([5, 6])\n\n# Group by 'Group' and calculate the average of 'Data 1' and 'Data 2'\naverages = df.groupby('Group')[['Data 1', 'Data 2']].mean()\n\n# Calculate the same-day average over the last 3 weeks for each date\ndf['SameDayAvg'] = df.groupby(['Date'])['Data 1'].transform(lambda x: x.rolling(21).mean())\n\nprint(averages)\n</code></pre>"},{"location":"2026-01-02-pandas-last-3-weeks-same-day-average-in-groups/#conclusion","title":"Conclusion","text":"<p>By using pandas' built-in functionality and data manipulation, you can efficiently calculate the same-day average over the last 3 weeks for each date in your dataset. This approach allows for easy handling of missing values and edge cases, providing a robust solution for real-world applications.</p>"},{"location":"2026-01-02-python-lz4-how-to-configure-the-number-of-threads/","title":"Optimizing Python-LZ4 Performance with Multithreading Configuration","text":"","tags":["python-lz4","multithreading","performance optimization"]},{"location":"2026-01-02-python-lz4-how-to-configure-the-number-of-threads/#core-problem","title":"Core Problem","text":"<p>LZ4, a popular compression library for Python, has introduced multithreading support in its version 1.10.0 to enhance performance in high-throughput environments.</p>","tags":["python-lz4","multithreading","performance optimization"]},{"location":"2026-01-02-python-lz4-how-to-configure-the-number-of-threads/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To configure the number of threads in the Python binding of LZ4, you can utilize the <code>thread_pool_size</code> parameter when creating an instance of <code>lz4.frame.open</code>.</p>","tags":["python-lz4","multithreading","performance optimization"]},{"location":"2026-01-02-python-lz4-how-to-configure-the-number-of-threads/#configuring-thread-pool-size","title":"Configuring Thread Pool Size","text":"<pre><code>import lz4.frame\nimport shutil\n\ninput_file = r\"E:\\Personal Projects\\tmp\\chunk_0.ndjson\"\noutput_file = r\"E:\\Personal Projects\\tmp\\chunk_0.ndjson.lz4\"\n\n# Create an instance with a thread pool size of 4\nwith lz4.frame.open(output_file, mode=\"wb\", thread_pool_size=4) as g:\n    shutil.copyfileobj(open(input_file, \"rb\"), g)\n</code></pre> <p>In this example, we set the <code>thread_pool_size</code> to 4, which means LZ4 will create a pool of 4 worker threads to handle compression and decompression tasks concurrently.</p>","tags":["python-lz4","multithreading","performance optimization"]},{"location":"2026-01-02-python-lz4-how-to-configure-the-number-of-threads/#benchmarking-performance","title":"Benchmarking Performance","text":"<p>To validate the performance benefits of multithreading, you can compare the execution time of your Python script with and without thread pooling:</p> <pre><code>import lz4.frame\nimport time\nimport shutil\n\ninput_file = r\"E:\\Personal Projects\\tmp\\chunk_0.ndjson\"\noutput_file = r\"E:\\Personal Projects\\tmp\\chunk_0.ndjson.lz4\"\n\n# Measure execution time without thread pooling\nstart_time = time.time()\nwith open(input_file, \"rb\") as f, lz4.frame.open(output_file, mode=\"wb\") as g:\n    shutil.copyfileobj(f, g)\nend_time = time.time()\nno_thread_pool_time = end_time - start_time\n\n# Measure execution time with thread pooling\nstart_time = time.time()\nwith lz4.frame.open(output_file, mode=\"wb\", thread_pool_size=4) as g:\n    shutil.copyfileobj(open(input_file, \"rb\"), g)\nend_time = time.time()\nthread_pool_time = end_time - start_time\n\nprint(f\"No Thread Pool: {no_thread_pool_time} seconds\")\nprint(f\"Thread Pool (4 threads): {thread_pool_time} seconds\")\n</code></pre> <p>By configuring the thread pool size in LZ4, you can significantly improve the performance of your Python script for high-throughput environments.</p>","tags":["python-lz4","multithreading","performance optimization"]}]}