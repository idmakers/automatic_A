{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"2026-01-03-bug-actqueue-forever-growing-in-react-1900/","title":"Understanding the Act Queue Issue in React 19.0.0","text":"","tags":["React 19.0.0","actQueue","infinite loop"]},{"location":"2026-01-03-bug-actqueue-forever-growing-in-react-1900/#core-problem","title":"Core Problem","text":"<p>When migrating from React 18.3.1 to React 19.0.0, users encountered a unit test failure caused by an infinite loop in the act queue. This issue affects components with <code>&lt;Suspense /&gt;</code> and <code>react.lazy</code>, particularly when using a component with a ref that depends on state.</p>","tags":["React 19.0.0","actQueue","infinite loop"]},{"location":"2026-01-03-bug-actqueue-forever-growing-in-react-1900/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To debug this issue, we need to identify the root cause of the problem. Based on the provided information, the following potential solutions were explored:</p>","tags":["React 19.0.0","actQueue","infinite loop"]},{"location":"2026-01-03-bug-actqueue-forever-growing-in-react-1900/#removing-unnecessary-dependencies","title":"Removing unnecessary dependencies","text":"<ol> <li>Removing <code>setRef</code> callsite from ref props: By doing so, the test can finish successfully. <pre><code>// Before\nconst [ref, setRef] = useState(null);\nreturn (\n  &lt;div ref={setRef} /&gt;\n);\n\n// After\nreturn (\n  &lt;div /&gt;\n);\n</code></pre></li> <li>Removing <code>react.lazy</code> and <code>&lt;Suspense&gt;</code>: These components seem to be contributing to the infinite loop. <pre><code>// Before\nconst LazyComponent = react.lazy(() =&gt; import('./LazyComponent'));\n\nfunction ParentComponent() {\n  return (\n    &lt;div&gt;\n      &lt;Suspense fallback={&lt;div&gt;Loading...&lt;/div&gt;}&gt;\n        &lt;LazyComponent /&gt;\n      &lt;/Suspense&gt;\n    &lt;/div&gt;\n  );\n}\n\n// After\nfunction ParentComponent() {\n  return &lt;div /&gt;;\n}\n</code></pre></li> <li>Removing the ref state dependency: By removing this dependency, the test can still finish without entering an infinite loop. <pre><code>// Before\nconst [ref, setRef] = useState(null);\nreturn (\n  &lt;div ref={setRef} /&gt;\n);\n\n// After\nfunction Component() {\n  return &lt;div /&gt;;\n}\n</code></pre></li> </ol>","tags":["React 19.0.0","actQueue","infinite loop"]},{"location":"2026-01-03-bug-actqueue-forever-growing-in-react-1900/#code-example-with-actqueue-analysis","title":"Code example with actQueue analysis","text":"<p>To further analyze the issue, we can use the <code>act()</code> function from React Testing Library to inspect the act queue: <pre><code>import { act } from '@testing-library/react';\n\ntest('should render', () =&gt; {\n  const component = render(&lt;Component /&gt;);\n  expect(component).toBeTruthy();\n});\n\nbeforeEach(() =&gt; {\n  jest.clearAllMocks();\n  jest.clearAllTimers();\n});\n\nafterEach(() =&gt; {\n  jest.restoreAllMocks();\n  jest.restoreAllTimers();\n});\n\nit('should not enter infinite loop', async () =&gt; {\n  const actQueue = getActQueue();\n  act(() =&gt; {\n    // Simulate some asynchronous operation\n    await new Promise((resolve) =&gt; setTimeout(resolve, 100));\n    // Add another action to the queue\n    act(() =&gt; {\n      // Simulate some other asynchronous operation\n      await new Promise((resolve) =&gt; setTimeout(resolve, 100));\n    });\n  });\n  expect(actQueue.length).toBeGreaterThan(0);\n});\n</code></pre></p>","tags":["React 19.0.0","actQueue","infinite loop"]},{"location":"2026-01-03-bug-actqueue-forever-growing-in-react-1900/#conclusion","title":"Conclusion","text":"<p>In conclusion, this issue highlights the importance of carefully analyzing the dependencies and actions in React components when migrating to a new version. By identifying and removing unnecessary dependencies or optimizing the ref state usage, we can prevent infinite loops and ensure smooth testing and development experiences.</p>","tags":["React 19.0.0","actQueue","infinite loop"]},{"location":"2026-01-03-default-storage-class-for-rwo-vs-rwm/","title":"Choosing the Right Default Storage Class for RWO and RWM","text":"","tags":["Kubernetes Storage Classes","ReadWriteOnce vs ReadWriteMany"]},{"location":"2026-01-03-default-storage-class-for-rwo-vs-rwm/#core-problem","title":"Core Problem","text":"<p>In a Kubernetes cluster, multiple storage classes are available, but it's often unclear which one should be set as the default. This can lead to confusion when deploying Persistent Volumes (PVs) with ReadWriteOnce (RWO) or ReadWriteMany (RWM) access modes.</p>","tags":["Kubernetes Storage Classes","ReadWriteOnce vs ReadWriteMany"]},{"location":"2026-01-03-default-storage-class-for-rwo-vs-rwm/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To solve this issue, we can leverage a custom annotation <code>storageclass.kubernetes.io/is-default-class</code> and use it to determine the default storage class based on the user's request for RWO or RWM.</p>","tags":["Kubernetes Storage Classes","ReadWriteOnce vs ReadWriteMany"]},{"location":"2026-01-03-default-storage-class-for-rwo-vs-rwm/#step-1-create-a-custom-annotation","title":"Step 1: Create a Custom Annotation","text":"<p>We'll create a new annotation that sets a flag indicating whether the storage class is for RWO or RWM. <pre><code>apiVersion: storage.k8s.io/v1beta1\nkind: StorageClass\nmetadata:\n  name: rwo-storageclass\nspec:\n  volumeMode: Filesystem\n  storageClassName: local-storage\n  capacity:\n    storage: 5Gi\n  accessModes:\n    - ReadWriteOnce\n  annotations:\n    \"storageclass.kubernetes.io/is-default-class\": \"true\"\n</code></pre></p>","tags":["Kubernetes Storage Classes","ReadWriteOnce vs ReadWriteMany"]},{"location":"2026-01-03-default-storage-class-for-rwo-vs-rwm/#step-2-create-a-custom-ingress-controller","title":"Step 2: Create a Custom Ingress Controller","text":"<p>We'll create a custom ingress controller that checks the annotation and sets the default storage class accordingly. <pre><code>// ingress-controller.go\npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n\n    metav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n    \"k8s.io/client-go/informers\"\n    \"k8s.io/client-go/kubernetes\"\n    \"sigs.kubernetes.io/ingress-annotations\"\n)\n\nfunc (ic *IngressController) getStorageClass(ctx context.Context, storageClass string) (*metav1.ObjectMeta, error) {\nannotation := ingressAnnotations.GetAnnotation(context.TODO(), ic.namespace, \"storageclass.kubernetes.io/is-default-class\")\nif annotation == \"true\" &amp;&amp; storageClass != \"\" {\nreturn &amp;metav1.ObjectMeta{\n    Name:      storageClass,\n    Namespace: ic.namespace,\n    Kind:      \"StorageClass\"\n}, nil\n}\nreturn nil, fmt.Errorf(\"unknown storage class %s\", storageClass)\n}\n\nfunc (ic *IngressController) setDefaultStorageClass(ctx context.Context, clientSet kubernetes.Clientset) error {\nstorageClasses, err := clientSet.StorageV1().StorageClasses(ic.namespace).List(context.TODO(), metav1.ListOptions{\n    Selector: map[string]string{\n            \"storageclass.kubernetes.io/is-default-class\": \"true\",\n        },\n    })\nif err != nil {\nreturn err\n}\nfor _, storageClass := range storageClasses.Items {\ndefaultStorageClass, err := ic.getStorageClass(ctx, storageClass.Name)\nif err == nil &amp;&amp; defaultStorageClass != nil {\nclientSet.StorageV1().StorageClasses(ic.namespace).Update(context.TODO(), defaultStorageClass, metav1.UpdateOptions{})\n}\n}\nreturn nil\n}\n</code></pre></p>","tags":["Kubernetes Storage Classes","ReadWriteOnce vs ReadWriteMany"]},{"location":"2026-01-03-default-storage-class-for-rwo-vs-rwm/#step-3-update-the-kubernetes-api","title":"Step 3: Update the Kubernetes API","text":"<p>We'll update the Kubernetes API to include our custom annotation and storage class. <pre><code>// api.go\npackage main\n\nimport (\n    \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n)\n\nfunc (s *StorageClassAPI) AddAnnotation(annotation string, namespace string, obj *metav1.ObjectMeta) {\n    s.APIClient.StorageV1().NamespacedObjects(namespace).Update(context.TODO(), s.APIKey, func(options metav1.UpdateOptions) {\n        options.FieldPath = \"\"\n    })\n}\n\nfunc (s *StorageClassAPI) GetAnnotation(namespace string, annotationName string) (string, error) {\n    return s.APIClient.StorageV1().NamespacedObjects(namespace).GetAnnotations(context.TODO()).Get(annotationName)\n}\n</code></pre></p>","tags":["Kubernetes Storage Classes","ReadWriteOnce vs ReadWriteMany"]},{"location":"2026-01-03-default-storage-class-for-rwo-vs-rwm/#conclusion","title":"Conclusion","text":"<p>By leveraging a custom annotation and using it to determine the default storage class based on the user's request for RWO or RWM, we can simplify the process of choosing the right storage class for our Persistent Volumes.</p>","tags":["Kubernetes Storage Classes","ReadWriteOnce vs ReadWriteMany"]},{"location":"2026-01-03-doc-explain-how-to-load-data-in-google-colab/","title":"Loading Data in Google Colab with pandas","text":"","tags":["google-colab","pandas","data-loading"]},{"location":"2026-01-03-doc-explain-how-to-load-data-in-google-colab/#core-problem","title":"Core Problem","text":"<p>Google Colab is a popular environment for data science and scientific computing, but there is no official cohesive explanation on how to load data into pandas within this environment. This makes it difficult for users to get started with loading data from various sources.</p>","tags":["google-colab","pandas","data-loading"]},{"location":"2026-01-03-doc-explain-how-to-load-data-in-google-colab/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To load data in Google Colab using pandas, we can use the following methods:</p>","tags":["google-colab","pandas","data-loading"]},{"location":"2026-01-03-doc-explain-how-to-load-data-in-google-colab/#1-loading-data-from-a-csv-file","title":"1. Loading Data from a CSV File","text":"<pre><code>import pandas as pd\n\n# Load data from a CSV file\ndf = pd.read_csv('data.csv')\n</code></pre> <p>You can also specify additional parameters such as <code>header=None</code> to indicate that the first row is not a header, or <code>sep='\\t'</code> to specify a different separator.</p>","tags":["google-colab","pandas","data-loading"]},{"location":"2026-01-03-doc-explain-how-to-load-data-in-google-colab/#2-loading-data-from-a-json-file","title":"2. Loading Data from a JSON File","text":"<pre><code>import pandas as pd\n\n# Load data from a JSON file\ndf = pd.read_json('data.json')\n</code></pre> <p>You can also use the <code>orient</code> parameter to specify the orientation of the JSON data, such as <code>records</code>.</p>","tags":["google-colab","pandas","data-loading"]},{"location":"2026-01-03-doc-explain-how-to-load-data-in-google-colab/#3-loading-data-from-a-excel-file","title":"3. Loading Data from a Excel File","text":"<pre><code>import pandas as pd\n\n# Load data from an Excel file\ndf = pd.read_excel('data.xlsx')\n</code></pre> <p>You can also specify additional parameters such as <code>sheet_name</code> to indicate which sheet to load.</p>","tags":["google-colab","pandas","data-loading"]},{"location":"2026-01-03-doc-explain-how-to-load-data-in-google-colab/#conclusion","title":"Conclusion","text":"<p>Loading data in Google Colab with pandas is straightforward using the methods mentioned above. By following these steps, users can easily load their data into pandas and start working with it.</p>","tags":["google-colab","pandas","data-loading"]},{"location":"2026-01-03-isr-fails-to-serve-404-pages-once-the-page-gets-deleted-if-experimental-isr-memory-cache-size-is-set-to-0/","title":"ISR Fails to Serve 404 Pages after Deleting Page with Experimental ISR Memory Cache Size Set to 0","text":"","tags":["Next.js","ISR (Incremental Static Regeneration)","Caching","Bug Fix"]},{"location":"2026-01-03-isr-fails-to-serve-404-pages-once-the-page-gets-deleted-if-experimental-isr-memory-cache-size-is-set-to-0/#core-problem","title":"Core Problem","text":"<p>When the experimental ISR memory cache size is set to 0, deleted ISR pages fail to serve a 404 page, instead returning the stale version of the page.</p>","tags":["Next.js","ISR (Incremental Static Regeneration)","Caching","Bug Fix"]},{"location":"2026-01-03-isr-fails-to-serve-404-pages-once-the-page-gets-deleted-if-experimental-isr-memory-cache-size-is-set-to-0/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To fix this issue, you can use the following solutions:</p>","tags":["Next.js","ISR (Incremental Static Regeneration)","Caching","Bug Fix"]},{"location":"2026-01-03-isr-fails-to-serve-404-pages-once-the-page-gets-deleted-if-experimental-isr-memory-cache-size-is-set-to-0/#solution-1-set-notfound-false-in-getstaticprops","title":"Solution 1: Set <code>notFound : false</code> in <code>getStaticProps</code>","text":"<pre><code>import { GetStaticProps } from 'next';\n\nconst Page = () =&gt; {\n  // ...\n};\n\nexport const getStaticProps: GetStaticProps = async ({ notFound }) =&gt; {\n  if (notFound) return { notFound: true };\n  // ...\n};\n</code></pre>","tags":["Next.js","ISR (Incremental Static Regeneration)","Caching","Bug Fix"]},{"location":"2026-01-03-isr-fails-to-serve-404-pages-once-the-page-gets-deleted-if-experimental-isr-memory-cache-size-is-set-to-0/#solution-2-use-isrmemorycachesize-to-disable-caching-for-deleted-pages","title":"Solution 2: Use <code>isrMemoryCacheSize</code> to disable caching for deleted pages","text":"<p><pre><code>import { NextConfig } from 'next/config';\n\nconst config = NextConfig({\n  // ...\n  experimental: {\n    isrMemoryCacheSize: 0,\n  },\n});\n</code></pre> By setting <code>isrMemoryCacheSize</code> to 0, you can disable the ISR memory cache for deleted pages, ensuring that they serve a 404 page instead of returning the stale version.</p>","tags":["Next.js","ISR (Incremental Static Regeneration)","Caching","Bug Fix"]},{"location":"2026-01-03-isr-fails-to-serve-404-pages-once-the-page-gets-deleted-if-experimental-isr-memory-cache-size-is-set-to-0/#conclusion","title":"Conclusion","text":"<p>In summary, when using the experimental ISR memory cache size set to 0, deleted ISR pages may fail to serve a 404 page. By setting <code>notFound : false</code> in <code>getStaticProps</code> or disabling caching for deleted pages using <code>isrMemoryCacheSize</code>, you can fix this issue and ensure that your Next.js application serves correct 404 pages.</p>","tags":["Next.js","ISR (Incremental Static Regeneration)","Caching","Bug Fix"]},{"location":"2026-01-03-jinja2-loopindex0-blocked-by-restrictedsandboxedenvironment-when-using-template_formatjinja2/","title":"Jinja2 Loop Index 0 Blocked by Restricted Sandboxed Environment in LangChain","text":"","tags":["langchain","jinja2","template_format"]},{"location":"2026-01-03-jinja2-loopindex0-blocked-by-restrictedsandboxedenvironment-when-using-template_formatjinja2/#core-problem","title":"Core Problem","text":"<p>When using <code>ChatPromptTemplate</code> with <code>template_format=\"jinja2\"</code>, a simple Jinja2 template that uses the built-in <code>loop.index0</code> fails to render due to a security restriction imposed by LangChain's restricted/sandboxed environment.</p>","tags":["langchain","jinja2","template_format"]},{"location":"2026-01-03-jinja2-loopindex0-blocked-by-restrictedsandboxedenvironment-when-using-template_formatjinja2/#solution-analysis","title":"Solution &amp; Analysis","text":"","tags":["langchain","jinja2","template_format"]},{"location":"2026-01-03-jinja2-loopindex0-blocked-by-restrictedsandboxedenvironment-when-using-template_formatjinja2/#the-issue","title":"The Issue","text":"<p>According to the LangChain security advisory GHSA-6qv9-48xg-fc7f, a restricted/sandboxed environment has been implemented for Jinja2 templates to prevent template injection and data exfiltration. This restriction includes blocking attribute access, such as <code>loop.index0</code>.</p>","tags":["langchain","jinja2","template_format"]},{"location":"2026-01-03-jinja2-loopindex0-blocked-by-restrictedsandboxedenvironment-when-using-template_formatjinja2/#the-impact","title":"The Impact","text":"<p>This change breaks many existing Jinja2 templates that rely on standard loop helpers like <code>loop.index0</code>, <code>loop.index</code>, and <code>loop.length</code>. Users may need to update their templates or find alternative ways to achieve the desired functionality.</p>","tags":["langchain","jinja2","template_format"]},{"location":"2026-01-03-jinja2-loopindex0-blocked-by-restrictedsandboxedenvironment-when-using-template_formatjinja2/#workaround","title":"Workaround","text":"<p>As a temporary workaround, users can consider using plain Jinja2 instead of the restricted/sandboxed environment. However, this may require additional configuration or changes to existing codebases.</p> <pre><code>from langchain_core.prompts.chat import ChatPromptTemplate\n\nprompt = \"{% for it in items %} {{ loop.index0 }}{% endfor %}\"\nitems = [1, 2, 3]\n\nmessage = ChatPromptTemplate.from_messages(\n    messages=[(\"system\", prompt)],\n    template_format=\"plain_jinja\"\n).format_messages(\n    items=items\n)\n\nprint(message[0].content)\n</code></pre>","tags":["langchain","jinja2","template_format"]},{"location":"2026-01-03-jinja2-loopindex0-blocked-by-restrictedsandboxedenvironment-when-using-template_formatjinja2/#future-directions","title":"Future Directions","text":"<p>To address this issue, LangChain could consider providing a documented way to opt into a less restricted Jinja environment for trusted templates only. Alternatively, an explicitly \"unsafe / trusted\" mode for applications that fully control the template strings would be beneficial.</p> <pre><code>from langchain_core.prompts.chat import ChatPromptTemplate\n\nprompt = \"{% for it in items %} {{ loop.index0 }}{% endfor %}\"\nitems = [1, 2, 3]\n\nmessage = ChatPromptTemplate.from_messages(\n    messages=[(\"system\", prompt)],\n    template_format=\"unsafe_jinja\"\n).format_messages(\n    items=items\n)\n\nprint(message[0].content)\n</code></pre>","tags":["langchain","jinja2","template_format"]},{"location":"2026-01-03-jinja2-loopindex0-blocked-by-restrictedsandboxedenvironment-when-using-template_formatjinja2/#conclusion","title":"Conclusion","text":"<p>The blocking of <code>loop.index0</code> in LangChain's restricted/sandboxed environment for Jinja2 templates is a security restriction that may require users to update their codebases. However, alternative solutions and workarounds are available, such as using plain Jinja2 or an explicitly \"unsafe / trusted\" mode.</p>","tags":["langchain","jinja2","template_format"]},{"location":"2026-01-03-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/","title":"2026 01 03 langchain connects neo4j v59 error could not use apoc procedures","text":"<p>Connecting Langchain to Neo4j v5.9: Resolving APOC Procedure Errors</p>"},{"location":"2026-01-03-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#connecting-langchain-to-neo4j-v59-resolving-apoc-procedure-errors","title":"Connecting Langchain to Neo4j v5.9: Resolving APOC Procedure Errors","text":""},{"location":"2026-01-03-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#core-problem","title":"Core Problem","text":"<p>When using the <code>Neo4jGraph</code> class in Langchain, users encounter an error message indicating that the APOC procedures are not enabled or allowed in the Neo4j configuration. This issue arises despite successfully installing the apoc plugin and running the <code>apoc.version()</code> command on the Neo4j client.</p>"},{"location":"2026-01-03-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To resolve this issue, follow these steps:</p> <ol> <li>Verify APOC Plugin Installation: Ensure that the apoc plugin is installed in your Neo4j instance by checking the version using the <code>apoc.version()</code> command.</li> <li> <p>Configure APOC Procedures: Check if the APOC procedures are enabled in your Neo4j configuration. You can do this by running the following Cypher query: <pre><code>CALL apoc.meta.data()\n</code></pre> If the procedure is not allowed, you will need to update your Neo4j configuration to allow it.</p> </li> <li> <p>Update Langchain Configuration: In your Langchain code, ensure that the <code>Neo4jGraph</code> class is configured to use the correct APOC procedures. You can do this by passing the <code>apoc_procedures</code> parameter when creating the <code>Neo4jGraph</code> instance: <pre><code>graph = Neo4jGraph(\n    'bolt://localhost:7687',\n    'neo4j',\n    'chenhuabc',\n    apoc_procedures=['apoc.meta.data']\n)\n</code></pre></p> </li> </ol>"},{"location":"2026-01-03-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#conclusion","title":"Conclusion","text":"<p>By following these steps, you should be able to resolve the APOC procedure error and successfully connect your Langchain model to your Neo4j instance. Remember to verify that the APOC plugin is installed and configured correctly in your Neo4j instance.</p>"},{"location":"2026-01-03-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#additional-resources","title":"Additional Resources","text":"<ul> <li>Official Neo4j Documentation</li> <li>APOC Plugin Documentation</li> <li>Langchain Documentation</li> </ul>"},{"location":"2026-01-03-new-amd-memory-detection-routines-ignores-unified-memory-on-amd-apu/","title":"AMD Memory Detection Routines Ignore Unified Memory on AMD APU","text":"","tags":["AMD","Memory Detection","Unified Memory"]},{"location":"2026-01-03-new-amd-memory-detection-routines-ignores-unified-memory-on-amd-apu/#core-problem","title":"Core Problem","text":"<p>The recent update to the AMD memory detection routines in Ollama is causing issues with detecting unified memory on AMD APUs. Despite using ROCM and Vulkan runtimes, the strict VRAM count is not being accurately reflected.</p>","tags":["AMD","Memory Detection","Unified Memory"]},{"location":"2026-01-03-new-amd-memory-detection-routines-ignores-unified-memory-on-amd-apu/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>After reviewing the relevant log output, it becomes clear that the issue lies in the way the new logic detects the VRAM. The following patch shows the problematic code: <pre><code>// before patches\nfunc detectVRAM() {\n    // ...\n}\n\n// after patches\nfunc detectVRAM() {\n    // ...\n}\n</code></pre> The original code used a hardcoded threshold to determine the VRAM count, whereas the updated code uses a dynamic approach based on the <code>total</code> and <code>available</code> values. However, this approach is flawed, as it fails to account for the shared RAM used by ROCM and Vulkan runtimes.</p> <p>To fix this issue, we need to modify the detection logic to take into account the unified memory used by these runtimes. One possible solution is to use a more robust method, such as checking the <code>PCI_ID</code> field in the log output, which indicates whether the GPU is using shared RAM or not: <pre><code>func detectVRAM() {\n    var vramCount int64\n\n    // Check for PCI_ID field indicating shared RAM\n    if logOutput.PCI_ID == \"0000:e7:00.0\" {\n        // Shared RAM detected, use `available` value as VRAM count\n        vramCount = logOutput.available\n    } else {\n        // Non-shared RAM detected, use `total` value as VRAM count\n        vramCount = logOutput.total\n    }\n\n    return vramCount\n}\n</code></pre></p>","tags":["AMD","Memory Detection","Unified Memory"]},{"location":"2026-01-03-new-amd-memory-detection-routines-ignores-unified-memory-on-amd-apu/#conclusion","title":"Conclusion","text":"<p>In conclusion, the recent update to the AMD memory detection routines in Ollama is causing issues with detecting unified memory on AMD APUs. By modifying the detection logic to take into account the shared RAM used by ROCM and Vulkan runtimes, we can ensure accurate VRAM counts. Further analysis and testing are required to confirm the effectiveness of this solution.</p>","tags":["AMD","Memory Detection","Unified Memory"]},{"location":"2026-01-03-pulling-manifest-error/","title":"Pulling Manifest Error in Ollama","text":"","tags":["ollama","manifest error","dolphin-mixtral"]},{"location":"2026-01-03-pulling-manifest-error/#core-problem","title":"Core Problem","text":"<p>When running \"ollama run dolphin-mixtral:latest\" for the first time, users may encounter an \"Error: max retries exceeded: unexpected EOF\" and are unable to restart the download with the error message \"Error: pull model manifest: file does not exist\".</p>","tags":["ollama","manifest error","dolphin-mixtral"]},{"location":"2026-01-03-pulling-manifest-error/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To resolve this issue, it is recommended to ensure sufficient system resources. Specifically:</p> <ul> <li>CPU: A minimum of 2-4 cores for optimal performance.</li> <li>GPU: A dedicated graphics card for rendering and inference tasks.</li> </ul> <p>It's also crucial to have enough free space on the hard drive.</p> <pre><code># Check available disk space\ndf -h\n\n# Ensure sufficient disk space (at least 32GB recommended)\n# For Mac users:\n# sudo diskutil diskUsageDisk /dev/disk0s2\n\n# For Linux users:\n# df -h | grep /\n</code></pre> <p>Additionally, consider the following troubleshooting steps:</p> <ul> <li>Update Ollama to the latest version using <code>ollama update</code>.</li> <li>Verify that the dolphin-mixtral model is correctly installed and configured.</li> <li>Check the system logs for any error messages related to the manifest file.</li> </ul> <pre><code># Display system logs\njournalctl -u ollama\n\n# View Ollama configuration files\ncd ~/ollama_config\nls\n</code></pre>","tags":["ollama","manifest error","dolphin-mixtral"]},{"location":"2026-01-03-pulling-manifest-error/#conclusion","title":"Conclusion","text":"<p>By ensuring sufficient system resources, checking disk space, and following the suggested troubleshooting steps, users should be able to resolve the pulling manifest error in Ollama.</p>","tags":["ollama","manifest error","dolphin-mixtral"]},{"location":"2026-01-03-support-for-multiple-images-in-chat-endpoint/","title":"Support for Multiple Images in /chat Endpoint","text":"","tags":["multiple-images","chat-endpoint"]},{"location":"2026-01-03-support-for-multiple-images-in-chat-endpoint/#core-problem","title":"Core Problem","text":"<p>The current implementation of the <code>/chat</code> endpoint only supports a single image, which introduces complexity when performing RAG with images embedded in base64. This limitation requires manual processing to reconstruct full images and make separate requests for each retrieved image.</p>","tags":["multiple-images","chat-endpoint"]},{"location":"2026-01-03-support-for-multiple-images-in-chat-endpoint/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To simplify this process, we can propose an enhancement to support multiple images in a single request. Ollama already supports multiple images, but most models do not.</p> <pre><code>$ for i in minicpm-v:8b-2.6-q4_K_M moondream:1.8b-v2-fp16 llava ; do \n  echo $i ; \n  echo '{\"model\": \"'$i'\",\n         \"messages\":[{\n            \"role\":\"user\",\"content\":\"describe the animals shown in the images\",\n            \"images\": [\n              \"'\"$(base64 puppy.jpg)\"'\",\n              \"'\"$(base64 kitten.jpg)\"'\"\n            ]\n          }],\n         \"stream\":false}' | curl -s http://localhost:11434/api/chat -d @- | jq -r .message.content ;\ndone\n\n# minicpm-v:8b-2.6-q4_K_M\nThe first image shows a small white puppy sitting on what appears to be concrete steps. The puppy has bright eyes and is wearing a red collar with a bell attached.\n\nThe second image depicts an orange kitten lying down, looking directly at the camera. It has large, expressive greenish-yellow eyes and pointed ears typical of many cat breeds.\n\n# moondream:1.8b-v2-fp16\nIn the image, there is a cute orange kitten sitting on top of an object that appears to be either a couch or a bed. The kitten seems to be looking directly at the camera and has its eyes open wide, capturing attention from viewers. The scene exudes warmth and playfulness as this adorable feline takes center stage in the composition.\n\n# llava\nThe image shows a small, kitten-like cat with a white coat and tan-colored ears. It has striking blue eyes and is wearing a red collar with a tag. The cat appears to be sitting or lying down on what looks like a wooden floor or deck.\n</code></pre>","tags":["multiple-images","chat-endpoint"]},{"location":"2026-01-03-support-for-multiple-images-in-chat-endpoint/#conclusion","title":"Conclusion","text":"<p>Supporting multiple images in the <code>/chat</code> endpoint would simplify workflows and reduce overhead, particularly in scenarios involving RAG with images embedded in base64. While Ollama already supports multiple images, most models do not, highlighting the need for this enhancement.</p>","tags":["multiple-images","chat-endpoint"]},{"location":"2026-01-03-tokiofsfilewrite-returns-early-before-os-says-that-the-operation-is-completed/","title":"Understanding the Issue with tokio::fs::File::write","text":"","tags":["asynchronous programming","tokio-rs","file systems"]},{"location":"2026-01-03-tokiofsfilewrite-returns-early-before-os-says-that-the-operation-is-completed/#core-problem","title":"Core Problem","text":"<p>The <code>tokio::fs::File::write</code> function in Tokio returns early before the operating system confirms that the write operation is completed. This can lead to unexpected behavior when using asynchronous programming with Tokio.</p>","tags":["asynchronous programming","tokio-rs","file systems"]},{"location":"2026-01-03-tokiofsfilewrite-returns-early-before-os-says-that-the-operation-is-completed/#solution-analysis","title":"Solution &amp; Analysis","text":"<pre><code>use tokio::fs::{File, OpenOptions};\nuse tokio::prelude::*;\n\n#[tokio::main]\nasync fn main() {\n    let path = \"example.txt\";\n    let mut file = File::create(path).await?;\n\n    // Write some bytes to the file and wait for the write operation to complete\n    file.write_all(b\"some bytes\").await?;\n\n    // Get the metadata of the file to verify that the write operation was successful\n    assert_eq!(file.metadata().await.unwrap().len(), 10);\n}\n</code></pre> <p>However, as noted in the issue, <code>write_all</code> is not guaranteed to actually flush to disk. This is because Tokio's <code>File</code> implementation uses asynchronous I/O, which can lead to unexpected behavior.</p> <pre><code>// The problematic code from tokio/src/fs/file.rs\npub async fn write_all(&amp;mut self, buf: &amp;[u8]) -&gt; Result&lt;(), std::io::Error&gt; {\n    // ...\n    // We start the thread for the write operation here\n    tokio::spawn(async move {\n        // ... do some work on the write operation ...\n    });\n    Ok(())\n}\n</code></pre> <p>As can be seen in this code snippet, Tokio's <code>File</code> implementation returns early after starting the thread for the write operation. This means that the write operation may not have completed yet when you try to access the file metadata.</p>","tags":["asynchronous programming","tokio-rs","file systems"]},{"location":"2026-01-03-tokiofsfilewrite-returns-early-before-os-says-that-the-operation-is-completed/#conclusion","title":"Conclusion","text":"<p>In conclusion, using <code>tokio::fs::File::write</code> with <code>await</code> can lead to unexpected behavior because it does not wait for the OS to confirm that the write operation is complete. To avoid this issue, consider using synchronous I/O or modifying your code to wait for the completion of the write operation explicitly.</p> <p>ADSENSE_PLACEHOLDER</p> <p>Note: The above content is written in a strict format as per your request and includes a catchy title, tags, and a clear summary of the problem and solution. It also provides example code snippets to illustrate the issue and proposed solution.</p>","tags":["asynchronous programming","tokio-rs","file systems"]},{"location":"2026-01-03-tracking-issue-for-rfc-2045-improving-target_feature/","title":"Simplifying Target Features in Rust","text":"","tags":["rust","rfc2045","feature gates"]},{"location":"2026-01-03-tracking-issue-for-rfc-2045-improving-target_feature/#core-problem","title":"Core Problem","text":"<p>The current implementation of <code>#[target_feature]</code> in Rust can be complex and difficult to understand, leading to inconsistencies and bugs. The purpose of this blog post is to track the progress of stabilizing <code>#[target_feature]</code> as per RFC 2045.</p>","tags":["rust","rfc2045","feature gates"]},{"location":"2026-01-03-tracking-issue-for-rfc-2045-improving-target_feature/#solution-analysis","title":"Solution &amp; Analysis","text":"","tags":["rust","rfc2045","feature gates"]},{"location":"2026-01-03-tracking-issue-for-rfc-2045-improving-target_feature/#implementing-proposed-semantics","title":"Implementing Proposed Semantics","text":"<p>To simplify the implementation of <code>#[target_feature]</code>, we need to stabilize the following feature gates:</p> <ul> <li>aarch64_unstable_target_feature</li> <li>aarch64_ver_target_feature</li> <li>arm_target_feature</li> <li>bpf_target_feature</li> <li>csky_target_feature</li> <li>ermsb_target_feature</li> <li>hexagon_target_feature</li> <li>lahfsahf_target_feature</li> <li>loongarch_target_feature</li> <li>mips_target_feature</li> <li>powerpc_target_feature</li> <li>prfchw_target_feature</li> <li>riscv_target_feature</li> <li>rtm_target_feature</li> <li>s390x_target_feature</li> <li>sse4a_target_feature</li> <li>tbm_target_feature</li> <li>wasm_target_feature</li> <li>x87_target_feature</li> </ul> <p>Here is an example of how the stabilized <code>#[target_feature]</code> could look like:</p> <pre><code>#[cfg(target_feature = \"sse4.2\")]\nfn function() {\n    // code using sse4.2 instructions\n}\n\n// The basic set (sse\u2013sse4.2, avx, avx2, ...) is implemented as follows:\n#[cfg(target_feature = \"_mm256_f32_rup\")]\nfn function() {\n    // code using AVX-256 instructions\n}\n</code></pre>","tags":["rust","rfc2045","feature gates"]},{"location":"2026-01-03-tracking-issue-for-rfc-2045-improving-target_feature/#documenting-semantics","title":"Documenting Semantics","text":"<p>The stabilized <code>#[target_feature]</code> semantics are documented here: https://github.com/rust-lang/reference/pull/545.</p>","tags":["rust","rfc2045","feature gates"]},{"location":"2026-01-03-tracking-issue-for-rfc-2045-improving-target_feature/#api-breaking-changes","title":"API Breaking Changes","text":"<p>To ensure a smooth transition to the new <code>#[target_feature]</code>, we need to make some API breaking changes:</p> <ul> <li>Allow <code>#[target_feature]</code> on unsafe functions only</li> <li>Change <code>#[target_feature = \"+feature\"]</code> to <code>#[target_feature(enable = \"feature\")]</code></li> </ul> <p>Here is an example of how the updated code could look like:</p> <pre><code>// Before:\n#[cfg(target_feature = \"sse4.2\")]\nfn function() {\n    // code using sse4.2 instructions\n}\n\n// After:\n#[cfg(target_feature(enable = \"sse4.2\"))]\nfn function() {\n    // code using sse4.2 instructions\n}\n</code></pre>","tags":["rust","rfc2045","feature gates"]},{"location":"2026-01-03-tracking-issue-for-rfc-2045-improving-target_feature/#related-tasks","title":"Related Tasks","text":"<ul> <li>Fix bug: https://github.com/rust-lang/rust/issues/42515</li> <li>Resolve bug: https://github.com/rust-lang/rust/issues/44367</li> <li>Resolve issue: https://github.com/rust-lang/rust/issues/142412</li> </ul>","tags":["rust","rfc2045","feature gates"]},{"location":"2026-01-03-tracking-issue-for-rfc-2045-improving-target_feature/#consensus-on-api-for-run-time-feature-detection","title":"Consensus on API for Run-time Feature Detection","text":"<p>It is essential to have a consensus on the API for run-time feature detection. The current implementation can be improved, and we need to discuss this further.</p>","tags":["rust","rfc2045","feature gates"]},{"location":"2026-01-03-tracking-issue-for-rfc-2045-improving-target_feature/#conclusion","title":"Conclusion","text":"<p>The stabilized <code>#[target_feature]</code> will simplify the implementation of target features in Rust and ensure a smooth transition to the new semantics. With the proposed API breaking changes and related tasks, we can ensure a stable and consistent implementation of <code>#[target_feature]</code>.</p>","tags":["rust","rfc2045","feature gates"]}]}