{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"2026-01-03-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/","title":"2026 01 03 langchain connects neo4j v59 error could not use apoc procedures","text":"<p>Connecting Langchain to Neo4j v5.9: Resolving APOC Procedure Errors</p>"},{"location":"2026-01-03-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#connecting-langchain-to-neo4j-v59-resolving-apoc-procedure-errors","title":"Connecting Langchain to Neo4j v5.9: Resolving APOC Procedure Errors","text":""},{"location":"2026-01-03-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#core-problem","title":"Core Problem","text":"<p>When using the <code>Neo4jGraph</code> class in Langchain, users encounter an error message indicating that the APOC procedures are not enabled or allowed in the Neo4j configuration. This issue arises despite successfully installing the apoc plugin and running the <code>apoc.version()</code> command on the Neo4j client.</p>"},{"location":"2026-01-03-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To resolve this issue, follow these steps:</p> <ol> <li>Verify APOC Plugin Installation: Ensure that the apoc plugin is installed in your Neo4j instance by checking the version using the <code>apoc.version()</code> command.</li> <li> <p>Configure APOC Procedures: Check if the APOC procedures are enabled in your Neo4j configuration. You can do this by running the following Cypher query: <pre><code>CALL apoc.meta.data()\n</code></pre> If the procedure is not allowed, you will need to update your Neo4j configuration to allow it.</p> </li> <li> <p>Update Langchain Configuration: In your Langchain code, ensure that the <code>Neo4jGraph</code> class is configured to use the correct APOC procedures. You can do this by passing the <code>apoc_procedures</code> parameter when creating the <code>Neo4jGraph</code> instance: <pre><code>graph = Neo4jGraph(\n    'bolt://localhost:7687',\n    'neo4j',\n    'chenhuabc',\n    apoc_procedures=['apoc.meta.data']\n)\n</code></pre></p> </li> </ol>"},{"location":"2026-01-03-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#conclusion","title":"Conclusion","text":"<p>By following these steps, you should be able to resolve the APOC procedure error and successfully connect your Langchain model to your Neo4j instance. Remember to verify that the APOC plugin is installed and configured correctly in your Neo4j instance.</p>"},{"location":"2026-01-03-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#additional-resources","title":"Additional Resources","text":"<ul> <li>Official Neo4j Documentation</li> <li>APOC Plugin Documentation</li> <li>Langchain Documentation</li> </ul>"},{"location":"2026-01-03-new-amd-memory-detection-routines-ignores-unified-memory-on-amd-apu/","title":"AMD Memory Detection Routines Ignore Unified Memory on AMD APU","text":"","tags":["AMD","Memory Detection","Unified Memory"]},{"location":"2026-01-03-new-amd-memory-detection-routines-ignores-unified-memory-on-amd-apu/#core-problem","title":"Core Problem","text":"<p>The recent update to the AMD memory detection routines in Ollama is causing issues with detecting unified memory on AMD APUs. Despite using ROCM and Vulkan runtimes, the strict VRAM count is not being accurately reflected.</p>","tags":["AMD","Memory Detection","Unified Memory"]},{"location":"2026-01-03-new-amd-memory-detection-routines-ignores-unified-memory-on-amd-apu/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>After reviewing the relevant log output, it becomes clear that the issue lies in the way the new logic detects the VRAM. The following patch shows the problematic code: <pre><code>// before patches\nfunc detectVRAM() {\n    // ...\n}\n\n// after patches\nfunc detectVRAM() {\n    // ...\n}\n</code></pre> The original code used a hardcoded threshold to determine the VRAM count, whereas the updated code uses a dynamic approach based on the <code>total</code> and <code>available</code> values. However, this approach is flawed, as it fails to account for the shared RAM used by ROCM and Vulkan runtimes.</p> <p>To fix this issue, we need to modify the detection logic to take into account the unified memory used by these runtimes. One possible solution is to use a more robust method, such as checking the <code>PCI_ID</code> field in the log output, which indicates whether the GPU is using shared RAM or not: <pre><code>func detectVRAM() {\n    var vramCount int64\n\n    // Check for PCI_ID field indicating shared RAM\n    if logOutput.PCI_ID == \"0000:e7:00.0\" {\n        // Shared RAM detected, use `available` value as VRAM count\n        vramCount = logOutput.available\n    } else {\n        // Non-shared RAM detected, use `total` value as VRAM count\n        vramCount = logOutput.total\n    }\n\n    return vramCount\n}\n</code></pre></p>","tags":["AMD","Memory Detection","Unified Memory"]},{"location":"2026-01-03-new-amd-memory-detection-routines-ignores-unified-memory-on-amd-apu/#conclusion","title":"Conclusion","text":"<p>In conclusion, the recent update to the AMD memory detection routines in Ollama is causing issues with detecting unified memory on AMD APUs. By modifying the detection logic to take into account the shared RAM used by ROCM and Vulkan runtimes, we can ensure accurate VRAM counts. Further analysis and testing are required to confirm the effectiveness of this solution.</p>","tags":["AMD","Memory Detection","Unified Memory"]},{"location":"2026-01-03-support-for-multiple-images-in-chat-endpoint/","title":"Support for Multiple Images in /chat Endpoint","text":"","tags":["multiple-images","chat-endpoint"]},{"location":"2026-01-03-support-for-multiple-images-in-chat-endpoint/#core-problem","title":"Core Problem","text":"<p>The current implementation of the <code>/chat</code> endpoint only supports a single image, which introduces complexity when performing RAG with images embedded in base64. This limitation requires manual processing to reconstruct full images and make separate requests for each retrieved image.</p>","tags":["multiple-images","chat-endpoint"]},{"location":"2026-01-03-support-for-multiple-images-in-chat-endpoint/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To simplify this process, we can propose an enhancement to support multiple images in a single request. Ollama already supports multiple images, but most models do not.</p> <pre><code>$ for i in minicpm-v:8b-2.6-q4_K_M moondream:1.8b-v2-fp16 llava ; do \n  echo $i ; \n  echo '{\"model\": \"'$i'\",\n         \"messages\":[{\n            \"role\":\"user\",\"content\":\"describe the animals shown in the images\",\n            \"images\": [\n              \"'\"$(base64 puppy.jpg)\"'\",\n              \"'\"$(base64 kitten.jpg)\"'\"\n            ]\n          }],\n         \"stream\":false}' | curl -s http://localhost:11434/api/chat -d @- | jq -r .message.content ;\ndone\n\n# minicpm-v:8b-2.6-q4_K_M\nThe first image shows a small white puppy sitting on what appears to be concrete steps. The puppy has bright eyes and is wearing a red collar with a bell attached.\n\nThe second image depicts an orange kitten lying down, looking directly at the camera. It has large, expressive greenish-yellow eyes and pointed ears typical of many cat breeds.\n\n# moondream:1.8b-v2-fp16\nIn the image, there is a cute orange kitten sitting on top of an object that appears to be either a couch or a bed. The kitten seems to be looking directly at the camera and has its eyes open wide, capturing attention from viewers. The scene exudes warmth and playfulness as this adorable feline takes center stage in the composition.\n\n# llava\nThe image shows a small, kitten-like cat with a white coat and tan-colored ears. It has striking blue eyes and is wearing a red collar with a tag. The cat appears to be sitting or lying down on what looks like a wooden floor or deck.\n</code></pre>","tags":["multiple-images","chat-endpoint"]},{"location":"2026-01-03-support-for-multiple-images-in-chat-endpoint/#conclusion","title":"Conclusion","text":"<p>Supporting multiple images in the <code>/chat</code> endpoint would simplify workflows and reduce overhead, particularly in scenarios involving RAG with images embedded in base64. While Ollama already supports multiple images, most models do not, highlighting the need for this enhancement.</p>","tags":["multiple-images","chat-endpoint"]}]}