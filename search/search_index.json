{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to ISSUE WEB SEARCH","text":"<p>This site collects technical notes and trending topics automatically generated by our AI agent.</p>"},{"location":"#latest-updates","title":"Latest Updates","text":"<p>Check the sidebar for the latest generated content.</p> <p>Last updated: 2026-01-02</p>"},{"location":"2026-01-02-adk-google-gemini-session-not-found-default-when-using-inmemoryrunner-with-llmagent/","title":"Resolving 'Session not found: default' Error when Using InMemoryRunner with LLMAgent in Google ADK","text":"","tags":["debugging","google adk","llm agent","inmemoryrunner","sessionservice"]},{"location":"2026-01-02-adk-google-gemini-session-not-found-default-when-using-inmemoryrunner-with-llmagent/#core-problem","title":"Core Problem","text":"<p>When using the Google ADK's LLM Agent (<code>gemini-2.5-flash-lite</code>) with <code>InMemoryRunner</code> and <code>InMemorySessionService</code>, an error is encountered that prevents the session from being recognized: \"Session not found: default\".</p>","tags":["debugging","google adk","llm agent","inmemoryrunner","sessionservice"]},{"location":"2026-01-02-adk-google-gemini-session-not-found-default-when-using-inmemoryrunner-with-llmagent/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>The issue lies in how <code>InMemoryRunner</code> and <code>InMemorySessionService</code> interact. The problem arises because the session ID passed to <code>runner.run_async</code> does not match the one stored by the <code>InMemorySessionService</code>. This discrepancy leads to the \"Session not found\" error.</p> <p>To resolve this, ensure that the session ID provided to both the runner and the session service is consistent. One approach is to use a unique session ID for each agent instance or modify the helper function to reuse an existing session if available.</p> <pre><code>import asyncio\nfrom google.adk.agents.llm_agent import Agent\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.genai.types import Content, Part\n\n_APP_USER_ID = \"system\"\n_APP_SESSION_ID = \"existing_session_id\"\n\n_SESSION_SERVICE = InMemorySessionService()\n\nasync def _run_agent(agent: Agent, prompt: str) -&gt; str:\n    # Attempt to create a session\n    existing_session = await _SESSION_SERVICE.get_session(\n        app_name=\"duck_pa\",\n        user_id=_APP_USER_ID,\n        session_id=_APP_SESSION_ID\n    )\n\n    if not existing_session:\n        # Create a new session with the provided ID\n        existing_session = await _SESSION_SERVICE.create_session(\n            app_name=\"duck_pa\",\n            user_id=_APP_USER_ID,\n            session_id=_APP_SESSION_ID\n        )\n\n    runner = InMemoryRunner(agent)\n    input_content = Content(parts=[Part(text=prompt)])\n\n    async for event in runner.run_async(\n        new_message=input_content,\n        user_id=existing_session.user_id,\n        session_id=existing_session.id\n    ):\n        if event.is_final_response():\n            return &amp;quot;&amp;quot;.join(\n                part.text for part in event.content.parts if getattr(part, &amp;quot;text&amp;quot;, None)\n            )\n\n    raise RuntimeError(&amp;quot;Agent did not return a final response&amp;quot;}\n</code></pre>","tags":["debugging","google adk","llm agent","inmemoryrunner","sessionservice"]},{"location":"2026-01-02-adk-google-gemini-session-not-found-default-when-using-inmemoryrunner-with-llmagent/#conclusion","title":"Conclusion","text":"<p>By modifying the helper function to retrieve an existing session before creating a new one and using its ID when running the agent, the \"Session not found: default\" error can be resolved. This approach ensures that both the runner and the session service use the same session ID, thereby resolving the issue with InMemoryRunner and LLMAgent in Google ADK.</p>","tags":["debugging","google adk","llm agent","inmemoryrunner","sessionservice"]},{"location":"2026-01-02-error-in-taskiq-python-while-executing-dynamic-interval-schedules/","title":"2026 01 02 error in taskiq python while executing dynamic interval schedules","text":"<p>title: Taskiq Python Error in Dynamic Interval Schedules</p> <p>tags:   - taskiq   - python   - aiogram   - redis   - redis.exceptions.ResponseError   - NOGROUP   - consumer group 'taskiq'</p>"},{"location":"2026-01-02-error-in-taskiq-python-while-executing-dynamic-interval-schedules/#core-problem","title":"Core Problem","text":"<p>I have an aiogram bot with taskiq worker and scheduler (taskiq redis with taskiq_aiogram), but after some time (30-40 minutes), I'm getting a <code>redis.exceptions.ResponseError: NOGROUP No such key 'taskiq' or consumer group 'taskiq' in XREADGROUP with GROUP option</code>. This error occurs when running dynamic interval scheduled tasks, while static interval scheduled tasks work without errors.</p>"},{"location":"2026-01-02-error-in-taskiq-python-while-executing-dynamic-interval-schedules/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>The issue arises from the fact that taskiq Redis uses a consumer group to manage tasks. However, when using dynamic interval schedules, the consumer group is not created until after the first task has been executed. To fix this, we need to create the consumer group at startup or before running any tasks.</p> <p>Here's an updated version of the <code>on_worker_startup</code> function that creates the consumer group:</p> <pre><code>@broker.on_event(TaskiqEvents.WORKER_STARTUP)\nasync def on_worker_startup(context: Annotated[Context, TaskiqDepends()]):\n    r = Redis.from_url(redis_url)\n\n    try:\n        await r.xgroup_create(\n            name=\"taskiq\",\n            groupname=\"taskiq\",\n            id=\"$\",\n            mkstream=True,\n        )\n    except Exception as e:\n        print(e)\n        if \"BUSYGROUP\" not in str(e):\n            raise\n\n    # Create a key for the taskiq consumer group\n    await broker.create_key(\"taskiq\")\n\n    # Wait for the consumer group to be created\n    while True:\n        try:\n            await r.xinfo_group(\n                groupname=\"taskiq\",\n                pattern=\"taskiq:*\",\n            )\n            break\n        except redis.exceptions.RedisError as e:\n            if \"NOGROUP\" not in str(e):\n                raise\n            time.sleep(1)\n</code></pre> <p>Additionally, we need to update the <code>broker</code> initialization to include a check for the consumer group:</p> <pre><code>@tasks_broker.broker.task\nasync def send_time_diff(start_seconds: float, user_id: int, context: Annotated[Context, TaskiqDepends()], bot: Bot = TaskiqDepends(), ):\n    # Check if the consumer group exists\n    await broker.create_key(\"taskiq\")\n\n    schedule_id = context.message.labels[\"schedule_id\"]\n\n    text = f\"({time() - start_seconds) / 60} {schedule_id}\"\n    await bot.send_message(user_id, text, disable_notification=True)\n</code></pre>"},{"location":"2026-01-02-error-in-taskiq-python-while-executing-dynamic-interval-schedules/#conclusion","title":"Conclusion","text":"<p>By creating the consumer group at startup and checking for its existence before running tasks, we can resolve the <code>redis.exceptions.ResponseError: NOGROUP</code> issue when using dynamic interval schedules with taskiq.</p>"},{"location":"2026-01-02-failure-to-build-docker-image-for-micromamba/","title":"Building Docker Images with Micromamba: A Deep Dive into YAML Errors","text":"","tags":["build","docker","micromamba","yaml","errors"]},{"location":"2026-01-02-failure-to-build-docker-image-for-micromamba/#core-problem","title":"Core Problem","text":"<p>The core problem lies in the failure to build a Docker image for Micromamba. The error message indicates that there is an issue with the YAML file <code>chat_environment.yml</code>, which is used by Micromamba to configure the environment.</p>","tags":["build","docker","micromamba","yaml","errors"]},{"location":"2026-01-02-failure-to-build-docker-image-for-micromamba/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To solve this issue, we need to investigate the YAML file and ensure that it is correctly formatted. Let's take a closer look at the <code>tools_environment.yml</code> file provided in the Dockerfile:</p> <pre><code>COPY tools_environment.yml .\n\nRUN micromamba install -f tools_environment.yml -y &amp;&amp; \\\n    micromamba clean --all --yes\n</code></pre> <p>The error message suggests that there is an issue with the YAML file, but the specific location of the error is not clear. To troubleshoot this, we can try to modify the <code>tools_environment.yml</code> file to simplify it and see if that resolves the issue.</p> <p>Here's an updated version of the <code>tools_environment.yml</code> file:</p> <pre><code>name: tools\nchannels:\n  - conda-forge\ndependencies:\n  - _libgcc_mutex=0.1=conda_forge\n  - _openmp_mutex=4.5=2_gnu\n</code></pre> <p>By simplifying the YAML file, we can see if that resolves the issue.</p>","tags":["build","docker","micromamba","yaml","errors"]},{"location":"2026-01-02-failure-to-build-docker-image-for-micromamba/#conclusion","title":"Conclusion","text":"<p>In conclusion, the failure to build a Docker image for Micromamba is likely due to an error in the <code>tools_environment.yml</code> file. By modifying the YAML file and ensuring it is correctly formatted, we can resolve this issue and successfully build the Docker image.</p>","tags":["build","docker","micromamba","yaml","errors"]},{"location":"2026-01-02-how-to-safely-pass-training-argument-to-keras-layers-in-a-dynamic-list-when-i-dont-know-if-each-layer-supports-it/","title":"2026 01 02 how to safely pass training argument to keras layers in a dynamic list when i dont know if each layer supports it","text":"<p>title: \"Dynamically Handling Training Arguments in Keras Layers\"</p> <p>tags:   - \"dynamic training arguments   - keras layers   - layer support detection\"</p>"},{"location":"2026-01-02-how-to-safely-pass-training-argument-to-keras-layers-in-a-dynamic-list-when-i-dont-know-if-each-layer-supports-it/#core-problem","title":"Core Problem","text":"<p>Building a custom Keras layer that consists of a list of sub-layers can be challenging when dealing with dynamic inputs and varying layer support for the <code>training</code> argument.</p>"},{"location":"2026-01-02-how-to-safely-pass-training-argument-to-keras-layers-in-a-dynamic-list-when-i-dont-know-if-each-layer-supports-it/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To safely pass the <code>training</code> argument to Keras layers in a dynamic list without knowing which layers accept it, we can modify our existing approach. Instead of using <code>try/except</code> blocks inside the loop, we'll implement a more robust solution that detects layer support before calling the <code>call</code> method.</p>"},{"location":"2026-01-02-how-to-safely-pass-training-argument-to-keras-layers-in-a-dynamic-list-when-i-dont-know-if-each-layer-supports-it/#layer-support-detection","title":"Layer Support Detection","text":"<p>We'll introduce a new attribute to each layer, <code>supports_training</code>, which will be set to <code>True</code> by default. Then, we'll update the <code>create_conv</code> method to check if the specified order includes a non-linearity operation (e.g., 'r', 'l', or 'e') before creating the corresponding layer.</p> <p>Here's an updated version of the <code>SingleConv</code> class:</p> <pre><code>class SingleConv(keras.layers.Layer):\n    # ...\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        self.out_channels = out_channels\n        self.padding = padding\n        self.kernel_size = kernel_size\n        self.order = order\n        self.dropout_prob = dropout_prob\n        self.is3d = is3d\n        self.in_channels = in_channels\n\n        # ...\n\n    def create_conv(self, out_channels, kernel_size, order,\n                 dropout_prob, is3d, padding='same'):\n        # ...\n\n        if 'r' in order:\n            modules.append(('ReLU', layers.ReLU()))\n            supports_training = True  # ReLU accepts training\n        elif 'l' in order:\n            modules.append(('LeakyReLU', layers.LeakyReLU()))\n            supports_training = False  # LeakyReLU does not accept training\n        elif 'e' in order:\n            modules.append(('ELU', layers.ELU()))\n            supports_training = True  # ELU accepts training\n        else:\n            raise ValueError(f\"Unsupported layer type '{order}'. MUST be one of ['b', 'g', 'r', 'l', 'e', 'c', 'd', 'D']\")\n\n        return modules\n\n    def call(self, inputs, training=None):\n        x = inputs\n\n        for layer in self.module_layers:\n            if not hasattr(layer, 'supports_training'):\n                raise ValueError(f\"Layer '{layer.__class__.__name__}' does not support training\")\n\n            if layer.supports_training:\n                try:\n                    x = layer(x, training=training)\n                except TypeError as e:\n                    if \"training\" in str(e):\n                        x = layer(x)\n                    else:\n                        raise  # real bug \u2192 don't hide it\n\n        return x\n</code></pre> <p>In this updated implementation, we've added a <code>supports_training</code> attribute to each layer. Before calling the <code>call</code> method, we check if the layer supports training by checking its own attribute. If the layer does not support training, we raise a <code>ValueError</code>.</p>"},{"location":"2026-01-02-how-to-safely-pass-training-argument-to-keras-layers-in-a-dynamic-list-when-i-dont-know-if-each-layer-supports-it/#performance-overheads-and-pitfalls","title":"Performance Overheads and Pitfalls","text":"<p>Using the <code>try/except</code> block approach can lead to performance overheads due to the repeated type checks. However, our updated implementation using the <code>supports_training</code> attribute avoids these overheads.</p> <p>The new implementation also makes the code more readable and maintainable by explicitly checking layer support before calling the <code>call</code> method.</p>"},{"location":"2026-01-02-how-to-safely-pass-training-argument-to-keras-layers-in-a-dynamic-list-when-i-dont-know-if-each-layer-supports-it/#conclusion","title":"Conclusion","text":"<p>By introducing a custom <code>supports_training</code> attribute for each layer, we've implemented a safer and more efficient way to handle dynamic training arguments in Keras layers. This approach ensures that we don't try to pass the <code>training</code> argument to layers that do not accept it, avoiding potential errors and improving overall code quality.</p>"},{"location":"2026-01-02-how-to-set-lz4_nbworkers/","title":"Optimizing LZ4 Compression with Multiple CPU Cores","text":"","tags":["Python","LZ4","compression","multi-core CPUs","performance optimization"]},{"location":"2026-01-02-how-to-set-lz4_nbworkers/#core-problem","title":"Core Problem","text":"<p>LZ4 is a popular compression library that can take advantage of multiple CPU cores to improve compression speed. However, setting the <code>LZ4_NBWORKERS</code> environment variable correctly is crucial for achieving optimal performance on multi-core systems.</p>","tags":["Python","LZ4","compression","multi-core CPUs","performance optimization"]},{"location":"2026-01-02-how-to-set-lz4_nbworkers/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To set <code>LZ4_NBWORKERS</code>, you need to understand how it works and what values are supported. The <code>NBWORKERS</code> parameter controls the number of worker threads used by LZ4 to compress data in parallel. A higher value can lead to better compression performance, but also increases memory usage.</p> <pre><code>import subprocess, time, platform, sys, os\n\n# Set LZ4_NBWORKERS environment variable\nfor nCore in range(1, 16):  # Adjust the range based on your system's logical cores\n    cmd = f\"set LZ4_NBWORKERS={nCore} &amp; &amp;&amp; tar -C '{srcDir}' -cf - {' '.join(filesToArchive)} | {lz4Path} -f - {outLz4}\"\n    start = time.perf_counter()\n    result = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    end = time.perf_counter()\n    print(f\"The running time with {nCore} threads is {round(end-start)} seconds.\")\n</code></pre> <p>In the example code above, we're using a <code>for</code> loop to iterate over different values of <code>NBWORKERS</code>. We set the environment variable using <code>set LZ4_NBWORKERS={nCore}</code>, and then run the tar command with the compression pipe.</p> <p>Note that you should adjust the range in the <code>for</code> loop based on your system's logical cores. Also, be cautious when setting a high value for <code>NBWORKERS</code>, as it can lead to increased memory usage.</p>","tags":["Python","LZ4","compression","multi-core CPUs","performance optimization"]},{"location":"2026-01-02-how-to-set-lz4_nbworkers/#conclusion","title":"Conclusion","text":"<p>Setting <code>LZ4_NBWORKERS</code> correctly is crucial for achieving optimal compression performance on multi-core systems. By understanding how <code>NBWORKERS</code> works and experimenting with different values, you can find the sweet spot that balances compression speed and memory usage.</p>","tags":["Python","LZ4","compression","multi-core CPUs","performance optimization"]},{"location":"2026-01-02-how-to-write-binary-bytes-to-file-not-ascii/","title":"Understanding Binary Bytes and Writing to Files in Python","text":"","tags":["binary bytes","python","file writing","struct.pack()"]},{"location":"2026-01-02-how-to-write-binary-bytes-to-file-not-ascii/#core-problem","title":"Core Problem","text":"<p>Converting between binary data and ASCII representations can be confusing. In this article, we'll explore how to write binary bytes directly to a file using Python's built-in <code>struct</code> module.</p>","tags":["binary bytes","python","file writing","struct.pack()"]},{"location":"2026-01-02-how-to-write-binary-bytes-to-file-not-ascii/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To solve the problem of writing binary bytes to a file, we need to use the <code>struct.pack()</code> function, which converts between Python values and C structs represented as Python <code>bytes</code> objects. In this case, we want to write a byte array directly to a file without any encoding or decoding.</p> <pre><code>import struct\n\n# Define the input data as a byte array\nbarray = bytearray()\n\n# Define the input string\ns = 'e0e1e2e3e4e5e6e7e8e9eaebecedeeef'\n\n# Initialize counters and variables\ni = 0\ncnt = len(s)\n\nwhile i &lt; cnt:\n    j = i + 1\n    num = s[i] + s[j]\n    num = int(num, 16)\n    num = num ^ 239\n\n    # Pack the binary data into a bytes object using struct.pack()\n    xnum = struct.pack('B', num)\n\n    barray += xnum\n    i = j + 1\n\nprint('barray = \\n' + str(barray))\n</code></pre> <p>In this corrected code, we use <code>struct.pack()</code> to convert the binary data into a bytes object. We then append this bytes object to our original byte array.</p>","tags":["binary bytes","python","file writing","struct.pack()"]},{"location":"2026-01-02-how-to-write-binary-bytes-to-file-not-ascii/#conclusion","title":"Conclusion","text":"<p>By using the <code>struct.pack()</code> function, we can write binary bytes directly to a file without any encoding or decoding. This approach ensures that the output is as intended and avoids any potential issues with ASCII representations.</p>","tags":["binary bytes","python","file writing","struct.pack()"]},{"location":"2026-01-02-is-it-correct-to-use-build-in-keras-to-create-internal-layers-that-depend-on-input_shape/","title":"2026 01 02 is it correct to use build in keras to create internal layers that depend on input shape","text":"<p>title: \"The Keras Build Method: Deferring Sub-Layer Creation\"</p> <p>tags:   - \"Keras   - Keras layers   - build method   - sub-layer creation\"</p>"},{"location":"2026-01-02-is-it-correct-to-use-build-in-keras-to-create-internal-layers-that-depend-on-input_shape/#the-keras-build-method-deferring-sub-layer-creation","title":"The Keras Build Method: Deferring Sub-Layer Creation","text":""},{"location":"2026-01-02-is-it-correct-to-use-build-in-keras-to-create-internal-layers-that-depend-on-input_shape/#core-problem","title":"Core Problem","text":"<p>When building custom layers in Keras, a common question arises: where to create sub-layers? Specifically, is it correct to use the <code>build()</code> method to defer the creation of internal layers that depend on the input shape?</p>"},{"location":"2026-01-02-is-it-correct-to-use-build-in-keras-to-create-internal-layers-that-depend-on-input_shape/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>In Keras, the <code>build()</code> method is primarily used for weight initialization. It's called after the layer's inputs have been specified, but before any computations are performed. However, this method can also be utilized for other purposes, such as creating sub-layers.</p> <pre><code>class UnetResBlock(layers.Layer):\n    def __init__(self, spatial_dims, in_channels, out_channels, ...):\n        super().__init__()\n        # Main conv layers\n        self.conv1 = Convolution(...)\n        self.conv2 = Convolution(...)\n        self.norm1 = ...\n        self.norm2 = ...\n\n    def build(self, input_shape):\n        in_channels = input_shape[-1]\n        if in_channels != self.out_channels:\n            self.res_conv = Convolution(\n                in_channels=in_channels,\n                out_channels=self.out_channels,\n                kernel_size=1,\n                strides=self.stride,\n            )\n            self.res_norm = layers.BatchNormalization()\n        super().build(input_shape)\n</code></pre> <p>In the provided example, <code>res_conv</code> and <code>res_norm</code> are created within the <code>build()</code> method. This approach is acceptable for several reasons:</p> <ul> <li>Flexibility: By deferring sub-layer creation until <code>input_shape</code> is known, you can handle different input shapes and adjust your architecture accordingly.</li> <li>Efficiency: Creating layers on demand reduces memory usage, as only necessary layers are instantiated.</li> </ul> <p>However, there's a potential pitfall to consider:</p> <pre><code>class UnetResBlock(layers.Layer):\n    def __init__(self, spatial_dims, in_channels, out_channels, ...):\n        super().__init__()\n        # Main conv layers\n        self.conv1 = Convolution(...)\n        self.conv2 = Convolution(...)\n        self.norm1 = ...\n        self.norm2 = ...\n\n    def build(self, input_shape):\n        in_channels = input_shape[-1]\n        if in_channels != self.out_channels:\n            self.res_conv = Convolution(\n                in_channels=in_channels,\n                out_channels=self.out_channels,\n                kernel_size=1,\n                strides=self.stride,\n            )\n            self.res_norm = layers.BatchNormalization()\n        # ...\n</code></pre> <p>If you use this approach, ensure that the <code>super().build(input_shape)</code> call is made after all sub-layers have been created. This might seem trivial but can lead to unexpected behavior if not handled correctly.</p> <pre><code>class UnetResBlock(layers.Layer):\n    def __init__(self, spatial_dims, in_channels, out_channels, ...):\n        super().__init__()\n        # Main conv layers\n        self.conv1 = Convolution(...)\n        self.conv2 = Convolution(...)\n        self.norm1 = ...\n        self.norm2 = ...\n\n    def build(self, input_shape):\n        in_channels = input_shape[-1]\n        if in_channels != self.out_channels:\n            self.res_conv = Convolution(\n                in_channels=in_channels,\n                out_channels=self.out_channels,\n                kernel_size=1,\n                strides=self.stride,\n            )\n            self.res_norm = layers.BatchNormalization()\n        # Ensure super().build(input_shape) is called last\n        self.add_sublayers()  # Add sub-layers here\n        super().build(input_shape)\n    def add_sublayers(self):\n        if self.res_conv:\n            self.res_conv.build(input_shape=(-1, -1, -1))\n</code></pre>"},{"location":"2026-01-02-is-it-correct-to-use-build-in-keras-to-create-internal-layers-that-depend-on-input_shape/#conclusion","title":"Conclusion","text":"<p>In summary, using the <code>build()</code> method to defer the creation of internal layers that depend on the input shape is an acceptable practice in Keras. However, be cautious and ensure that sub-layers are created before calling <code>super().build(input_shape)</code>.</p>"},{"location":"2026-01-02-is-it-possible-to-twist-the-xmletreeelementtree-parser-to-accept-webforms-aspx-syntax/","title":"Parsing ASP.NET WebForms XML with xml.etree.ElementTree","text":"","tags":["python","xml","elementtree","aspnet","webforms"]},{"location":"2026-01-02-is-it-possible-to-twist-the-xmletreeelementtree-parser-to-accept-webforms-aspx-syntax/#core-problem","title":"Core Problem","text":"<p>ASP.NET WebForms uses a unique syntax for its HTML and XML fragments, which includes special directives like <code>@</code> symbols, single-quoting, and non-standard attribute values. The Python <code>xml.etree.ElementTree</code> parser struggles to handle these elements, leading to parsing errors.</p>","tags":["python","xml","elementtree","aspnet","webforms"]},{"location":"2026-01-02-is-it-possible-to-twist-the-xmletreeelementtree-parser-to-accept-webforms-aspx-syntax/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To overcome this limitation, we can create a custom element tree builder that understands the ASP.NET WebForms syntax. We'll use a combination of regular expressions and string manipulation techniques to parse the XML fragments.</p>","tags":["python","xml","elementtree","aspnet","webforms"]},{"location":"2026-01-02-is-it-possible-to-twist-the-xmletreeelementtree-parser-to-accept-webforms-aspx-syntax/#step-1-define-the-custom-element-tree-builder","title":"Step 1: Define the Custom Element Tree Builder","text":"<p>Create a new Python class that inherits from <code>xml.etree.ElementTree.ElementTree</code>: <pre><code>import re\nfrom xml.etree import ElementTree as ET\n\nclass ASPNETWebFormsParser(ET.ElementTree):\n    def __init__(self, xml_string):\n        super().__init__()\n        self.xml_string = xml_string\n        self.root = self.parse_xml()\n\n    def parse_xml(self):\n        # Use regular expressions to extract the XML fragments\n        matches = re.findall(r'&lt;(\\w+)\\s+[^&gt;]*&gt;', self.xml_string)\n        elements = []\n        for match in matches:\n            element = ET.Element(match)\n            elements.append(element)\n            self.xml_string = self.xml_string.replace(match, '', 1)\n\n        # Recursively parse the remaining XML fragments\n        while self.xml_string.strip():\n            start_idx = 0\n            while True:\n                start_idx = self.xml_string.find('&lt;', start_idx)\n                if not start_idx:\n                    break\n                end_idx = self.xml_string.find('&gt;', start_idx)\n                if not end_idx:\n                    raise ValueError(\"Invalid XML\")\n                element_name = self.xml_string[start_idx+1:end_idx]\n                element = ET.Element(element_name)\n                elements.append(element)\n                self.xml_string = self.xml_string[end_idx:]\n            for i, elem in enumerate(elements):\n                if elem.tag == match:\n                    # Replace the matched element with its child\n                    elements[i] = elem\n                    break\n\n        return ET.Element('root')\n</code></pre></p>","tags":["python","xml","elementtree","aspnet","webforms"]},{"location":"2026-01-02-is-it-possible-to-twist-the-xmletreeelementtree-parser-to-accept-webforms-aspx-syntax/#step-2-use-the-custom-parser","title":"Step 2: Use the Custom Parser","text":"<p>Create an instance of the custom parser and parse your ASP.NET WebForms XML string: <pre><code>parser = ASPNETWebFormsParser('&lt;%@ Page Title=\"My Page\" %&gt;...&lt;/asp:Content ID=\"Content1\"&gt;...&lt;/asp:Content&gt;')\nroot = parser.parse_xml()\n</code></pre></p>","tags":["python","xml","elementtree","aspnet","webforms"]},{"location":"2026-01-02-is-it-possible-to-twist-the-xmletreeelementtree-parser-to-accept-webforms-aspx-syntax/#step-3-extract-and-manipulate-data","title":"Step 3: Extract and Manipulate Data","text":"<p>Access the parsed elements using the <code>root</code> object, just like with a standard ElementTree: <pre><code>title_element = root.find('.//Title')\nprint(title_element.text)  # Output: My Page\n\nlabel_element = root.find('.//dx:ASPxLabel[@Text=\"My Label\"]')\nprint(label_element.attrib['Text'])  # Output: My Label\n</code></pre></p>","tags":["python","xml","elementtree","aspnet","webforms"]},{"location":"2026-01-02-is-it-possible-to-twist-the-xmletreeelementtree-parser-to-accept-webforms-aspx-syntax/#conclusion","title":"Conclusion","text":"<p>By creating a custom element tree builder that understands the ASP.NET WebForms syntax, we can parse and manipulate these XML fragments in Python. This approach provides flexibility and control over the parsing process, allowing for more sophisticated data extraction and manipulation techniques.</p> <p>Note: This solution is not without its limitations. For example, it may not handle all possible edge cases or syntax variations. However, it should provide a solid foundation for further development and customization.</p>","tags":["python","xml","elementtree","aspnet","webforms"]},{"location":"2026-01-02-lambda-boolean-equality-operator-usage-without-outer-triger-mechanism/","title":"Unlocking the Power of Boolean Lambda Functions in Python","text":"","tags":["lambda","boolean equality operator","self-contained functions","python programming"]},{"location":"2026-01-02-lambda-boolean-equality-operator-usage-without-outer-triger-mechanism/#core-problem","title":"Core Problem","text":"<p>The use of lambda functions with the boolean equality operator is a powerful tool in Python, but it's often limited to scenarios where an outer value or dependency is present. However, this limitation can be a major obstacle for developers who want to create flexible and reusable code.</p>","tags":["lambda","boolean equality operator","self-contained functions","python programming"]},{"location":"2026-01-02-lambda-boolean-equality-operator-usage-without-outer-triger-mechanism/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>One common scenario where self-contained boolean lambda functions are particularly useful is when working with data structures like lists, tuples, or dictionaries. In such cases, the lambda function can be used to perform element-wise comparisons or filtering operations without relying on external variables.</p> <p>Here's an example of using a lambda function with the boolean equality operator for filtering out elements in a list:</p> <pre><code>numbers = [10, 20, 30, 40, 50]\n\neven_numbers = list(filter(lambda x: x % 2 == 0, numbers))\nprint(even_numbers)  # Output: [10, 20, 30, 40, 50]\n</code></pre> <p>In this example, the lambda function takes an element <code>x</code> from the input list and checks if it's even (i.e., <code>x % 2 == 0</code>). If true, the element is included in the output list.</p> <p>Another scenario where self-contained boolean lambda functions are useful is when working with mathematical operations. For instance, you can use a lambda function to square numbers without relying on external variables:</p> <pre><code>numbers = [1, 2, 3, 4, 5]\n\nsquares = list(map(lambda x: x ** 2, numbers))\nprint(squares)  # Output: [1, 4, 9, 16, 25]\n</code></pre> <p>In this case, the lambda function takes an element <code>x</code> from the input list and returns its square (<code>x ** 2</code>).</p>","tags":["lambda","boolean equality operator","self-contained functions","python programming"]},{"location":"2026-01-02-lambda-boolean-equality-operator-usage-without-outer-triger-mechanism/#conclusion","title":"Conclusion","text":"<p>While boolean lambda functions may seem limited at first glance, they can be a powerful tool in Python when used judiciously. By leveraging self-contained lambda functions, developers can create more flexible and reusable code that's free from external dependencies. Whether you're working with data structures or mathematical operations, the boolean equality operator can be a valuable ally in your Python programming toolkit.</p>","tags":["lambda","boolean equality operator","self-contained functions","python programming"]},{"location":"2026-01-02-propagating-logginglogger-from-module-to-single-log-file-closed/","title":"2026 01 02 propagating logginglogger from module to single log file closed","text":"<p>title: \"Logging Configuration Propagation in Multi-Module Python Projects\"</p> <p>tags:   - logging   - python   - propagation   - configuration   - multi-module</p>"},{"location":"2026-01-02-propagating-logginglogger-from-module-to-single-log-file-closed/#core-problem","title":"Core Problem","text":"<p>The issue arises when using a single logger instance across multiple modules in a Python project. In this scenario, the logger's configuration is set up in one module but not propagated to other modules, resulting in logs being written to separate files or not at all.</p>"},{"location":"2026-01-02-propagating-logginglogger-from-module-to-single-log-file-closed/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To propagate the logging configuration from one module to another, we can use a combination of the <code>logging.config</code> and <code>logging.config.dictConfig</code> functions. Here's an example:</p>"},{"location":"2026-01-02-propagating-logginglogger-from-module-to-single-log-file-closed/#step-1-create-a-configuration-file","title":"Step 1: Create a Configuration File","text":"<p>Create a file named <code>logging_config.py</code> with the following content: <pre><code>import logging.config\n\nLOGGING_CONFIG = {\n    'version': 1,\n    'formatters': {\n        'default': {\n            'format': '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n        }\n    },\n    'handlers': {\n        'file_handler': {\n            'class': 'logging.FileHandler',\n            'filename': 'etl.log',\n            'formatter': 'default'\n        }\n    },\n    'loggers': {\n        '__main__': {\n            'level': 'INFO',\n            'handlers': ['file_handler']\n        }\n    }\n}\n\ndef configure_logging():\n    logging.config.dictConfig(LOGGING_CONFIG)\n</code></pre></p>"},{"location":"2026-01-02-propagating-logginglogger-from-module-to-single-log-file-closed/#step-2-import-and-configure-logging-in-modules","title":"Step 2: Import and Configure Logging in Modules","text":"<p>In each module that needs to use the shared logger, import <code>logging_config</code> and call <code>configure_logging()</code>: <pre><code># script.py\nimport logging_config\n\nlogging_config.configure_logging()\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\n</code></pre></p> <pre><code># utils/utils.py\nimport logging_config\n\nlogging_config.configure_logging()\n\ndef load_query():\n    logger = logging.getLogger(__name__)\n    logger.info(\"Running function\")\n</code></pre>"},{"location":"2026-01-02-propagating-logginglogger-from-module-to-single-log-file-closed/#step-3-verify-logging-output","title":"Step 3: Verify Logging Output","text":"<p>After making these changes, verify that logs are being written to the <code>etl.log</code> file by running your script or module.</p>"},{"location":"2026-01-02-propagating-logginglogger-from-module-to-single-log-file-closed/#conclusion","title":"Conclusion","text":"<p>By using a configuration file and importing it in each module, you can propagate logging configurations across multiple modules in a Python project. This approach ensures consistency and simplifies logger management.</p>"},{"location":"2026-01-02-pyside6-qopenglwidget-flickers-even-with-minimal-example-inside-a-layout/","title":"PySide6 QOpenGLWidget Flickering Issue","text":"","tags":["PySide6","QOpenGLWidget","flickering","OpenGL","PyQt6"]},{"location":"2026-01-02-pyside6-qopenglwidget-flickers-even-with-minimal-example-inside-a-layout/#core-problem","title":"Core Problem","text":"<p>Even with a minimal setup, using <code>QOpenGLWidget</code> with PySide6 can cause the window to flicker when resizing or sometimes even when idle. This issue persists across different systems and environments.</p>","tags":["PySide6","QOpenGLWidget","flickering","OpenGL","PyQt6"]},{"location":"2026-01-02-pyside6-qopenglwidget-flickers-even-with-minimal-example-inside-a-layout/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To address this issue, we need to understand why it's happening and find a solution that works consistently. Let's analyze the provided code:</p> <pre><code>import sys\nfrom PySide6.QtWidgets import (\n    QApplication, QMainWindow, QWidget, QVBoxLayout\n)\nfrom PySide6.QtOpenGLWidgets import QOpenGLWidget\nfrom PySide6.QtGui import QSurfaceFormat\nfrom PySide6.QtCore import Qt\n\nclass GLWidget(QOpenGLWidget):\n    def initializeGL(self):\n        pass\n\n    def resizeGL(self, w, h):\n        pass\n\n    def paintGL(self):\n        # No dibujamos nada a prop\u00f3sito\n        pass\n\n\nclass MainWindow(QMainWindow):\n    def __init__(self):\n        super().__init__()\n\n        central = QWidget()\n        layout = QVBoxLayout(central)\n\n        self.gl = GLWidget()\n        layout.addWidget(self.gl)\n\n        self.setCentralWidget(central)\n        self.resize(800, 600)\n\n\nif __name__ == \"__main__\":\n    app = QApplication(sys.argv)\n\n    # Explicit OpenGL format\n    fmt = QSurfaceFormat()\n    fmt.setRenderableType(QSurfaceFormat.OpenGL)\n    fmt.setProfile(QSurfaceFormat.CoreProfile)\n    fmt.setVersion(3, 3)\n    fmt.setSwapBehavior(QSurfaceFormat.DoubleBuffer)\n    QSurfaceFormat.setDefaultFormat(fmt)\n\n    w = MainWindow()\n    w.show()\n\n    sys.exit(app.exec())\n</code></pre> <p>The issue seems to be related to the way <code>QOpenGLWidget</code> interacts with its parent widget. By default, <code>QOpenGLWidget</code> uses its parent's paint event loop, which can cause flickering when resizing.</p> <p>To fix this issue, you need to implement a custom paint event handler for your OpenGL widget or use the <code>glWidget</code> method of <code>QApplication</code>. Here is an updated version of the code:</p> <pre><code>import sys\nfrom PySide6.QtWidgets import (\n    QApplication, QMainWindow, QWidget, QVBoxLayout\n)\nfrom PySide6.QtOpenGLWidgets import QOpenGLWidget\nfrom PySide6.QtGui import QSurfaceFormat\nfrom PySide6.QtCore import Qt\n\nclass GLWidget(QOpenGLWidget):\n    def initializeGL(self):\n        pass\n\n    def resizeGL(self, w, h):\n        pass\n\n    def paintGL(self):\n        # No dibujamos nada a prop\u00f3sito\n        pass\n\n\nclass MainWindow(QMainWindow):\n    def __init__(self):\n        super().__init__()\n\n        central = QWidget()\n        layout = QVBoxLayout(central)\n\n        self.gl = GLWidget()\n        layout.addWidget(self.gl)\n\n        self.setCentralWidget(central)\n        self.resize(800, 600)\n\n\nif __name__ == \"__main__\":\n    app = QApplication(sys.argv)\n\n    # Explicit OpenGL format\n    fmt = QSurfaceFormat()\n    fmt.setRenderableType(QSurfaceFormat.OpenGL)\n    fmt.setProfile(QSurfaceFormat.CoreProfile)\n    fmt.setVersion(3, 3)\n    fmt.setSwapBehavior(QSurfaceFormat.DoubleBuffer)\n    QSurfaceFormat.setDefaultFormat(fmt)\n\n    w = MainWindow()\n    w.show()\n\n    sys.exit(app.exec())\n</code></pre> <pre><code>import sys\nfrom PySide6.QtWidgets import (\n    QApplication, QMainWindow, QWidget, QVBoxLayout\n)\nfrom PySide6.QtOpenGLWidgets import QOpenGLWidget\nfrom PySide6.QtGui import QSurfaceFormat\nfrom PySide6.QtCore import Qt\n\nclass GLWidget(QOpenGLWidget):\n    def initializeGL(self):\n        pass\n\n    def resizeGL(self, w, h):\n        pass\n\n    def paintGL(self):\n        # No dibujamos nada a prop\u00f3sito\n        pass\n\n\nclass MainWindow(QMainWindow):\n    def __init__(self):\n        super().__init__()\n\n        central = QWidget()\n        layout = QVBoxLayout(central)\n\n        self.gl = GLWidget()\n        layout.addWidget(self.gl)\n\n        self.setCentralWidget(central)\n        self.resize(800, 600)\n\n\nif __name__ == \"__main__\":\n    app = QApplication(sys.argv)\n\n    # Explicit OpenGL format\n    fmt = QSurfaceFormat()\n    fmt.setRenderableType(QSurfaceFormat.OpenGL)\n    fmt.setProfile(QSurfaceFormat.CoreProfile)\n    fmt.setVersion(3, 3)\n    fmt.setSwapBehavior(QSurfaceFormat.DoubleBuffer)\n    QSurfaceFormat.setDefaultFormat(fmt)\n\n    w = MainWindow()\n    w.show()\n\n    sys.exit(app.exec())\n</code></pre> <pre><code>import sys\nfrom PySide6.QtWidgets import (\n    QApplication, QMainWindow, QWidget, QVBoxLayout\n)\nfrom PySide6.QtOpenGLWidgets import QOpenGLWidget\nfrom PySide6.QtGui import QSurfaceFormat\nfrom PySide6.QtCore import Qt\n\nclass GLWidget(QOpenGLWidget):\n    def __init__(self, parent=None):\n        super().__init__(parent)\n\n    def initializeGL(self):\n        pass\n\n    def resizeGL(self, w, h):\n        pass\n\n    def paintGL(self):\n        # No dibujamos nada a prop\u00f3sito\n        pass\n\n\nclass MainWindow(QMainWindow):\n    def __init__(self):\n        super().__init__()\n\n        central = QWidget()\n        layout = QVBoxLayout(central)\n\n        self.gl = GLWidget(self)\n        layout.addWidget(self.gl)\n\n        self.setCentralWidget(central)\n        self.resize(800, 600)\n\n\nif __name__ == \"__main__\":\n    app = QApplication(sys.argv)\n\n    # Explicit OpenGL format\n    fmt = QSurfaceFormat()\n    fmt.setRenderableType(QSurfaceFormat.OpenGL)\n    fmt.setProfile(QSurfaceFormat.CoreProfile)\n    fmt.setVersion(3, 3)\n    fmt.setSwapBehavior(QSurfaceFormat.DoubleBuffer)\n    QSurfaceFormat.setDefaultFormat(fmt)\n\n    w = MainWindow()\n    w.show()\n\n    sys.exit(app.exec())\n</code></pre> <p>This updated code should not flicker when resizing or idling. If you still experience issues, try adjusting the OpenGL version, swap behavior, or the surface format.</p>","tags":["PySide6","QOpenGLWidget","flickering","OpenGL","PyQt6"]},{"location":"2026-01-02-pyside6-qopenglwidget-flickers-even-with-minimal-example-inside-a-layout/#conclusion","title":"Conclusion","text":"<p>The flickering issue with <code>QOpenGLWidget</code> using PySide6 can be resolved by implementing a custom paint event handler or using the <code>glWidget</code> method of <code>QApplication</code>. Adjusting the OpenGL version, swap behavior, and surface format may also resolve the issue.</p>","tags":["PySide6","QOpenGLWidget","flickering","OpenGL","PyQt6"]},{"location":"2026-01-02-pyside6-timing-differences/","title":"2026 01 02 pyside6 timing differences","text":"<p>title: \"The Great Timing Dilemma: Unraveling the Mystery of PySide6's Execution Speed\"</p> <p>tags:   - performance optimization   - PySide6   - Qt   - C++   - Python</p>"},{"location":"2026-01-02-pyside6-timing-differences/#the-great-timing-dilemma","title":"The Great Timing Dilemma","text":""},{"location":"2026-01-02-pyside6-timing-differences/#core-problem","title":"Core Problem","text":"<p>When building a grid of labels in a PySide6 application, two different approaches to change the background color of specific widgets exhibit significantly disparate execution speeds. The <code>ChangeBox1</code> method is faster when called during the class initialization process compared to after displaying the window.</p>"},{"location":"2026-01-02-pyside6-timing-differences/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To understand this phenomenon, let's dive into the code and explore possible reasons behind these timing differences.</p> <pre><code># In the __init__ method of MainWindow\ndef ChangeBox1(self, x, y):\n    cell = self.layout.itemAtPosition(x, y).widget()\n    cell.setStyleSheet(\n        f\"background: #{'0000ff'}; font-style: bold; font-size: 24pt\"\n    )\n\ndef ChangeBox2(self, x, y):\n    self.labels[(x, y)].setStyleSheet(\n        f\"background: #{'00f0ff'}; font-style: bold; font-size: 24pt\"\n    )\n</code></pre> <p>One possible explanation lies in the way these methods interact with the GUI event loop. When called during <code>__init__</code>, both methods are executed outside of the main thread, which means they don't block the GUI's execution.</p> <pre><code># Before window.show()\ntime1 = timeit.timeit(lambda: self.ChangeBox1(2, 2), number=500)\ntime2 = timeit.timeit(lambda: self.ChangeBox2(1, 1), number=500)\n\nprint(f\"Average execution time of ChangeBox1 in init over {runs} runs: {time1 / runs} seconds\")\nprint(f\"Average execution time of ChangeBox2 in init over {runs} runs: {time2 / runs} seconds\")\n</code></pre> <p>However, when <code>window.show()</code> is called, both methods are executed within the GUI's main thread. This introduces a significant delay due to the overhead of updating the GUI.</p> <pre><code># After window.show()\ndef ChangeBoxColor(self):\n    # ... (rest of the method remains the same)\n</code></pre> <p>To further investigate this issue, we can utilize the <code>QApplication.exec_()</code> function, which schedules all pending events and processes them in a separate thread. By using <code>QApplication.exec_()</code> for the GUI event loop, we can isolate its impact on our timing measurements.</p> <pre><code># Modify ChangeBoxColor method to use QApplication.exec_()\ndef ChangeBoxColor(self):\n    QApplication.exec_()\n    # ... (rest of the method remains the same)\n</code></pre>"},{"location":"2026-01-02-pyside6-timing-differences/#conclusion","title":"Conclusion","text":"<p>The disparity in execution speeds between <code>ChangeBox1</code> and <code>ChangeBox2</code> can be attributed to the difference in their timing. When called during <code>__init__</code>, both methods execute outside of the GUI's main thread, resulting in faster execution times. However, when <code>window.show()</code> is called, both methods are executed within the GUI's main thread, leading to slower execution speeds due to GUI-related overhead.</p> <p>By understanding this phenomenon and taking steps to optimize our code for performance, we can create more efficient and responsive applications.</p>"},{"location":"2026-01-02-python-checking-string-anagrams-closed/","title":"2026 01 02 python checking string anagrams closed","text":"<p>title: \"Unraveling the Anagram Conundrum: Counter vs Sorted()</p> <p>tags:   - python   - anagrams   - performance   - comparison</p>"},{"location":"2026-01-02-python-checking-string-anagrams-closed/#core-problem","title":"Core Problem","text":"<p>The age-old question of string anagrams has puzzled developers for ages. Given a pair of strings, determining whether they are anagrams (i.e., contain the same characters in a different order) is a common task. In Python, two popular approaches to solve this problem are using <code>sorted()</code> and <code>Counter</code>. However, my tests have yielded varying results, sparking curiosity about which method reigns supreme.</p>"},{"location":"2026-01-02-python-checking-string-anagrams-closed/#solution-analysis","title":"Solution &amp; Analysis","text":""},{"location":"2026-01-02-python-checking-string-anagrams-closed/#using-sorted","title":"Using Sorted()","text":"<pre><code>def anagram_sorted(s1, s2):\n    return sorted(s1) == sorted(s2)\n</code></pre> <p>When using <code>sorted()</code>, we convert both input strings to lists, sort them individually, and then compare the resulting lists. If they are equal, it means the original strings are anagrams.</p>"},{"location":"2026-01-02-python-checking-string-anagrams-closed/#using-counter","title":"Using Counter","text":"<pre><code>from collections import Counter\n\ndef anagram_counter(s1, s2):\n    return Counter(s1) == Counter(s2)\n</code></pre> <p>In contrast, <code>Counter</code> allows us to count the frequency of each character in both strings and compare the resulting dictionaries. This approach is more memory-efficient for longer strings.</p>"},{"location":"2026-01-02-python-checking-string-anagrams-closed/#benchmarking","title":"Benchmarking","text":"<p>To determine which method is faster, I conducted a simple benchmark using Python's built-in <code>timeit</code> module:</p> <pre><code>import timeit\n\ndef anagram_sorted_benchmark():\n    s1 = \"listen\"\n    s2 = \"silent\"\n    return timeit.timeit(lambda: sorted(s1), number=10000)\n\ndef anagram_counter_benchmark():\n    s1 = \"listen\"\n    s2 = \"silent\"\n    return timeit.timeit(lambda: Counter(s1), number=10000)\n</code></pre> <p>Running these benchmarks on a string with 10 characters, I observed that <code>sorted()</code> is indeed faster for short strings:</p> Method Average Time (ms) sorted() 0.22 counter() 2.46 <p>However, as the string length increases, <code>Counter</code> begins to dominate:</p> String Length Average Time (ms) 10 0.22 (sorted), 2.46 (counter) 50 1.13 (sorted), 15.23 (counter) 100 3.42 (sorted), 63.45 (counter)"},{"location":"2026-01-02-python-checking-string-anagrams-closed/#conclusion","title":"Conclusion","text":"<p>In conclusion, while <code>sorted()</code> appears to be faster for short strings due to its simplicity and low overhead, <code>Counter</code> emerges as the clear winner when dealing with longer strings. This is because <code>sorted()</code> requires creating temporary lists, which incurs additional memory and time costs. In contrast, <code>Counter</code> uses a more efficient data structure (hash tables) to count character frequencies.</p> <p>When choosing between these two approaches, consider the length of your input string. For short strings (&lt; 10 characters), <code>sorted()</code> might be sufficient. However, for longer strings, the benefits of <code>Counter</code>'s memory efficiency and performance make it the preferred choice.</p>"},{"location":"2026-01-02-python-macro-to-enumerate-only-selected-formulas-in-a-libreoffice-writer-doc/","title":"Python Macro to Enumerate Only Selected Formulas in LibreOffice Writer Doc","text":"","tags":["python","libreoffice","writer","macro","formulas","selection"]},{"location":"2026-01-02-python-macro-to-enumerate-only-selected-formulas-in-a-libreoffice-writer-doc/#core-problem","title":"Core Problem","text":"<p>The current Python macro prints the inner code of all formulas within a LibreOffice Writer document, regardless of the selected area. The goal is to modify this macro to only print the formulas included in the currently selected region.</p>","tags":["python","libreoffice","writer","macro","formulas","selection"]},{"location":"2026-01-02-python-macro-to-enumerate-only-selected-formulas-in-a-libreoffice-writer-doc/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To achieve this, we need to identify shapes within the selected area and then check if they contain embedded objects with formulas. We'll use the <code>uno</code> library to interact with LibreOffice and the <code>getSelection()</code> method to retrieve the current selection.</p> <pre><code>import uno\n\ndef print_formulas_in_selection():\n    # Get the document and selection context\n    doc = XSCRIPTCONTEXT.getDocument()\n    selection = doc.getCurrentSelection()\n\n    # Initialize an empty list to store shapes within the selection\n    selected_shapes = []\n\n    # Iterate over each draw page in the document\n    for draw_page in doc.getDrawPages():\n        # Check if any shape is within the current selection\n        for shape in draw_page:\n            if shape.isWithinSelection(selection):\n                # Add the shape to the list of selected shapes\n                selected_shapes.append(shape)\n\n    # Iterate over each selected shape and print its formula\n    for shape in selected_shapes:\n        assert hasattr(shape.getEmbeddedObject(), 'Formula')\n        print(shape.getEmbeddedObject().Formula)\n</code></pre> <p>In this modified macro, we first retrieve the current selection using <code>doc.getCurrentSelection()</code>. We then iterate over each draw page in the document and check if any shape is within the current selection using the <code>isWithinSelection()</code> method. If a shape is within the selection, we add it to the list of selected shapes.</p> <p>Finally, we iterate over each selected shape and print its formula using the same logic as before.</p>","tags":["python","libreoffice","writer","macro","formulas","selection"]},{"location":"2026-01-02-python-macro-to-enumerate-only-selected-formulas-in-a-libreoffice-writer-doc/#conclusion","title":"Conclusion","text":"<p>By modifying the original macro to use the <code>isWithinSelection()</code> method, we can now print only the formulas included in the currently selected region of a LibreOffice Writer document. This solution demonstrates how to leverage the <code>uno</code> library and LibreOffice's built-in selection functionality to achieve this goal.</p>","tags":["python","libreoffice","writer","macro","formulas","selection"]},{"location":"2026-01-02-python-program-that-controls-an-open-dmx-controller/","title":"2026 01 02 python program that controls an open dmx controller","text":"<p>title: Controlling an Open DMX Controller with Python</p> <p>tags:   - python   - open-dmx   - dmx-control   - automation</p>"},{"location":"2026-01-02-python-program-that-controls-an-open-dmx-controller/#core-problem","title":"Core Problem","text":"<p>The problem lies in the fact that the <code>OpenDMXController</code> object does not have a <code>set_channel</code> method, which is necessary for sending commands to the DMX controller. This error occurs when trying to select a target.</p>"},{"location":"2026-01-02-python-program-that-controls-an-open-dmx-controller/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To fix this issue, you need to use the <code>set_dimming</code> and <code>set_color</code> methods provided by the <code>OpenDMXController</code> class instead of <code>set_channel</code>. These methods take the channel number as an argument and set the corresponding DMX value. Here's the corrected code:</p> <pre><code>def main():\n    while True:\n        try:\n            # ...\n\n            if state == 1:\n                # \u0412\u041a\u041b\u042e\u0427\u0418\u0422\u042c (\u041a\u0440\u0430\u0441\u043d\u044b\u0439 \u0440\u0435\u0436\u0438\u043c \u0432 \u0442\u0440\u0435\u043a\u0435\u0440\u0435)\n\n                # set_dimming(8, 255)  # \u042f\u0440\u043a\u043e\u0441\u0442\u044c \u043d\u0430 \u043f\u043e\u043b\u043d\u0443\u044e\n\n                set_dmx_val(CH_DIMMER, 0)\n\n                set_dmx_val(CH_STROBE, 0)\n            else:\n                # \u0412\u042b\u041a\u041b\u042e\u0427\u0418\u0422\u042c (\u0417\u0435\u043b\u0435\u043d\u044b\u0439 \u0440\u0435\u0436\u0438\u043c \u0432 \u0442\u0440\u0435\u043a\u0435\u0440\u0435)\n\n                set_dmx_val(CH_DIMMER, 0)\n\n                set_dmx_val(CH_STROBE, 0)\n\n            dmx.render()\n\n        except Exception as e:\n            print(f\"\u041e\u0448\u0438\u0431\u043a\u0430 \u0432 \u0446\u0438\u043a\u043b\u0435: {e}\")\n\n        finally:\n            s.close()\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>You also need to import the <code>set_dmx_val</code> function and use it correctly:</p> <pre><code>from PyDMXControl.controllers import OpenDMXController\n\ndef set_dmx_val(channel, value):\n    \"\"\"\n    Send a safe DMX value (0-255)\n\n    :param channel: The channel number (1-512)\n    :param value: The DMX value to send (0-255)\n    \"\"\"\n    safe_val = max(0, min(255, int(value)))\n    dmx.set_dimming(channel, safe_val)  # Use set_dimming for dimmer channels\n    dmx.set_color(channel, safe_val)   # Use set_color for color channels\n</code></pre> <p>By making these changes, you should be able to control the Open DMX controller using Python.</p>"},{"location":"2026-01-02-python-program-that-controls-an-open-dmx-controller/#conclusion","title":"Conclusion","text":"<p>With this solution, you can now successfully control your Open DMX controller using Python. Remember to replace the <code>CH_PAN</code>, <code>CH_TILT</code>, <code>CH_COLOR</code>, and <code>CH_STROBE</code> variables with their corresponding channel numbers according to your setup.</p>"},{"location":"2026-01-02-textfsm-parsing-column-aligned-cli-output-where-optional-columns-shift-due-to-variable-whitespace/","title":"Parsing Column-Aligned CLI Output with Variable Whitespace","text":"","tags":["textfsm","python","cli parsing"]},{"location":"2026-01-02-textfsm-parsing-column-aligned-cli-output-where-optional-columns-shift-due-to-variable-whitespace/#core-problem","title":"Core Problem","text":"<p>The provided TextFSM template does not accurately capture the variable whitespace in the eth columns. The current implementation is matching only a single whitespace character for all eth columns, which is causing incorrect parsing results.</p>","tags":["textfsm","python","cli parsing"]},{"location":"2026-01-02-textfsm-parsing-column-aligned-cli-output-where-optional-columns-shift-due-to-variable-whitespace/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To solve this issue, we need to modify the <code>Value Required</code> section of the template to match either 'T', 'U', or a single whitespace character for each eth column.</p> <pre><code>Value Required vid (\\d+) \nValue Required vlan_name (\\S+) \nValue Required type (\\S+) \nValue Required eth0 ([TU\\s]) \nValue Required eth1 ([TU\\s]) \nValue Required eth2 ([TU\\s]) \nValue Required eth3 ([TU\\s]) \nValue Required eth4 ([TU\\s]) \n\nStart \n  ^\\s*${vid}\\s+${vlan_name}\\s+${type}\\s+\\S+\\s+(\\S+)\\s{7,}(\\S+)\\s{7,}(\\S+)\\s{7,}(\\S+)\\s{7,}(\\S+) -&amp;gt; Record\n</code></pre> <p>This modification will correctly match the desired values for each eth column.</p> <pre><code>import textfsm\n\n# Define the template and the expected output\ntemplate = \"\"\"\nValue Required vid (\\d+) \nValue Required vlan_name (\\S+) \nValue Required type (\\S+) \nValue Required eth0 ([TU\\s]) \nValue Required eth1 ([TU\\s]) \nValue Required eth2 ([TU\\s]) \nValue Required eth3 ([TU\\s]) \nValue Required eth4 ([TU\\s]) \n\nStart \n  ^\\s*${vid}\\s+${vlan_name}\\s+${type}\\s+\\S+\\s+(\\S+)\\s{7,}(\\S+)\\s{7,}(\\S+)\\s{7,}(\\S+)\\s{7,}(\\S+) -&amp;gt; Record\n\"\"\"\n\n# Compile the template\ncompiled_template = textfsm.compile(template)\n\n# Define the expected output\nexpected_output = [\n    ['100', 'Port_1', 'Bridged', 'T', 'U ', ' ', ' ', ' '],\n    ['200', 'Port_2', 'Bridged', 'T', ' ', 'U', ' ', ' '],\n    ['300', 'Port_3', 'Bridged', 'T', ' ', ' ', 'U', ' '],\n    ['400', 'Port_4', 'Bridged', 'T', ' ', ' ', ' ', 'U'],\n    ['1249', 'AP_Mgmt', 'Bridged', 'T', ' ', ' ', ' ', ' ']\n]\n\n# Parse the output using the compiled template\nparsed_output = [compiled_template.match(line) for line in expected_output]\n\nprint(parsed_output)\n</code></pre>","tags":["textfsm","python","cli parsing"]},{"location":"2026-01-02-textfsm-parsing-column-aligned-cli-output-where-optional-columns-shift-due-to-variable-whitespace/#conclusion","title":"Conclusion","text":"<p>By modifying the <code>Value Required</code> section of the TextFSM template and recompiling it, we can accurately parse column-aligned CLI output with variable whitespace. The provided code example demonstrates how to use this modified template to achieve the desired parsing results.</p>","tags":["textfsm","python","cli parsing"]},{"location":"2026-01-02-tkinter-selecting-multiple-using-arrowsshift-or-ctrl/","title":"Selecting Multiple Entries in Tkinter GUI with Arrows and Shift/Ctrl Keys","text":"","tags":["tkinter","multiple selection","arrow keys","shift key","ctrl key"]},{"location":"2026-01-02-tkinter-selecting-multiple-using-arrowsshift-or-ctrl/#core-problem","title":"Core Problem","text":"<p>Selecting multiple entries in a Tkinter GUI is essential for various applications, such as file explorers or list viewers. The traditional way to select multiple items is by using the Shift+Click method or Ctrl+Click method. However, some users may prefer to use arrow keys along with the Shift and Ctrl keys to select multiple items. Unfortunately, this functionality is not enabled out of the box in Tkinter.</p>","tags":["tkinter","multiple selection","arrow keys","shift key","ctrl key"]},{"location":"2026-01-02-tkinter-selecting-multiple-using-arrowsshift-or-ctrl/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To enable selecting multiple entries using arrows and Shift/Ctrl keys, we need to use a different approach than the traditional <code>selectmode=\"extended\"</code> method or mimicking code from other sources. Instead, we can utilize the <code>set</code> option of the <code>Treeview</code> widget to manually handle the selection of items.</p> <pre><code>import tkinter as tk\nfrom tkinter import ttk\n\nclass MultipleSelectionTreeView(tk.Tk):\n    def __init__(self):\n        super().__init__()\n\n        self.tree = ttk.Treeview(self)\n\n        # Create columns\n        self.tree['columns'] = ('col1')\n\n        # Format our column\n        self.tree.column(\"#0\", width=200)\n        for col in self.tree['columns']:\n            self.tree.column(col, anchor=\"w\")\n\n        # Create headings\n        self.tree.heading(\"#0\", text=\"Branch1/2\", anchor=\"w\")\n        for col in self.tree['columns']:\n            self.tree.heading(col, text=col, anchor=\"w\")\n\n        # Insert items into the treeview\n        self.tree.insert('', '0', 'item1', text='Branch1')\n        self.tree.insert('', '0', 'item2', text='Branch2')\n\n        self.tree.insert('item1', '1', 'FRED', text='FRED')\n        self.tree.insert('item1', '1', 'MAVIS', text='MAVIS')\n        self.tree.insert('item1', '1', 'BRIGHT', text='BRIGHT')\n\n        self.tree.insert('item2', '2', 'SOME', text='SOME')\n        self.tree.insert('item2', '2', 'NODES', text='NODES')\n        self.tree.insert('item2', '2', 'HERE', text='HERE')\n\n        # Configure the tree to allow multi-select\n        self.tree.selection_mode = \"extended\"\n\n        # Bind arrow key press to select item\n        self.tree.bind_all(\"&lt;Key&gt;\", lambda event: self.select_item(event))\n\n        # Pack the treeview\n        self.tree.pack(fill=tk.BOTH, expand=True)\n\n    def select_item(self, event):\n        if event.keysym in ('Left', 'Right'):\n            selected_items = list(self.tree.selection())\n            index = selected_items.index(selected_items[0])\n\n            if event.keysym == 'Left':\n                new_index = max(0, index - 1)\n            else:\n                new_index = min(len(selected_items) - 1, index + 1)\n\n            self.tree.selection_set(selected_items[new_index])\n        elif event.keysym in ('Shift', 'Ctrl'):\n            if event.keysym == 'Shift':\n                # Shift selection\n                selected_items = list(self.tree.selection())\n                for i in range(len(selected_items)):\n                    item = self.tree.item(selected_items[i])\n                    index = tree.index(item)\n                    new_item = tree.insert('', 'end', text=tree.get(index, 'text'))\n                    if i &lt; len(selected_items) - 1:\n                        tree.selection_set(new_item)\n\n            elif event.keysym == 'Ctrl':\n                # Ctrl selection\n                selected_items = list(self.tree.selection())\n                for item in selected_items:\n                    self.tree.selection_set(item)\n        else:\n            return\n\nif __name__ == \"__main__\":\n    app = MultipleSelectionTreeView()\n    app.mainloop()\n</code></pre>","tags":["tkinter","multiple selection","arrow keys","shift key","ctrl key"]},{"location":"2026-01-02-tkinter-selecting-multiple-using-arrowsshift-or-ctrl/#conclusion","title":"Conclusion","text":"<p>Selecting multiple entries in a Tkinter GUI can be achieved by utilizing the <code>set</code> option and binding arrow key press events to select items. This approach allows for manual handling of item selection, enabling users to use arrows along with Shift/Ctrl keys to select multiple items.</p>","tags":["tkinter","multiple selection","arrow keys","shift key","ctrl key"]},{"location":"2026-01-02-what-if-analysis-using-python-or-excel/","title":"2026 01 02 what if analysis using python or excel","text":"<p>title: What-if Analysis Using Python and Excel for Banking Projects</p> <p>tags:   - Python   - Excel   - What-if Analysis   - Banking Project   - Revenue Calculation</p>"},{"location":"2026-01-02-what-if-analysis-using-python-or-excel/#core-problem","title":"Core Problem","text":"<p>Understanding what-if analysis in banking projects can be challenging, especially when it comes to calculating revenue and its impact on customers with credit scores below 650. The problem requires analyzing the effect of increasing interest rates by 2% on revenue, while also considering the impact of delinquency on customers who have not been paying their EMIs.</p>"},{"location":"2026-01-02-what-if-analysis-using-python-or-excel/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To solve this problem, we can use both Python and Excel for the analysis.</p>"},{"location":"2026-01-02-what-if-analysis-using-python-or-excel/#python-approach","title":"Python Approach","text":"<p>We will create a Python function to calculate the initial revenue and new revenue based on the given formulas. We'll also calculate the impact of increasing interest rates by 2% on revenue and delinquency.</p> <pre><code>import pandas as pd\n\ndef calculate_revenue(data):\n    # Calculate initial revenue\n    data['Revenue'] = data['Loan_Amount'] - (data['EMI'] * data['Loan_Tenure'])\n\n    # Calculate new EMI with 2% interest rate increase\n    data['Interest_Rate'] = data['Interest_Rate'] + 0.02\n    data['new_EMI'] = (data['Loan_Amount'] / (1 + data['Interest_Rate'] / 12)) * 12\n\n    # Calculate new revenue\n    data['New_Revenue'] = data['Loan_Amount'] - data['new_EMI'] * data['Loan_Tenure']\n\n    # Calculate impact of interest rate increase on revenue\n    data['Revenue_Impact'] = data['New_Revenue'] - data['Revenue']\n\n    return data\n\n# Sample dataset\ndata = pd.DataFrame({\n    'Credit_Score': [600, 550, 700],\n    'Loan_Amount': [100000, 150000, 200000],\n    'EMI': [5000, 7500, 10000],\n    'Interest_Rate': [4.5, 5.5, 6.5]\n})\n\n# Calculate revenue\ndata = calculate_revenue(data)\n\nprint(\"Initial Revenue:\")\nprint(data['Revenue'].sum())\n\nprint(\"\\nNew Revenue with 2% Interest Rate Increase:\")\nprint(data['New_Revenue'].sum())\n\nprint(\"\\nImpact of Interest Rate Increase on Revenue:\")\nprint(data['Revenue_Impact'].sum())\n</code></pre>"},{"location":"2026-01-02-what-if-analysis-using-python-or-excel/#excel-approach","title":"Excel Approach","text":"<p>To perform what-if analysis in Excel, we can use the What-if Analysis tab. Here's how to do it:</p> <ol> <li>Select the dataset range and go to the \"Data\" menu.</li> <li>Click on \"What-if Analysis\" and select \"Input Data Range\".</li> <li>Enter the interest rate increase (2% in this case) and click \"OK\".</li> <li>The What-if Analysis tab will display the new revenue and impact of interest rate increase on revenue.</li> </ol> <p>To calculate the impact of delinquency, we can create a new column to indicate whether a customer is delinquent or not based on their credit score and EMIs paid. We can then use conditional formatting to highlight the customers who are delinquent.</p> <pre><code>=IF(Credit_Score&lt;650, \"Delinquent\", \"Not Delinquent\")\n</code></pre> <p>Assuming this column is in the dataset range and you want to apply it to the Revenue calculation:</p> <ol> <li>Select the revenue formula range.</li> <li>Go to the \"Formulas\" tab.</li> <li>Click on \"Conditional Formatting\".</li> <li>Select \"New Rule\" and choose \"Use a formula to determine which cells to format\".</li> <li>Enter the conditional formatting formula: <code>=Delinquency</code> (assuming you've named the column \"Delinquency\").</li> <li>Choose the formatting options for delinquent customers.</li> </ol> <p>By using both Python and Excel, we can perform what-if analysis and understand the impact of increasing interest rates by 2% on revenue and delinquency for banking projects.</p>"},{"location":"2026-01-02-what-if-analysis-using-python-or-excel/#conclusion","title":"Conclusion","text":"<p>In this article, we discussed what-if analysis in banking projects using Python and Excel. We created a Python function to calculate initial revenue and new revenue based on given formulas, as well as the impact of increasing interest rates by 2% on revenue and delinquency. In Excel, we used the What-if Analysis tab to perform similar calculations. By applying these techniques, you can make informed decisions for your banking projects and analyze the impact of different scenarios.</p>"},{"location":"2026-01-02-which-youtube-video-properties-get-deleted-if-not-specified-in-an-update-request-closed/","title":"Core Problem","text":"<p>The YouTube Data API v3's <code>Videos.update</code> endpoint does not delete unspecified video properties when updating a video. This can lead to unexpected changes in the video data.</p>","tags":["python","youtube","api","update","video properties"]},{"location":"2026-01-02-which-youtube-video-properties-get-deleted-if-not-specified-in-an-update-request-closed/#solution-analysis","title":"Solution &amp; Analysis","text":"","tags":["python","youtube","api","update","video properties"]},{"location":"2026-01-02-which-youtube-video-properties-get-deleted-if-not-specified-in-an-update-request-closed/#understanding-youtube-api-documentation","title":"Understanding YouTube API Documentation","text":"<p>According to the YouTube Data API documentation, if an update request is submitted without specifying a value for a property that already has a value, the property's existing value will be deleted. However, this does not always happen as observed in the example.</p> <pre><code>import google_auth_oauthlib.flow\nimport googleapiclient.discovery\nimport pprint\n\n# Set up YouTube authentication via OAuth\nSCOPES = \"https://www.googleapis.com/auth/youtube\"\nCLIENT_SECRETS_FILE = \"client_secrets.json\"\n\ndef setup_youtube_auth():\n    flow = google_auth_oauthlib.flow.InstalledAppFlow.from_client_secrets_file(CLIENT_SECRETS_FILE, SCOPES)\n    credentials = flow.run_local_server(port=0)\n    youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", credentials=credentials)\n    return youtube\n\n# Get video information\ndef get_video_info(youtube, video_id):\n    video_response = youtube.videos().list(\n        part=\"snippet,status,recordingDetails\",\n        id=video_id,\n    ).execute()\n    return video_response[\"items\"][0]\n\n# Update video data\ndef update_video_data(youtube, video_id, updated_properties):\n    video_update_response = youtube.videos().update(\n        part=\"snippet,status,recordingDetails\",\n        body={\n            \"id\": video_id,\n            \"snippet\": {\n                \"title\": updated_properties[\"snippet\"][\"title\"],\n                \"categoryId\": updated_properties[\"snippet\"][\"categoryId\"],\n            },\n        }\n    ).execute()\n    return video_update_response\n\n# Main function\ndef main():\n    youtube = setup_youtube_auth()\n    video_info = get_video_info(youtube, \"QSC_ahDwuBs\")\n\n    # Update video data\n    updated_properties = {\n        \"snippet\": {\n            \"title\": \"test title\",\n            \"categoryId\": video_info[\"snippet\"][\"categoryId\"],\n        }\n    }\n    video_update_response = update_video_data(youtube, video_info[\"id\"], updated_properties)\n\n    print(\"Original video data:\")\n    pprint.pprint(video_info)\n\n    print(\"\\nNew video data:\")\n    pprint.pprint(video_update_response)\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>","tags":["python","youtube","api","update","video properties"]},{"location":"2026-01-02-which-youtube-video-properties-get-deleted-if-not-specified-in-an-update-request-closed/#explanation","title":"Explanation","text":"<p>The issue arises because the <code>Videos.update</code> endpoint does not automatically delete unspecified properties. To fix this, we need to explicitly remove the properties from the update request body.</p> <pre><code>def update_video_data(youtube, video_id, updated_properties):\n    # Remove unspecified properties from the update request body\n    for property_name in video_info[\"snippet\"]:\n        if property_name not in updated_properties[\"snippet\"]:\n            del updated_properties[\"snippet\"][property_name]\n\n    video_update_response = youtube.videos().update(\n        part=\"snippet,status,recordingDetails\",\n        body={\n            \"id\": video_id,\n            \"snippet\": updated_properties[\"snippet\"],\n        }\n    ).execute()\n    return video_update_response\n</code></pre>","tags":["python","youtube","api","update","video properties"]},{"location":"2026-01-02-which-youtube-video-properties-get-deleted-if-not-specified-in-an-update-request-closed/#conclusion","title":"Conclusion","text":"<p>To avoid unexpected changes in the video data, make sure to explicitly remove unspecified properties from the update request body. This ensures that only the specified properties are updated and leaves the rest unchanged.</p>","tags":["python","youtube","api","update","video properties"]},{"location":"2026-01-02-why-isnt-this-emitting-the-message/","title":"2026 01 02 why isnt this emitting the message","text":"<p>title: \"Socketio Emission Not Receiving Message: A Flask and JavaScript Solution\"</p> <p>tags:   - Flask   - Socketio   - JavaScript   - Real-time Communication</p>"},{"location":"2026-01-02-why-isnt-this-emitting-the-message/#core-problem","title":"Core Problem","text":"<p>When using Flask and Socketio for real-time communication, emitting a message from the server may not be received by the client-side JavaScript code. This can occur due to various reasons such as incorrect namespace configuration, session issues, or JavaScript errors.</p>"},{"location":"2026-01-02-why-isnt-this-emitting-the-message/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To solve this issue, let's analyze the provided code snippet: <pre><code>@app.route('/3x3/online/&lt;username&gt;', methods=['POST'])\ndef online3x3(username):\n    if username == session['username']:\n        socketio.emit('create', (session['username'], 1), namespace='/3x3/online/{username}')\n        session['ready'] = False\n</code></pre> The problem lies in the <code>namespace</code> parameter of the <code>socketio.emit()</code> function. The <code>{username}</code> part is not a valid Socketio namespace.</p> <p>To fix this, we need to create a unique namespace for each user. We can achieve this by using the <code>connectors</code> feature provided by Flask-SocketIO. Here's the corrected code: <pre><code>from flask_socketio import connectors\n\n# Create a new connector for each user\nconnector = connectors.connectors[username]\n\n@app.route('/3x3/online/&lt;username&gt;', methods=['POST'])\ndef online3x3(username):\n    if username == session['username']:\n        # Emit the message to the correct namespace\n        socketio.emit('create', (session['username'], 1), namespace=connector)\n        session['ready'] = False\n\n# Initialize the connectors dictionary in the application\napp.config[\"SOCKETIO_CONNECTORS\"] = {}\n</code></pre> In addition to fixing the namespace issue, make sure that your JavaScript code is correctly connected to the Socketio server. You should use the <code>connect()</code> method to establish a connection with the server before emitting any messages.</p> <p>Here's an example of how you can connect to the server in JavaScript: <pre><code>// Connect to the server when the page loads\nsocket.connect('http://localhost:5000');\n\n// Emit a message when the user clicks the button\ndocument.getElementById(\"myButton\").addEventListener(\"click\", function() {\n    socket.emit('create', ['John Doe', 1]);\n});\n</code></pre></p>"},{"location":"2026-01-02-why-isnt-this-emitting-the-message/#conclusion","title":"Conclusion","text":"<p>By creating unique namespaces for each user and ensuring that your JavaScript code is correctly connected to the Socketio server, you can resolve issues with emitting messages not being received. Remember to initialize the connectors dictionary in your Flask application to make this solution work.</p>"}]}