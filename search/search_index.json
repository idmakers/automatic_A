{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to ISSUE WEB SEARCH","text":"<p>This site collects technical notes and trending topics automatically generated by our AI agent.</p>"},{"location":"#latest-updates","title":"Latest Updates","text":"<p>Check the sidebar for the latest generated content.</p> <p>Last updated: 2026-01-02</p>"},{"location":"2026-01-02-django-model-with-foreign-key-onto-settingsauth_user_model-fails-when-app-is-incorporated-into-other-app-using-postgres/","title":"2026 01 02 django model with foreign key onto settingsauth user model fails when app is incorporated into other app using postgres","text":""},{"location":"2026-01-02-django-model-with-foreign-key-onto-settingsauth_user_model-fails-when-app-is-incorporated-into-other-app-using-postgres/#django-model-with-foreign-key-to-settingsauth_user_model-fails-when-incorporated-into-another-app-using-postgres","title":"Django Model with Foreign Key to Settings.AUTH_USER_MODEL Fails When Incorporated into Another App Using Postgres","text":""},{"location":"2026-01-02-django-model-with-foreign-key-onto-settingsauth_user_model-fails-when-app-is-incorporated-into-other-app-using-postgres/#core-problem","title":"Core Problem","text":"<p>When incorporating a Django app with a foreign key to <code>settings.AUTH_USER_MODEL</code> into another app using Postgres, the migration fails due to null values in the <code>owner_id</code> column of the survey table.</p>"},{"location":"2026-01-02-django-model-with-foreign-key-onto-settingsauth_user_model-fails-when-app-is-incorporated-into-other-app-using-postgres/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To resolve this issue, we need to understand why the <code>owner_id</code> column is being created as deferrable and then added with a constraint that makes it immediate. This is happening because Django is using a different approach to handle foreign keys on Postgres compared to SQLite.</p> <p>In Django 3.2 and later, when you define a foreign key to <code>settings.AUTH_USER_MODEL</code>, the migration will create a deferrable constraint for the <code>owner_id</code> column. This means that the constraint will be applied after the data is inserted into the table, rather than during the creation of the table.</p> <p>However, when you run the migrations with Postgres, Django expects the constraint to be immediate, meaning it should be applied during the creation of the table.</p> <p>To fix this issue, we need to explicitly specify that the <code>owner_id</code> column should be created as immediate. We can do this by modifying our model to use the <code>db_constraint=False</code> argument when defining the foreign key.</p> <pre><code># models.py\n\nfrom django.contrib.auth.models import User\nfrom django.db import models\n\nclass Survey(models.Model):\n    owner = models.ForeignKey(User, on_delete=models.CASCADE, db_constraint=False)\n</code></pre> <p>By setting <code>db_constraint=False</code>, we're telling Django not to create a constraint for the <code>owner_id</code> column. This will allow us to avoid the null value issue when running migrations with Postgres.</p>"},{"location":"2026-01-02-django-model-with-foreign-key-onto-settingsauth_user_model-fails-when-app-is-incorporated-into-other-app-using-postgres/#conclusion","title":"Conclusion","text":"<p>In summary, when incorporating a Django app with a foreign key to <code>settings.AUTH_USER_MODEL</code> into another app using Postgres, we need to explicitly specify that the <code>owner_id</code> column should be created as immediate. By doing so, we can avoid the null value issue and ensure that our migrations run smoothly.</p> <pre><code># manage.py migrate\n</code></pre> <p>By applying these changes, you should be able to resolve the issue and successfully run your migrations with Postgres.</p>"},{"location":"2026-01-02-ovr-classification-not-working-on-mnist-dataset-closed/","title":"Understanding OVR Classification Issues with MNIST Dataset","text":"","tags":["Multiclass classification","One-vs-Rest (OVR) classifier","MNIST dataset"]},{"location":"2026-01-02-ovr-classification-not-working-on-mnist-dataset-closed/#core-problem","title":"Core Problem","text":"<p>Classification models using the One-vs-Rest (OVR) approach for multiclass problems, such as the MNIST dataset, can exhibit unexpected behavior when predicting class labels. In this scenario, images uploaded into the model are consistently classified as class 7, even full white or full black images, which were previously correctly classified as class 5.</p>","tags":["Multiclass classification","One-vs-Rest (OVR) classifier","MNIST dataset"]},{"location":"2026-01-02-ovr-classification-not-working-on-mnist-dataset-closed/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>The issue lies in the way OVR classifiers handle the classes and their boundaries. By design, OVR models train a separate classifier for each possible pair of classes against a common baseline (usually the majority class). This approach can lead to issues when dealing with datasets where the classes are not well-separated or have overlapping boundaries.</p> <p>In this specific case, it seems that the MNIST dataset's classes might be too loosely defined, causing the OVR classifier to misinterpret the input images. The model is trained on a balanced set of classes (0-9), but during prediction, it may not fully understand the subtleties between some of these classes.</p> <p>To address this issue, consider the following adjustments:</p> <ol> <li>Data Preprocessing: Before feeding data into the OVR classifier, apply additional preprocessing steps to enhance class separation and model interpretability.</li> <li>Class Balancing: If possible, balance the training data for each pair of classes to improve the overall performance of the model.</li> <li>Hyperparameter Tuning: Experiment with different hyperparameters for the OVR classifier to find optimal settings that better suit your dataset.</li> </ol> <p>Here's an updated code snippet incorporating some of these suggestions:</p> <pre><code>from sklearn.datasets import fetch_openml\nimport numpy as np\n\nmnist = fetch_openml('mnist_784', as_frame=False)\nX, y = mnist.data, mnist.target\n\n# Applying class balancing to improve model performance\nclass_balance = {}\nfor label in np.unique(y):\n    class_balance[label] = len(y[y == label])\n\nbalanced_y = []\nfor i, l in enumerate(y):\n    if l not in class_balance:\n        continue\n    balanced_y.append(class_balance[l])\n    y[i] = l\n\nX_train, X_test, y_train, y_test = X[:60000], X[60000:], np.array(balanced_y)[:60000], np.array(balanced_y)[60000:]\n\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import SVC\n\n# Applying a small amount of data augmentation to enhance class separation\ndef augment_data(img):\n    aug_img = img.copy()\n    aug_img[img &lt; 128] *= 1.2\n    return aug_img\n\novr_clf = OneVsRestClassifier(SVC(random_state=42))\novr_clf.fit(X_train, y_train)\n\nfrom google.colab import files\n\nuploaded = files.upload()\n\nfilename = next(iter(uploaded))\n\nimg = Image.open(filename).convert(\"L\")\naug_img = augment_data(img)\nimg_array = np.array(aug_img)\nimg_array = img_array.reshape(1, 784)\n\nprint(img_array)\novr_clf.predict(img_array)\n</code></pre>","tags":["Multiclass classification","One-vs-Rest (OVR) classifier","MNIST dataset"]},{"location":"2026-01-02-ovr-classification-not-working-on-mnist-dataset-closed/#conclusion","title":"Conclusion","text":"<p>By understanding the fundamental principles of OVR classification and applying targeted adjustments to your dataset and preprocessing steps, you can improve the accuracy and reliability of your multiclass classification models. Regularly monitor model performance on both training and test data to ensure that these modifications are effective in addressing specific issues.</p>","tags":["Multiclass classification","One-vs-Rest (OVR) classifier","MNIST dataset"]},{"location":"2026-01-02-python-lz4-how-to-configure-the-number-of-threads/","title":"Optimizing Python-LZ4 Performance with Multithreading Configuration","text":"","tags":["python-lz4","multithreading","performance optimization"]},{"location":"2026-01-02-python-lz4-how-to-configure-the-number-of-threads/#core-problem","title":"Core Problem","text":"<p>LZ4, a popular compression library for Python, has introduced multithreading support in its version 1.10.0 to enhance performance in high-throughput environments.</p>","tags":["python-lz4","multithreading","performance optimization"]},{"location":"2026-01-02-python-lz4-how-to-configure-the-number-of-threads/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To configure the number of threads in the Python binding of LZ4, you can utilize the <code>thread_pool_size</code> parameter when creating an instance of <code>lz4.frame.open</code>.</p>","tags":["python-lz4","multithreading","performance optimization"]},{"location":"2026-01-02-python-lz4-how-to-configure-the-number-of-threads/#configuring-thread-pool-size","title":"Configuring Thread Pool Size","text":"<pre><code>import lz4.frame\nimport shutil\n\ninput_file = r\"E:\\Personal Projects\\tmp\\chunk_0.ndjson\"\noutput_file = r\"E:\\Personal Projects\\tmp\\chunk_0.ndjson.lz4\"\n\n# Create an instance with a thread pool size of 4\nwith lz4.frame.open(output_file, mode=\"wb\", thread_pool_size=4) as g:\n    shutil.copyfileobj(open(input_file, \"rb\"), g)\n</code></pre> <p>In this example, we set the <code>thread_pool_size</code> to 4, which means LZ4 will create a pool of 4 worker threads to handle compression and decompression tasks concurrently.</p>","tags":["python-lz4","multithreading","performance optimization"]},{"location":"2026-01-02-python-lz4-how-to-configure-the-number-of-threads/#benchmarking-performance","title":"Benchmarking Performance","text":"<p>To validate the performance benefits of multithreading, you can compare the execution time of your Python script with and without thread pooling:</p> <pre><code>import lz4.frame\nimport time\nimport shutil\n\ninput_file = r\"E:\\Personal Projects\\tmp\\chunk_0.ndjson\"\noutput_file = r\"E:\\Personal Projects\\tmp\\chunk_0.ndjson.lz4\"\n\n# Measure execution time without thread pooling\nstart_time = time.time()\nwith open(input_file, \"rb\") as f, lz4.frame.open(output_file, mode=\"wb\") as g:\n    shutil.copyfileobj(f, g)\nend_time = time.time()\nno_thread_pool_time = end_time - start_time\n\n# Measure execution time with thread pooling\nstart_time = time.time()\nwith lz4.frame.open(output_file, mode=\"wb\", thread_pool_size=4) as g:\n    shutil.copyfileobj(open(input_file, \"rb\"), g)\nend_time = time.time()\nthread_pool_time = end_time - start_time\n\nprint(f\"No Thread Pool: {no_thread_pool_time} seconds\")\nprint(f\"Thread Pool (4 threads): {thread_pool_time} seconds\")\n</code></pre> <p>By configuring the thread pool size in LZ4, you can significantly improve the performance of your Python script for high-throughput environments.</p>","tags":["python-lz4","multithreading","performance optimization"]}]}