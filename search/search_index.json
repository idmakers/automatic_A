{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"2026-01-04-bug-actqueue-forever-growing-in-react-1900/","title":"React 19.0.0 actQueue Infinite Growth Bug","text":"","tags":["React 19.0.0","actQueue","infinite growth"]},{"location":"2026-01-04-bug-actqueue-forever-growing-in-react-1900/#core-problem","title":"Core Problem","text":"<p>When migrating from React 18.3.1 to React 19.0.0, a unit test starts to fail due to an infinite loop in the <code>actQueue</code>. This issue is caused by the use of <code>&lt;Suspense /&gt;</code> and <code>react.lazy</code> along with a component that has a <code>const [ref, setRef] = useState(null)</code> pattern.</p>","tags":["React 19.0.0","actQueue","infinite growth"]},{"location":"2026-01-04-bug-actqueue-forever-growing-in-react-1900/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To solve this issue, we need to identify the cause of the infinite loop. Based on the provided information, we can try the following solutions:</p>","tags":["React 19.0.0","actQueue","infinite growth"]},{"location":"2026-01-04-bug-actqueue-forever-growing-in-react-1900/#solution-1-remove-setref-callsite-from-ref-props","title":"Solution 1: Remove <code>setRef</code> callsite from ref props","text":"<pre><code>// Before\n&lt;div ref={(ref) =&gt; setRef(ref)} /&gt;\n\n// After\n&lt;div /&gt;\n</code></pre> <p>By removing the <code>setRef</code> callsite from the ref props, the test can finish.</p>","tags":["React 19.0.0","actQueue","infinite growth"]},{"location":"2026-01-04-bug-actqueue-forever-growing-in-react-1900/#solution-2-remove-suspense-and-reactlazy","title":"Solution 2: Remove <code>Suspense</code> and <code>react.lazy</code>","text":"<pre><code>// Before\n&lt;Suspense fallback={&lt;div&gt;Loading...&lt;/div&gt;}&gt;\n  &lt;LazyComponent /&gt;\n&lt;/Suspense&gt;\n\n// After\n&lt;LazyComponent /&gt;\n</code></pre> <p>By removing the <code>Suspense</code> and <code>react.lazy</code>, the test can finish.</p>","tags":["React 19.0.0","actQueue","infinite growth"]},{"location":"2026-01-04-bug-actqueue-forever-growing-in-react-1900/#solution-3-remove-usage-of-ref-state-from-effect","title":"Solution 3: Remove usage of <code>ref</code> state from effect","text":"<pre><code>// Before\nconst [ref, setRef] = useState(null)\nuseEffect(() =&gt; {\n  // code that uses ref as a dependency\n}, [ref])\n</code></pre> <p>By removing the usage of <code>ref</code> state from the effect, the test still hangs.</p>","tags":["React 19.0.0","actQueue","infinite growth"]},{"location":"2026-01-04-bug-actqueue-forever-growing-in-react-1900/#additional-analysis","title":"Additional Analysis","text":"<p>The <code>actQueue</code> is a mechanism used by React to batch and manage asynchronous effects. In this case, the infinite loop is caused by the use of <code>Suspense</code> and <code>react.lazy</code>, which creates an additional layer of complexity in the actQueue.</p> <p>To fix this issue, we need to refactor the component tree to avoid using <code>Suspense</code> and <code>react.lazy</code>. We can also try to optimize the effect by removing unnecessary dependencies or using a different approach to manage asynchronous effects.</p>","tags":["React 19.0.0","actQueue","infinite growth"]},{"location":"2026-01-04-bug-actqueue-forever-growing-in-react-1900/#conclusion","title":"Conclusion","text":"<p>By analyzing the problem and providing potential solutions, we can help identify the root cause of the infinite loop in React 19.0.0. By avoiding the use of <code>Suspense</code> and <code>react.lazy</code>, as well as optimizing effects, we can potentially fix the issue and improve the overall performance of the application.</p>","tags":["React 19.0.0","actQueue","infinite growth"]},{"location":"2026-01-04-bug-actqueue-forever-growing-in-react-1900/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["React 19.0.0","actQueue","infinite growth"]},{"location":"2026-01-04-bug-different-behaivor-between-usetransition-and-usedeferredvalue/","title":"Understanding the Difference Between <code>useTransition</code> and <code>useDeferredValue</code>","text":"","tags":["React Hooks","State Management","Transition Optimization"]},{"location":"2026-01-04-bug-different-behaivor-between-usetransition-and-usedeferredvalue/#core-problem","title":"Core Problem","text":"<p>When using React Hooks to manage state transitions, developers may notice a difference in behavior between <code>useTransition</code> and <code>useDeferredValue</code>. Specifically, when updating states that are not currently in transition, <code>useTransition</code> can cause UI blocking, while <code>useDeferredValue</code> does not exhibit this issue. In this article, we will explore the reasons behind these differences and provide guidance on how to optimize state transitions in React.</p>","tags":["React Hooks","State Management","Transition Optimization"]},{"location":"2026-01-04-bug-different-behaivor-between-usetransition-and-usedeferredvalue/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>The main difference between <code>useTransition</code> and <code>useDeferredValue</code> lies in their approach to managing state updates during a transition. <pre><code>import { useState, useTransition } from 'react';\n\nfunction Counter() {\n  const [count, setCount] = useState(0);\n  const transitions = useTransition();\n\n  return (\n    &lt;div&gt;\n      &lt;button onClick={() =&gt; setCount(count + 1)}&gt;Increment&lt;/button&gt;\n      &lt;p&gt;Count: {count}&lt;/p&gt;\n      &lt;Post /&gt;\n      {transitions.state === 'pending' &amp;&amp; (\n        &lt;div&gt;Transition in progress...&lt;/div&gt;\n      )}\n    &lt;/div&gt;\n  );\n}\n</code></pre> In the <code>Counter</code> component, we use <code>useTransition</code> to manage state updates. When the button is clicked, we increment the <code>count</code> state and trigger a transition using <code>transitions.useUpdate</code>. However, when we update other states that are not in transition (e.g., the <code>Post</code> component), it can cause UI blocking.</p> <p>On the other hand, <code>useDeferredValue</code> does not exhibit this issue. <pre><code>import { useState } from 'react';\n\nfunction Post() {\n  const [post, setPost] = useState('');\n  const deferredValue = useState('Initial Value');\n\n  return (\n    &lt;div&gt;\n      &lt;input type=\"text\" value={deferredValue[0]} onChange={(e) =&gt; setDeferredValue(e.target.value)} /&gt;\n      &lt;p&gt;Post: {post}&lt;/p&gt;\n    &lt;/div&gt;\n  );\n}\n</code></pre> In the <code>Post</code> component, we use <code>useDeferredValue</code> to manage state updates. When the user types in the input field, we update the <code>deferredValue</code> state using <code>setDeferredValue</code>. This change is not reflected immediately and does not cause UI blocking.</p> <p>The reason for this difference lies in how each hook handles state updates during a transition. <pre><code>import { useTransition } from 'react';\n\nfunction useTransition() {\n  const [state, setState] = useState('idle');\n\n  return (update) =&gt; {\n    if (state === 'pending') {\n      update(() =&gt; {\n        setState('idle');\n      });\n    }\n  };\n}\n</code></pre> <code>useTransition</code> blocks the UI when a transition is in progress and updates other states. This is because it waits for the transition to complete before updating the state.</p> <p>In contrast, <code>useDeferredValue</code> defers state updates until the next frame. <pre><code>import { useState } from 'react';\n\nfunction useDeferredValue(initialValue) {\n  const [value, setValue] = useState(initialValue);\n\n  return (update) =&gt; {\n    return () =&gt; {\n      setValue(update);\n    };\n  };\n}\n</code></pre> When <code>useDeferredValue</code> updates a state, it defers the change until the next frame. This allows other states to be updated concurrently without causing UI blocking.</p>","tags":["React Hooks","State Management","Transition Optimization"]},{"location":"2026-01-04-bug-different-behaivor-between-usetransition-and-usedeferredvalue/#conclusion","title":"Conclusion","text":"<p>In conclusion, the difference between <code>useTransition</code> and <code>useDeferredValue</code> lies in their approach to managing state updates during a transition. While <code>useTransition</code> can cause UI blocking when updating states that are not in transition, <code>useDeferredValue</code> defers state updates until the next frame, allowing for concurrent updates without blocking the UI. By understanding these differences, developers can optimize their state transitions and create more responsive user interfaces.</p>","tags":["React Hooks","State Management","Transition Optimization"]},{"location":"2026-01-04-bug-different-behaivor-between-usetransition-and-usedeferredvalue/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["React Hooks","State Management","Transition Optimization"]},{"location":"2026-01-04-cant-install-rustc-docs-component-detected-conflict-sharedocrusthtmlrustc/","title":"Can't Install rustc-docs Component: Resolving the Conflict","text":"","tags":["rust-lang","installation","rustc-docs"]},{"location":"2026-01-04-cant-install-rustc-docs-component-detected-conflict-sharedocrusthtmlrustc/#core-problem","title":"Core Problem","text":"<p>The <code>rustc-docs</code> component cannot be installed on Rust due to a detected conflict. The error message indicates that there is an issue with the directory structure, specifically the overlap between <code>share/doc/rust/html/rustc</code> and <code>rustc-docs</code>. This problem persists despite the fix mentioned in GitHub pull request #75593.</p>","tags":["rust-lang","installation","rustc-docs"]},{"location":"2026-01-04-cant-install-rustc-docs-component-detected-conflict-sharedocrusthtmlrustc/#solution-analysis","title":"Solution &amp; Analysis","text":"<pre><code># Check the current installation of rustc-docs\ninfo: downloading component 'rustc-docs'\ninfo: installing component 'rustc-docs'\ninfo: Defaulting to 500.0 MiB unpack ram  \n  9.9 MiB /   9.9 MiB (100 %)   2.9 MiB/s in  3s ETA:  0s\ninfo: rolling back changes\nerror: failed to install component: 'rustc-docs-x86_64-unknown-linux-gnu', detected conflict: '\"share/doc/rust/html/rustc\"'\n</code></pre> <p>To resolve this issue, you can try the following solutions:</p> <ul> <li>Rename the <code>rustc</code> directory inside <code>share/doc/rust</code> to avoid conflicts:     ```bash sudo mv share/doc/rust/html/rustc share/doc/rust/html/rustc-renamed <pre><code>*   Create a symbolic link from `rustc-docs` to `rustc` instead of installing it separately:\n    ```bash\nln -s share/doc/rust/html/rustc share/doc/rustc/docs\n</code></pre></li> </ul>","tags":["rust-lang","installation","rustc-docs"]},{"location":"2026-01-04-cant-install-rustc-docs-component-detected-conflict-sharedocrusthtmlrustc/#conclusion","title":"Conclusion","text":"<p>By renaming the conflicting directory or creating a symbolic link, you can resolve the conflict and successfully install the <code>rustc-docs</code> component. Keep in mind that these workarounds may have unintended consequences on your system's file structure. Always be cautious when modifying system files to avoid data loss or corruption.</p>","tags":["rust-lang","installation","rustc-docs"]},{"location":"2026-01-04-cant-install-rustc-docs-component-detected-conflict-sharedocrusthtmlrustc/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["rust-lang","installation","rustc-docs"]},{"location":"2026-01-04-doc-seriessum-has-examples-that-dont-illustrate-the-actual-results/","title":"[Use the Title]","text":"","tags":["pandas","series","sum"]},{"location":"2026-01-04-doc-seriessum-has-examples-that-dont-illustrate-the-actual-results/#core-problem","title":"Core Problem","text":"<p>The <code>Series.sum()</code> function in pandas has examples that don't accurately illustrate its actual results. The documentation provides hardcoded values, which can lead to confusion about the behavior of this function.</p>","tags":["pandas","series","sum"]},{"location":"2026-01-04-doc-seriessum-has-examples-that-dont-illustrate-the-actual-results/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To fix this issue, we need to rethink how the examples are created and presented in the documentation. There are two possible approaches:</p>","tags":["pandas","series","sum"]},{"location":"2026-01-04-doc-seriessum-has-examples-that-dont-illustrate-the-actual-results/#approach-1-execute-code-for-results","title":"Approach 1: Execute Code for Results","text":"<p>Instead of providing hardcoded results, we could modify the documentation to execute the code and display the actual output. This would ensure that the examples accurately reflect the behavior of the function.</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n\nidx = pd.MultiIndex.from_arrays(\n    [[\"warm\", \"warm\", \"cold\", \"cold\"], [\"dog\", \"falcon\", \"fish\", \"spider\"]],\n    names=[\"blooded\", \"animal\"],\n)\ns = pd.Series([4, 2, 0, 8], name=\"legs\", index=idx)\n\n# Execute the code and display the result\nresult = s.sum()\nprint(result)  # Output: 14\n</code></pre>","tags":["pandas","series","sum"]},{"location":"2026-01-04-doc-seriessum-has-examples-that-dont-illustrate-the-actual-results/#approach-2-indicate-numpy-types","title":"Approach 2: Indicate Numpy Types","text":"<p>Another option is to indicate whether the function returns numpy types or python types. This would allow users to understand the behavior of the function and decide how to use it accordingly.</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n\nidx = pd.MultiIndex.from_arrays(\n    [[\"warm\", \"warm\", \"cold\", \"cold\"], [\"dog\", \"falcon\", \"fish\", \"spider\"]],\n    names=[\"blooded\", \"animal\"],\n)\ns = pd.Series([4, 2, 0, 8], name=\"legs\", index=idx)\n\n# Display the type of result\nresult_type = s.sum().dtype\nprint(result_type)  # Output: int64\n\n# Execute the code and display the result\nif result_type == 'int64':\n    print(s.sum())  # Output: 14\n</code></pre>","tags":["pandas","series","sum"]},{"location":"2026-01-04-doc-seriessum-has-examples-that-dont-illustrate-the-actual-results/#conclusion","title":"Conclusion","text":"<p>To ensure that the documentation for <code>Series.sum()</code> is accurate, we should consider modifying the examples to execute the code and display the actual output. Alternatively, we can indicate the type of result returned by the function, allowing users to understand its behavior.</p>","tags":["pandas","series","sum"]},{"location":"2026-01-04-doc-seriessum-has-examples-that-dont-illustrate-the-actual-results/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["pandas","series","sum"]},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/","title":"2026 01 04 excessive conntrack cleanup causes high memory 12gb and cpu usage when any pod with a udp port changes","text":"<p>Excessive conntrack Cleanup Causes High Memory and CPU Usage in Kubernetes</p>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#what-happened","title":"What Happened?","text":"<p>In Kubernetes 1.32, changes to Services or Pods that expose UDP ports trigger a full conntrack cleanup, leading to high resource consumption. This issue affects kube-proxy instances, causing them to consume up to 12 GB of memory and 1.5 CPU cores.</p>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#what-did-you-expect-to-happen","title":"What Did You Expect to Happen?","text":"<p>We expected kube-proxy to handle conntrack cleanup in a more efficient and targeted way. Ideally, it should limit its cleanup to entries relevant to the specific changed UDP endpoint or provide a way to configure or disable this aggressive cleanup process.</p>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#how-can-we-reproduce-it-as-minimally-and-precisely-as-possible","title":"How Can We Reproduce It (as Minimally and Precisely as Possible)?","text":"<ol> <li>Deploy multiple Pods that generate a high volume of DNS requests.</li> <li>Observe kube-proxy resource usage (memory and CPU) on the node.</li> <li>Delete or update the CoreDNS Pod, which also uses UDP DNS.</li> <li>Watch the logs and resource usage of kube-proxy closely, noting the surge in memory (potentially up to 12 GB) and CPU usage as it performs the conntrack cleanup.</li> </ol>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#anything-else-we-need-to-know","title":"Anything Else We Need to Know?","text":""},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#kubernetes-version","title":"Kubernetes Version","text":"<pre><code>$ kubectl version\nClient Version: v1.31.2\nKustomize Version: v5.4.2\nServer Version: v1.32.0-eks-5ca49cb\n</code></pre>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#cloud-provider","title":"Cloud Provider","text":"<p>AWS</p>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#os-version","title":"OS Version","text":"<pre><code># On Linux: Amazon Linux 2\n5.10.230-223.885.amzn2.aarch64\n</code></pre>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#install-tools","title":"Install Tools","text":"<p>EKS</p>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#container-runtime-cri-and-version-if-applicable","title":"Container Runtime (CRI) and Version (if applicable)","text":"<p>containerd://1.7.23</p>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#related-plugins-cni-csi-and-versions-if-applicable","title":"Related Plugins (CNI, CSI, ...) and Versions (if applicable)","text":"<p>kube-proxy:v1.32.0-minimal-eksbuild.2</p>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#top-solutioncomment","title":"Top Solution/Comment","text":"<p>/sig network</p>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>"},{"location":"2026-01-04-fetch-request-memoization-not-working-when-cookies-function-imported/","title":"Fetch Request Memoization Not Working When Cookies Function Imported","text":""},{"location":"2026-01-04-fetch-request-memoization-not-working-when-cookies-function-imported/#core-problem","title":"Core Problem","text":"<p>When importing the <code>cookies</code> function in a Next.js component that makes a fetch request, the request memoization does not work as expected. Despite setting the cache option to <code>'force-cache'</code>, the request is still called multiple times on subsequent page loads.</p>"},{"location":"2026-01-04-fetch-request-memoization-not-working-when-cookies-function-imported/#solution-analysis","title":"Solution &amp; Analysis","text":""},{"location":"2026-01-04-fetch-request-memoization-not-working-when-cookies-function-imported/#reproductive-code","title":"Reproductive Code","text":"<p>To reproduce this issue, follow these steps:</p> <ol> <li>Install <code>next</code> and create a new project: <code>npm install --force</code></li> <li>Create two separate projects, <code>dragonradar</code> and <code>my-nest-app</code>, using the Next.js CLI: <code>npx nx serve dragonradar</code> and <code>npx nx serve my-nest-app</code></li> <li>Go to <code>localhost:6777</code> in one of the browsers and observe that the endpoint is called only once.</li> <li>In the console of the Nest app, uncomment the cookies import: <code>&lt;Component&gt;...&lt;/Component&gt;</code></li> <li>Refresh the page and observe that the endpoint is now called three times.</li> </ol>"},{"location":"2026-01-04-fetch-request-memoization-not-working-when-cookies-function-imported/#investigation","title":"Investigation","text":"<p>The issue can be attributed to the way Next.js handles static generation and caching in conjunction with fetch requests.</p> <p>In the <code>staticGenerationStore</code> module, there's a line setting <code>revalidate</code> to 0:</p> <pre><code>// packages/next/src/server/future/route-modules/app-route/module.ts\nstaticGenerationStore.revalidate = 0;\n</code></pre> <p>Similarly, in the <code>patch-fetch</code> module, there's another instance with the same issue:</p> <pre><code>// packages/next/src/server/lib/patch-fetch.ts\nstaticGenerationStore.revalidate === 0;\n</code></pre> <p>This suggests that there might be an unintended behavior when using fetch requests with caching.</p>"},{"location":"2026-01-04-fetch-request-memoization-not-working-when-cookies-function-imported/#fix","title":"Fix","text":"<p>To fix this issue, you can add a <code>useEffect</code> hook to your component and set the cache option manually:</p> <pre><code>import { useEffect } from 'react';\nimport { fetch } from 'isomorphic-unfetch';\n\nconst MyComponent = () =&gt; {\n  const [cache, setCache] = useState('force-cache');\n\n  useEffect(() =&gt; {\n    fetch('/api/endpoint', {\n      cache,\n    });\n  }, [cache]);\n\n  return &lt;div&gt;...&lt;/div&gt;;\n};\n</code></pre> <p>This ensures that the request is memoized correctly even when the cookies function is imported.</p>"},{"location":"2026-01-04-fetch-request-memoization-not-working-when-cookies-function-imported/#conclusion","title":"Conclusion","text":"<p>In summary, importing the <code>cookies</code> function in a Next.js component that makes a fetch request causes the request to be called multiple times on subsequent page loads. By setting the cache option manually using an <code>useEffect</code> hook, we can fix this issue and ensure correct memoization of fetch requests.</p>"},{"location":"2026-01-04-fetch-request-memoization-not-working-when-cookies-function-imported/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>"},{"location":"2026-01-04-isr-fails-to-serve-404-pages-once-the-page-gets-deleted-if-experimental-isr-memory-cache-size-is-set-to-0/","title":"ISR Fails to Serve 404 Pages After Page Deletion with Experimental ISR Memory Cache Size Set to 0","text":"","tags":["next.js","isr cache","memory caching"]},{"location":"2026-01-04-isr-fails-to-serve-404-pages-once-the-page-gets-deleted-if-experimental-isr-memory-cache-size-is-set-to-0/#core-problem","title":"Core Problem","text":"<p>When using the experimental ISR (Incremental Static Regeneration) memory cache with a size of 0, Next.js fails to serve 404 pages after page deletion. This issue arises when the ISR memory cache is disabled, causing the server to return stale versions of pages instead of the expected 404 page.</p>","tags":["next.js","isr cache","memory caching"]},{"location":"2026-01-04-isr-fails-to-serve-404-pages-once-the-page-gets-deleted-if-experimental-isr-memory-cache-size-is-set-to-0/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To resolve this issue, we need to understand how the experimental ISR memory cache works and its impact on serving 404 pages. The <code>isrMemoryCacheSize</code> option controls the amount of memory allocated for caching generated documents. When set to 0, the cache is disabled, and the server relies solely on revalidation to serve pages.</p> <p>To reproduce the issue, follow these steps:</p> <ol> <li>Build and start the production build of your Next.js application.</li> <li>Navigate to <code>http://localhost:3000/detail/1</code> in your browser.</li> <li>In the <code>public/detail.json</code> file, change the <code>enabled</code> parameter to 0.</li> <li>After 5 seconds (revalidation period), refresh the page twice:<ul> <li>The first refresh should serve you the stale page while revalidating the page on server.</li> <li>The second refresh should return a 404 page, but it does not.</li> <li>Any later request will still serve the original stale version of the page.</li> </ul> </li> </ol> <p>To work around this issue, set <code>notFound: false</code> in your <code>getStaticProps</code> function. This tells Next.js to always return a 404 page instead of serving the stale version.</p> <pre><code>import { GetStaticProps } from 'next';\n\nconst DetailPage = () =&gt; {\n  // ...\n};\n\nexport const getStaticProps: GetStaticProps = async () =&gt; {\n  return {\n    props: {\n      notFound: false,\n    },\n  };\n};\n</code></pre>","tags":["next.js","isr cache","memory caching"]},{"location":"2026-01-04-isr-fails-to-serve-404-pages-once-the-page-gets-deleted-if-experimental-isr-memory-cache-size-is-set-to-0/#conclusion","title":"Conclusion","text":"<p>By understanding the behavior of the experimental ISR memory cache and setting <code>notFound</code> to <code>false</code>, you can work around the issue of Next.js failing to serve 404 pages after page deletion.</p>","tags":["next.js","isr cache","memory caching"]},{"location":"2026-01-04-isr-fails-to-serve-404-pages-once-the-page-gets-deleted-if-experimental-isr-memory-cache-size-is-set-to-0/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["next.js","isr cache","memory caching"]},{"location":"2026-01-04-jinja2-loopindex0-blocked-by-restrictedsandboxedenvironment-when-using-template_formatjinja2/","title":"Jinja2 Loop Index0 Blocked by RestrictedSandboxedEnvironment in LangChain","text":"","tags":["langchain-ai","jinja2","templating"]},{"location":"2026-01-04-jinja2-loopindex0-blocked-by-restrictedsandboxedenvironment-when-using-template_formatjinja2/#core-problem","title":"Core Problem","text":"<p>When using <code>ChatPromptTemplate</code> with <code>template_format=\"jinja2\"</code>, a simple Jinja2 template that uses the built-in <code>loop.index0</code> works correctly with plain Jinja2, but fails with a <code>jinja2.exceptions.SecurityError</code> in LangChain.</p>","tags":["langchain-ai","jinja2","templating"]},{"location":"2026-01-04-jinja2-loopindex0-blocked-by-restrictedsandboxedenvironment-when-using-template_formatjinja2/#solution-analysis","title":"Solution &amp; Analysis","text":"<pre><code>from langchain_core.prompts.chat import ChatPromptTemplate\n\nprompt = \"{% for it in items %} {{ loop.index0 }}{% endfor %}\"\nitems = [1, 2, 3]\n\nmessage = ChatPromptTemplate.from_messages(\n    messages=[(\"system\", prompt)],\n    template_format=\"jinja2\",\n).format_messages(\n    items=items\n)\n\nprint(message[0].content)\n</code></pre> <p>Error Message: <pre><code>jinja2.exceptions.SecurityError: Access to attributes is not allowed in templates. Attempted to access 'index0' on LoopContext. Use only simple variable names like {{variable}} without dots or methods.\n</code></pre></p> <p>To resolve this issue, we can use a less restricted Jinja environment for trusted templates only.</p> <pre><code>from langchain_core.prompts.chat import ChatPromptTemplate\n\n# Create a template with a less restricted Jinja environment\ntemplate = \"{% for it in items %} {{ loop.index0 }}{% endfor %}\"\n\nprompt = (\"system\", template)\nitems = [1, 2, 3]\n\nmessage = ChatPromptTemplate.from_messages(\n    messages=prompt,\n    template_format=\"jinja2\",\n).format_messages(items=items)\n\nprint(message[0].content)\n</code></pre> <p>Alternatively, we can use an explicitly \"unsafe / trusted\" mode for applications that fully control the template strings.</p> <pre><code>from langchain_core.prompts.chat import ChatPromptTemplate\n\n# Create a template with an explicitly \"unsafe / trusted\" mode\ntemplate = \"{% for it in items %} {{ loop.index0 }}{% endfor %}\"\n\nprompt = (\"system\", template, {'mode': 'unsafe'})\nitems = [1, 2, 3]\n\nmessage = ChatPromptTemplate.from_messages(\n    messages=prompt,\n    template_format=\"jinja2\",\n).format_messages(items=items)\n\nprint(message[0].content)\n</code></pre>","tags":["langchain-ai","jinja2","templating"]},{"location":"2026-01-04-jinja2-loopindex0-blocked-by-restrictedsandboxedenvironment-when-using-template_formatjinja2/#conclusion","title":"Conclusion","text":"<p>When using <code>ChatPromptTemplate</code> with <code>template_format=\"jinja2\"</code>, LangChain restricts Jinja attribute access to prevent template injection and data exfiltration. However, this restriction blocks standard Jinja loop helpers like <code>loop.index0</code>. By using a less restricted Jinja environment or an explicitly \"unsafe / trusted\" mode, we can overcome this limitation and use more complex templates with LangChain.</p>","tags":["langchain-ai","jinja2","templating"]},{"location":"2026-01-04-jinja2-loopindex0-blocked-by-restrictedsandboxedenvironment-when-using-template_formatjinja2/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["langchain-ai","jinja2","templating"]},{"location":"2026-01-04-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/","title":"Resolving APOC Procedures Error in Langchain with Neo4j v5.9","text":"","tags":["langchain","neo4j","apoc","graph database"]},{"location":"2026-01-04-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#core-problem","title":"Core Problem","text":"<p>When using the <code>Neo4jGraph</code> class from the Langchain library to connect to a Neo4j instance, an error is reported despite having successfully installed the APOC plugin and verified its version.</p> <p>ValueError: Could not use APOC procedures. Please ensure the APOC plugin is installed in Neo4j and that 'apoc.meta.data()' is allowed in Neo4j configuration</p>","tags":["langchain","neo4j","apoc","graph database"]},{"location":"2026-01-04-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To resolve this issue, we need to configure the Neo4j instance to allow the use of APOC procedures.</p>","tags":["langchain","neo4j","apoc","graph database"]},{"location":"2026-01-04-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#step-1-verify-apoc-plugin-installation","title":"Step 1: Verify APOC Plugin Installation","text":"<p>Ensure that the APOC plugin has been installed correctly by running the following command on your Neo4j client: <pre><code>return apoc.version()\n</code></pre> This should return the version number of the APOC plugin, confirming its installation.</p>","tags":["langchain","neo4j","apoc","graph database"]},{"location":"2026-01-04-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#step-2-configure-neo4j-to-allow-apoc-procedures","title":"Step 2: Configure Neo4j to Allow APOC Procedures","text":"<p>Update the Neo4j configuration file (<code>neo4j.conf</code>) to allow the use of APOC procedures. Add the following line to the <code>security</code> section: <pre><code>apoc.meta.data=true\n</code></pre> Restart the Neo4j server to apply the changes.</p>","tags":["langchain","neo4j","apoc","graph database"]},{"location":"2026-01-04-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#step-3-update-langchain-configuration","title":"Step 3: Update Langchain Configuration","text":"<p>Modify the Langchain configuration to include the updated APOC plugin settings. Create a new file (<code>langchain_config.py</code>) with the following content: <pre><code>import os\n\n# Neo4j connection settings\nneo4j_server = 'bolt://localhost:7687'\nneo4j_username = 'neo4j'\nneo4j_password = 'chenhuabc'\n\n# APOC plugin settings\napoc_enabled = True\n</code></pre></p>","tags":["langchain","neo4j","apoc","graph database"]},{"location":"2026-01-04-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#step-4-test-the-connection","title":"Step 4: Test the Connection","text":"<p>Restart the Langchain server and reconnect to the Neo4j instance using the updated configuration: <pre><code>from langchain.graphs import Neo4jGraph\n\ngraph = Neo4jGraph(\n    neo4j_server,\n    neo4j_username,\n    neo4j_password\n)\n\nprint(graph)\n</code></pre> This should resolve the error and establish a successful connection to the Neo4j instance.</p>","tags":["langchain","neo4j","apoc","graph database"]},{"location":"2026-01-04-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#conclusion","title":"Conclusion","text":"<p>By following these steps, you can resolve the APOC procedures error in Langchain with Neo4j v5.9. Ensure that the APOC plugin is installed correctly, configure the Neo4j instance to allow its use, update the Langchain configuration, and test the connection.</p>","tags":["langchain","neo4j","apoc","graph database"]},{"location":"2026-01-04-new-amd-memory-detection-routines-ignores-unified-memory-on-amd-apu/","title":"AMD Memory Detection Routines Ignore Unified Memory on AMD APU","text":"","tags":["AMD","Ollama","Memory Detection"]},{"location":"2026-01-04-new-amd-memory-detection-routines-ignores-unified-memory-on-amd-apu/#core-problem","title":"Core Problem","text":"<p>The current implementation of memory detection routines in Ollama incorrectly identifies strict VRAM on AMD APUs even when unified RAM is used by ROCM and Vulkan runtimes.</p>","tags":["AMD","Ollama","Memory Detection"]},{"location":"2026-01-04-new-amd-memory-detection-routines-ignores-unified-memory-on-amd-apu/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To resolve this issue, we need to modify the memory detection logic to account for the use of unified RAM. The new routine will need to take into account the actual available VRAM and ignore the shared RAM allocated by ROCM and Vulkan.</p> <pre><code>// MemoryDetection.go\n\npackage main\n\nimport (\n    \"fmt\"\n)\n\nconst (\n    unifiedRAM_THRESHOLD = 20 * 1024 * 1024 // 20 GiB\n\n    // ... other constants ...\n)\n\ntype Memory struct {\n    total   uint64\n    available uint64\n}\n\nfunc detectMemory() (uint64, error) {\n    // Get the total and available VRAM\n    var vram Memory\n    vram.total = getVramTotal()\n    vram.available = getVramAvailable()\n\n    // Check if unified RAM is used\n    if vram.available &gt; unifiedRAM_THRESHOLD {\n        return 0, fmt.Errorf(\"unified RAM is used\")\n    }\n\n    return vram.available, nil\n}\n\nfunc main() {\n    memory, err := detectMemory()\n    if err != nil {\n        fmt.Println(err)\n    } else {\n        fmt.Printf(\"Available VRAM: %d bytes\\n\", memory)\n    }\n}\n\n// ... other functions to get total and available VRAM ...\n</code></pre>","tags":["AMD","Ollama","Memory Detection"]},{"location":"2026-01-04-new-amd-memory-detection-routines-ignores-unified-memory-on-amd-apu/#conclusion","title":"Conclusion","text":"<p>The updated memory detection routine will correctly identify the actual available VRAM on AMD APUs, even when unified RAM is used by ROCM and Vulkan. This fix ensures that Ollama accurately detects the memory constraints of the system, allowing for more efficient and effective model training.</p>","tags":["AMD","Ollama","Memory Detection"]},{"location":"2026-01-04-pulling-manifest-error/","title":"Resolving 'max retries exceeded' and 'file does not exist' Errors When Pulling Manifest","text":"","tags":["ollama","docker","manifest","errors"]},{"location":"2026-01-04-pulling-manifest-error/#core-problem","title":"Core Problem","text":"<p>The \"ollama run\" command fails with an error message indicating that the maximum number of retries has been exceeded due to an unexpected EOF (End Of File), followed by a failure to pull the model manifest, resulting in a file not existing error. This issue can be frustrating for users trying to deploy and train machine learning models.</p>","tags":["ollama","docker","manifest","errors"]},{"location":"2026-01-04-pulling-manifest-error/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To resolve this issue, we need to ensure that the system has sufficient memory resources to handle the Docker container's requirements. The recommended minimum memory requirement for running ollama is 32GB of CPU and GPU memory on a Macstation. Additionally, it's crucial to have enough free space on the hard drive.</p>","tags":["ollama","docker","manifest","errors"]},{"location":"2026-01-04-pulling-manifest-error/#solution-steps","title":"Solution Steps:","text":"<ol> <li>Check System Resources:</li> <li>Check your system's CPU and GPU memory usage.</li> <li>Ensure you have at least 32GB of total memory available (CPU + GPU).</li> <li>Update Docker and ollama Images:</li> <li>Run <code>docker pull --update docker/ollama:latest</code> to update the ollama image.</li> <li>Clear Download Directory:</li> <li>Remove any existing download directory or cache files related to ollama.</li> <li>Increase Memory Allocation for Docker Container:<ul> <li>Run the command with increased memory allocation, e.g., <code>OLLAMA_MEMORY=64G ollama run dolphin-mixtral:latest</code></li> </ul> </li> <li>Check Disk Space Availability:<ul> <li>Ensure there is sufficient free space on your hard drive (at least a few GB).</li> </ul> </li> </ol>","tags":["ollama","docker","manifest","errors"]},{"location":"2026-01-04-pulling-manifest-error/#example-code","title":"Example Code:","text":"<pre><code># Increase memory allocation for Docker container\nOLLAMA_MEMORY=64G ollama run dolphin-mixtral:latest\n\n# Clear download directory\nrm -rf ~/.ollama/download/\n\n# Update Docker and ollama images\ndocker pull --update docker/ollama:latest\n</code></pre>","tags":["ollama","docker","manifest","errors"]},{"location":"2026-01-04-pulling-manifest-error/#conclusion","title":"Conclusion","text":"<p>By following these steps, you should be able to resolve the 'max retries exceeded' and 'file does not exist' errors when pulling manifest. Ensure your system has sufficient memory resources and disk space available for optimal performance.</p>","tags":["ollama","docker","manifest","errors"]},{"location":"2026-01-04-pulling-manifest-error/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["ollama","docker","manifest","errors"]},{"location":"2026-01-04-reasoning-tokens-not-passing-through-from-openrouter-to-chatopenai/","title":"2026 01 04 reasoning tokens not passing through from openrouter to chatopenai","text":"<p>The error message indicates that there was an issue with the completion response from the Anthropic API. The native finish reason is 'stop', which suggests that the API encountered an error and stopped processing the request.</p> <p>To troubleshoot this issue, you can try the following:</p> <ol> <li>Check the API documentation to ensure that you are using the correct parameters and formatting.</li> <li>Verify that your token is valid and not expired.</li> <li>Try sending a new request with different parameters or formatting to see if the error persists.</li> <li>If you are using a caching mechanism, clear the cache and try again.</li> </ol> <p>Additionally, the output suggests that the API returned an error message indicating that your token was exposed in your PR description. This is likely a security warning from the Anthropic team, and it's recommended to rotate your token to prevent any potential security risks.</p> <p>To resolve this issue, you can take the following steps:</p> <ol> <li>Rotate your token by following the instructions provided by the Anthropic team.</li> <li>Review your code and ensure that you are not exposing sensitive information in your API requests.</li> <li>Implement proper error handling mechanisms to catch and handle any errors that may occur during API requests.</li> </ol> <p>By taking these steps, you should be able to resolve the issue and get back to generating content with the Anthropic API.</p>"},{"location":"2026-01-04-reasoning-tokens-not-passing-through-from-openrouter-to-chatopenai/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>"},{"location":"2026-01-04-scheduler-will-run-into-race-conditions-on-large-scale-clusters/","title":"2026 01 04 scheduler will run into race conditions on large scale clusters","text":"<p>A Catchy Title: \"Scheduler will run into race conditions on large scale clusters\" Tags: Kubernetes, Scheduler, Race Conditions, Large Scale Clusters</p>"},{"location":"2026-01-04-scheduler-will-run-into-race-conditions-on-large-scale-clusters/#understanding-the-issue-with-scheduler-in-large-scale-clusters","title":"Understanding the Issue with Scheduler in Large Scale Clusters","text":""},{"location":"2026-01-04-scheduler-will-run-into-race-conditions-on-large-scale-clusters/#core-problem","title":"Core Problem","text":"<p>The Kubernetes scheduler is prone to race conditions when dealing with large-scale clusters. This issue can lead to unexpected pod assignments and may have significant impacts on cluster stability.</p>"},{"location":"2026-01-04-scheduler-will-run-into-race-conditions-on-large-scale-clusters/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To mitigate this issue, we need to extend the 30-second timeout for bind operations and make it adaptable to cluster state. Here's a possible solution:</p> <pre><code>// Increased timeout for bind operation\nconst (\n    longBindTimeout = 60 * time.Second // 1 minute\n)\n\n// Update scheduler configuration\nfunc (s *Scheduler) Configure() {\n    s.config.Timeout.Bind = longBindTimeout\n}\n</code></pre> <p>Additionally, implementing a more robust and distributed approach to handling pod assignments can help reduce the likelihood of race conditions. This could involve using a centralized caching mechanism or load balancer to distribute the workload.</p>"},{"location":"2026-01-04-scheduler-will-run-into-race-conditions-on-large-scale-clusters/#conclusion","title":"Conclusion","text":"<p>The proposed solution involves increasing the timeout for bind operations and adapting it to cluster state. By doing so, we can minimize the impact of race conditions on large-scale clusters. Further research is needed to explore alternative solutions and identify best practices for mitigating this issue in Kubernetes clusters.</p> <p>Top Solution/Comment: @ahg-g: This issue is currently awaiting triage.</p> <p>If a SIG or subproject determines this is a relevant issue, they will accept it by applying the <code>triage/accepted</code> label and provide further guidance.</p> <p>The <code>triage/accepted</code> label can be added by org members by writing <code>/triage accepted</code> in a comment.</p> <p>Instructions for interacting with me using PR comments are available here.  If you have questions or suggestions related to my behavior, please file an issue against the kubernetes/test-infra repository.</p>"},{"location":"2026-01-04-scheduler-will-run-into-race-conditions-on-large-scale-clusters/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>"},{"location":"2026-01-04-support-for-multiple-images-in-chat-endpoint/","title":"Support for Multiple Images in /chat Endpoint","text":"","tags":["multiple-images","ollama-api","chat-endpoint"]},{"location":"2026-01-04-support-for-multiple-images-in-chat-endpoint/#core-problem","title":"Core Problem","text":"<p>The current implementation of the /chat endpoint only supports a single image, which introduces an additional layer of complexity when performing RAG (Reinforcement Algorithm with Gaze) with images embedded in base64.</p>","tags":["multiple-images","ollama-api","chat-endpoint"]},{"location":"2026-01-04-support-for-multiple-images-in-chat-endpoint/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To simplify this process, we can leverage existing libraries and frameworks that support multiple images. In the GitHub repository ollama/ollama, there is a note that ollama supports multiple images, but most models do not.</p> <p>For example, using the <code>base64</code> library in Python, we can pass multiple images in a single request:</p> <pre><code>$ for i in minicpm-v:8b-2.6-q4_K_M moondream:1.8b-v2-fp16 llava ; do \n  echo $i ; \n  echo '{\"model\": \"'$i'\",\n         \"messages\":[{\n            \"role\":\"user\",\"content\":\"describe the animals shown in the images\",\n            \"images\": [\n              \"'\"$(base64 puppy.jpg)\"'\",\n              \"'\"$(base64 kitten.jpg)\"'\"\n            ]\n          }],\n         \"stream\":false}' | curl -s http://localhost:11434/api/chat -d @- | jq -r .message.content ;\ndone\n</code></pre> <p>In this example, the <code>base64</code> library is used to encode the images and pass them in a single request. The response from the API can then be summarized into one.</p> <p>Another approach is to use the LLAVA model, which merges two images and describes a scene with multiple objects. This allows for more complex descriptions of scenes with multiple images.</p>","tags":["multiple-images","ollama-api","chat-endpoint"]},{"location":"2026-01-04-support-for-multiple-images-in-chat-endpoint/#conclusion","title":"Conclusion","text":"<p>Supporting multiple images in the /chat endpoint would greatly simplify workflows and reduce overhead in scenarios like RAG with images embedded in base64. While there is currently no plan to add this feature, existing libraries and frameworks can be used as a workaround.</p>","tags":["multiple-images","ollama-api","chat-endpoint"]},{"location":"2026-01-04-tokiofsfilewrite-returns-early-before-os-says-that-the-operation-is-completed/","title":"Understanding the Issue with Tokio's <code>File::write</code>","text":"","tags":["async programming","tokio-rs","file system operations"]},{"location":"2026-01-04-tokiofsfilewrite-returns-early-before-os-says-that-the-operation-is-completed/#core-problem","title":"Core Problem","text":"<p>When using Tokio's <code>File</code> API to perform file system operations asynchronously, a surprising behavior is observed. The <code>write</code> method of the <code>File</code> struct returns early before the operating system (OS) completes the write operation. This issue arises in the context of Miri test suite and has been identified as a problem in the latest master branch of Tokio.</p>","tags":["async programming","tokio-rs","file system operations"]},{"location":"2026-01-04-tokiofsfilewrite-returns-early-before-os-says-that-the-operation-is-completed/#solution-analysis","title":"Solution &amp; Analysis","text":"<pre><code>use tokio::fs::File;\nuse tokio::prelude::*;\n\n// Create a file with content \"some bytes\"\nlet mut file = File::create(\"example.txt\").await?;\nfile.write_all(b\"some bytes\").await?;\n\n// Verify that the written content is 10 bytes long\nassert_eq!(file.metadata().await.unwrap().len(), 5);\n</code></pre> <p>In this example, we observe that even though we await the completion of <code>write_all</code>, the metadata of the file still shows a length of 5 bytes instead of 10. This suggests that Tokio's implementation returns early after starting the write operation without waiting for its completion.</p> <pre><code>// Investigate how Tokio's File::write is implemented\n\n// The relevant part of the code\n\npub async fn write(\n    &amp;self,\n    buf: &amp;[u8],\n) -&gt; Result&lt;(), std::io::Error&gt; {\n    // Initialize an IO thread to perform the write operation\n    let write_task = tokio::task::spawn_blocking(move || {\n        self.write_to_inner(buf)\n    });\n\n    // Return immediately without waiting for the write task's completion\n    Ok(())\n}\n\n// Note that we do not wait for the completion of write_task here.\n</code></pre> <p>The provided code snippet from Tokio's <code>file.rs</code> reveals that <code>File::write</code> uses an IO thread to perform the write operation. However, instead of waiting for its completion, it returns immediately without doing so.</p>","tags":["async programming","tokio-rs","file system operations"]},{"location":"2026-01-04-tokiofsfilewrite-returns-early-before-os-says-that-the-operation-is-completed/#conclusion","title":"Conclusion","text":"<p>In conclusion, this behavior is a result of how Tokio's implementation handles asynchronous file system operations. By returning early before completing the OS write operation, Tokio's <code>File::write</code> method may cause issues with the ordering of concurrent operations.</p>","tags":["async programming","tokio-rs","file system operations"]},{"location":"2026-01-04-tokiofsfilewrite-returns-early-before-os-says-that-the-operation-is-completed/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["async programming","tokio-rs","file system operations"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/","title":"Tracking Issue for RFC 2045: Improving <code>#[target_feature]</code>","text":"","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/#core-problem","title":"Core Problem","text":"<p>The <code>#[target_feature]</code> attribute, introduced in RFC 2045, provides a way to conditionally compile code based on the target architecture's feature set. However, its usage and semantics are not yet fully stabilized.</p>","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/#solution-analysis","title":"Solution &amp; Analysis","text":"","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/#implementing-proposed-semantics","title":"Implementing Proposed Semantics","text":"<p>To implement the proposed <code>#[target_feature]</code> semantics, we need to add support for the following feature gates:</p> <pre><code>// Enable or disable features for a specific target\n#[cfg(target_feature = \"aarch64_unstable_target_feature\")]\nfn foo() {\n    // Code for aarch64_unstable_target_feature only\n}\n\n// Allow `#[target_feature]` on unsafe functions only\n#[unsafe_fn]\n#[cfg(target_feature = \"+feature\")]\nfn bar() {\n    // Code for the specified feature gate\n}\n</code></pre>","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/#documenting-semantics","title":"Documenting Semantics","text":"<p>The proposed semantics are documented in RFC 2045 and can be found at https://github.com/rust-lang/reference/pull/545.</p>","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/#stabilization-plan","title":"Stabilization Plan","text":"<p>To stabilize <code>#[target_feature]</code>, we need to:</p> <ol> <li> <p>Implement the basic set of features for x86_64 and i686: <pre><code>// Enable or disable features for a specific target (basic set)\n#[cfg(target_arch = \"x86_64\")]\nfn baz() {\n    // Code for x86_64\n}\n\n#[cfg(target_arch = \"i686\")]\nfn qux() {\n    // Code for i686\n}\n</code></pre></p> </li> <li> <p>Add support for ARM, AArch64, Hexagon, PowerPC, and MIPS: <pre><code>// Enable or disable features for a specific target (arm)\n#[cfg(target_feature = \"arm_target_feature\")]\nfn foo() {\n    // Code for arm\n}\n\n// Enable or disable features for a specific target (aarch64)\n#[cfg(target_feature = \"aarch64_ver_target_feature\")]\nfn bar() {\n    // Code for aarch64\n}\n</code></pre></p> </li> </ol>","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/#api-breaking-changes","title":"API Breaking Changes","text":"<p>To improve the stability of <code>#[target_feature]</code>, we need to make some API breaking changes:</p> <ol> <li> <p>Allow <code>#[target_feature]</code> on unsafe functions only: <pre><code>// Allow `#[target_feature]` on unsafe functions only\n#[unsafe_fn]\n#[cfg(target_feature = \"+feature\")]\nfn baz() {\n    // Code for the specified feature gate\n}\n</code></pre></p> </li> <li> <p>Change <code>#[target_feature = \"+feature\"]</code> to <code>#[target_feature(enable = \"feature\")]</code>: <pre><code>// Enable or disable features for a specific target (new syntax)\n#[cfg(target_feature(enable = \"feature\"))]\nfn qux() {\n    // Code for the specified feature gate\n}\n</code></pre></p> </li> </ol>","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/#related-tasks","title":"Related Tasks","text":"<p>To further improve <code>#[target_feature]</code>, we need to:</p> <ol> <li>Fix bug: https://github.com/rust-lang/rust/issues/42515</li> <li>Resolve bug: https://github.com/rust-lang/rust/issues/44367</li> <li>Implement runtime feature detection: <pre><code>// Runtime feature detection using the `cfg` macro\n#[cfg(feature = \"feature\")]\nfn foo() {\n    // Code for the specified feature gate\n}\n</code></pre></li> </ol>","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/#conclusion","title":"Conclusion","text":"<p>The <code>#[target_feature]</code> attribute is an essential tool for conditional compilation in Rust. By implementing the proposed semantics, documenting its usage, and making API breaking changes, we can improve its stability and usability.</p>","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["Rust Feature Gates","RFC 2045"]},{"location":"tags/","title":"Tags","text":"<ul> <li>AMD</li> <li>Memory Detection</li> <li>Ollama</li> <li>RFC 2045</li> <li>React 19.0.0</li> <li>React Hooks</li> <li>Rust Feature Gates</li> <li>State Management</li> <li>Transition Optimization</li> <li>actQueue</li> <li>apoc</li> <li>async programming</li> <li>chat-endpoint</li> <li>docker</li> <li>errors</li> <li>file system operations</li> <li>graph database</li> <li>infinite growth</li> <li>installation</li> <li>isr cache</li> <li>jinja2</li> <li>langchain</li> <li>langchain-ai</li> <li>manifest</li> <li>memory caching</li> <li>multiple-images</li> <li>neo4j</li> <li>next.js</li> <li>ollama</li> <li>ollama-api</li> <li>pandas</li> <li>rust-lang</li> <li>rustc-docs</li> <li>series</li> <li>sum</li> <li>templating</li> <li>tokio-rs</li> </ul>"},{"location":"tags/#tag:amd","title":"AMD","text":"<ul> <li>            AMD Memory Detection Routines Ignore Unified Memory on AMD APU          </li> </ul>"},{"location":"tags/#tag:memory-detection","title":"Memory Detection","text":"<ul> <li>            AMD Memory Detection Routines Ignore Unified Memory on AMD APU          </li> </ul>"},{"location":"tags/#tag:ollama","title":"Ollama","text":"<ul> <li>            AMD Memory Detection Routines Ignore Unified Memory on AMD APU          </li> </ul>"},{"location":"tags/#tag:rfc-2045","title":"RFC 2045","text":"<ul> <li>            Tracking Issue for RFC 2045: Improving `#[target_feature]`          </li> </ul>"},{"location":"tags/#tag:react-1900","title":"React 19.0.0","text":"<ul> <li>            React 19.0.0 actQueue Infinite Growth Bug          </li> </ul>"},{"location":"tags/#tag:react-hooks","title":"React Hooks","text":"<ul> <li>            Different Behaivor between useTransition and useDeferredValue in React          </li> </ul>"},{"location":"tags/#tag:rust-feature-gates","title":"Rust Feature Gates","text":"<ul> <li>            Tracking Issue for RFC 2045: Improving `#[target_feature]`          </li> </ul>"},{"location":"tags/#tag:state-management","title":"State Management","text":"<ul> <li>            Different Behaivor between useTransition and useDeferredValue in React          </li> </ul>"},{"location":"tags/#tag:transition-optimization","title":"Transition Optimization","text":"<ul> <li>            Different Behaivor between useTransition and useDeferredValue in React          </li> </ul>"},{"location":"tags/#tag:actqueue","title":"actQueue","text":"<ul> <li>            React 19.0.0 actQueue Infinite Growth Bug          </li> </ul>"},{"location":"tags/#tag:apoc","title":"apoc","text":"<ul> <li>            Resolving APOC Procedures Error in Langchain with Neo4j v5.9          </li> </ul>"},{"location":"tags/#tag:async-programming","title":"async programming","text":"<ul> <li>            Why Tokio's `File::write` Returns Early Before OS Completes the Operation          </li> </ul>"},{"location":"tags/#tag:chat-endpoint","title":"chat-endpoint","text":"<ul> <li>            Support for Multiple Images in /chat Endpoint          </li> </ul>"},{"location":"tags/#tag:docker","title":"docker","text":"<ul> <li>            Resolving 'max retries exceeded' and 'file does not exist' Errors When Pulling Manifest          </li> </ul>"},{"location":"tags/#tag:errors","title":"errors","text":"<ul> <li>            Resolving 'max retries exceeded' and 'file does not exist' Errors When Pulling Manifest          </li> </ul>"},{"location":"tags/#tag:file-system-operations","title":"file system operations","text":"<ul> <li>            Why Tokio's `File::write` Returns Early Before OS Completes the Operation          </li> </ul>"},{"location":"tags/#tag:graph-database","title":"graph database","text":"<ul> <li>            Resolving APOC Procedures Error in Langchain with Neo4j v5.9          </li> </ul>"},{"location":"tags/#tag:infinite-growth","title":"infinite growth","text":"<ul> <li>            React 19.0.0 actQueue Infinite Growth Bug          </li> </ul>"},{"location":"tags/#tag:installation","title":"installation","text":"<ul> <li>            Can't Install rustc-docs Component: Resolving the Conflict          </li> </ul>"},{"location":"tags/#tag:isr-cache","title":"isr cache","text":"<ul> <li>            ISR Fails to Serve 404 Pages After Page Deletion with Experimental ISR Memory Cache Size Set to 0          </li> </ul>"},{"location":"tags/#tag:jinja2","title":"jinja2","text":"<ul> <li>            Jinja2 loop.index0 blocked by RestrictedSandboxedEnvironment in LangChain          </li> </ul>"},{"location":"tags/#tag:langchain","title":"langchain","text":"<ul> <li>            Resolving APOC Procedures Error in Langchain with Neo4j v5.9          </li> </ul>"},{"location":"tags/#tag:langchain-ai","title":"langchain-ai","text":"<ul> <li>            Jinja2 loop.index0 blocked by RestrictedSandboxedEnvironment in LangChain          </li> </ul>"},{"location":"tags/#tag:manifest","title":"manifest","text":"<ul> <li>            Resolving 'max retries exceeded' and 'file does not exist' Errors When Pulling Manifest          </li> </ul>"},{"location":"tags/#tag:memory-caching","title":"memory caching","text":"<ul> <li>            ISR Fails to Serve 404 Pages After Page Deletion with Experimental ISR Memory Cache Size Set to 0          </li> </ul>"},{"location":"tags/#tag:multiple-images","title":"multiple-images","text":"<ul> <li>            Support for Multiple Images in /chat Endpoint          </li> </ul>"},{"location":"tags/#tag:neo4j","title":"neo4j","text":"<ul> <li>            Resolving APOC Procedures Error in Langchain with Neo4j v5.9          </li> </ul>"},{"location":"tags/#tag:nextjs","title":"next.js","text":"<ul> <li>            ISR Fails to Serve 404 Pages After Page Deletion with Experimental ISR Memory Cache Size Set to 0          </li> </ul>"},{"location":"tags/#tag:ollama","title":"ollama","text":"<ul> <li>            Resolving 'max retries exceeded' and 'file does not exist' Errors When Pulling Manifest          </li> </ul>"},{"location":"tags/#tag:ollama-api","title":"ollama-api","text":"<ul> <li>            Support for Multiple Images in /chat Endpoint          </li> </ul>"},{"location":"tags/#tag:pandas","title":"pandas","text":"<ul> <li>            Pandas Series.sum() Misrepresentation in Documentation          </li> </ul>"},{"location":"tags/#tag:rust-lang","title":"rust-lang","text":"<ul> <li>            Can't Install rustc-docs Component: Resolving the Conflict          </li> </ul>"},{"location":"tags/#tag:rustc-docs","title":"rustc-docs","text":"<ul> <li>            Can't Install rustc-docs Component: Resolving the Conflict          </li> </ul>"},{"location":"tags/#tag:series","title":"series","text":"<ul> <li>            Pandas Series.sum() Misrepresentation in Documentation          </li> </ul>"},{"location":"tags/#tag:sum","title":"sum","text":"<ul> <li>            Pandas Series.sum() Misrepresentation in Documentation          </li> </ul>"},{"location":"tags/#tag:templating","title":"templating","text":"<ul> <li>            Jinja2 loop.index0 blocked by RestrictedSandboxedEnvironment in LangChain          </li> </ul>"},{"location":"tags/#tag:tokio-rs","title":"tokio-rs","text":"<ul> <li>            Why Tokio's `File::write` Returns Early Before OS Completes the Operation          </li> </ul>"}]}