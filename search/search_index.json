{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Index by Tag","text":""},{"location":"#amd","title":"AMD","text":"<ul> <li>AMD Memory Detection Routines Ignore Unified Memory on AMD APU</li> </ul>"},{"location":"#dra","title":"DRA","text":"<ul> <li>Introducing Permanent and Transient Error Handling in kubelet</li> </ul>"},{"location":"#dra-drivers","title":"DRA drivers","text":"<ul> <li>Surface Permanent Errors in Kubelet and DRA Drivers</li> </ul>"},{"location":"#debugging","title":"Debugging","text":"<ul> <li>TSServer Exited. Code: null. Signal: SIGTERM - A Troubleshooting Guide</li> </ul>"},{"location":"#deep-learning","title":"Deep Learning","text":"<ul> <li>Unlocking CPU Potential in Model-Driven Applications</li> </ul>"},{"location":"#deepseek-r1","title":"DeepSeek-R1","text":"<ul> <li>DeepSeek-R1 671B Q4_K_M Error: Model Requires More System Memory Than Available</li> </ul>"},{"location":"#image-pull-issues","title":"Image Pull Issues","text":"<ul> <li>Detecting and Handling Stuck Pods due to Invalid Image Pulls</li> </ul>"},{"location":"#image-validation","title":"Image Validation","text":"<ul> <li>Failing Stuck Pods due to Invalid Images: A Mechanism for Rescue</li> </ul>"},{"location":"#kubernetes","title":"Kubernetes","text":"<ul> <li>Pods with Zero TerminationGracePeriod are Force-Deleted</li> <li>Introducing Permanent and Transient Error Handling in kubelet</li> <li>Surface Permanent Errors in Kubelet and DRA Drivers</li> <li>Enabling Label Selector Support in Resource Quota's ScopeSelector</li> <li>Detecting and Handling Stuck Pods due to Invalid Image Pulls</li> <li>Racing to Zero: Mitigating Race Conditions in Kubernetes Schedulers</li> <li>Failing Stuck Pods due to Invalid Images: A Mechanism for Rescue</li> </ul>"},{"location":"#linux","title":"Linux","text":"<ul> <li>TcpStream::set_linger Can Lead to Blocking in Tokio</li> </ul>"},{"location":"#memory-detection","title":"Memory Detection","text":"<ul> <li>AMD Memory Detection Routines Ignore Unified Memory on AMD APU</li> </ul>"},{"location":"#moe-architecture","title":"MoE Architecture","text":"<ul> <li>DeepSeek-R1 671B Q4_K_M Error: Model Requires More System Memory Than Available</li> </ul>"},{"location":"#model-optimization","title":"Model Optimization","text":"<ul> <li>Unlocking CPU Potential in Model-Driven Applications</li> </ul>"},{"location":"#modulenotfounderror","title":"ModuleNotFoundError","text":"<ul> <li>ModuleNotFoundError: No module named 'langchain.schema</li> </ul>"},{"location":"#ollama","title":"Ollama","text":"<ul> <li>AMD Memory Detection Routines Ignore Unified Memory on AMD APU</li> </ul>"},{"location":"#performance-optimization","title":"Performance Optimization","text":"<ul> <li>Racing to Zero: Mitigating Race Conditions in Kubernetes Schedulers</li> </ul>"},{"location":"#pod-failure","title":"Pod Failure","text":"<ul> <li>Detecting and Handling Stuck Pods due to Invalid Image Pulls</li> <li>Failing Stuck Pods due to Invalid Images: A Mechanism for Rescue</li> </ul>"},{"location":"#pod-termination","title":"Pod Termination","text":"<ul> <li>Pods with Zero TerminationGracePeriod are Force-Deleted</li> </ul>"},{"location":"#python","title":"Python","text":"<ul> <li>ModuleNotFoundError: No module named 'langchain.schema</li> </ul>"},{"location":"#quotas","title":"Quotas","text":"<ul> <li>Enabling Label Selector Support in Resource Quota's ScopeSelector</li> </ul>"},{"location":"#rfc-2045","title":"RFC 2045","text":"<ul> <li>Tracking Issue for RFC 2045: Improving <code>#[target_feature]</code></li> </ul>"},{"location":"#react-1900","title":"React 19.0.0","text":"<ul> <li>React 19.0.0 actQueue Infinite Growth Bug</li> </ul>"},{"location":"#react-hooks","title":"React Hooks","text":"<ul> <li>Different Behavior between useTransition and useDeferredValue in React</li> <li>Different Behaivor between useTransition and useDeferredValue in React</li> </ul>"},{"location":"#rust","title":"Rust","text":"<ul> <li>Backwards-Incompatible Assert Desugaring Change in Rust</li> <li>tokio::fs::File::write Returns Early Before OS Says Operation is Completed</li> </ul>"},{"location":"#rust-feature-gates","title":"Rust Feature Gates","text":"<ul> <li>Tracking Issue for RFC 2045: Improving <code>#[target_feature]</code></li> </ul>"},{"location":"#so_linger","title":"SO_LINGER","text":"<ul> <li>TcpStream::set_linger Can Lead to Blocking in Tokio</li> </ul>"},{"location":"#scheduler","title":"Scheduler","text":"<ul> <li>Racing to Zero: Mitigating Race Conditions in Kubernetes Schedulers</li> </ul>"},{"location":"#scopeselector","title":"ScopeSelector","text":"<ul> <li>Enabling Label Selector Support in Resource Quota's ScopeSelector</li> </ul>"},{"location":"#state-management","title":"State Management","text":"<ul> <li>Different Behavior between useTransition and useDeferredValue in React</li> <li>Different Behaivor between useTransition and useDeferredValue in React</li> </ul>"},{"location":"#statefulsets","title":"StatefulSets","text":"<ul> <li>Pods with Zero TerminationGracePeriod are Force-Deleted</li> </ul>"},{"location":"#tsc-server","title":"TSC Server","text":"<ul> <li>TSServer Exited. Code: null. Signal: SIGTERM - A Troubleshooting Guide</li> </ul>"},{"location":"#tcpstream","title":"TcpStream","text":"<ul> <li>TcpStream::set_linger Can Lead to Blocking in Tokio</li> </ul>"},{"location":"#transition-optimization","title":"Transition Optimization","text":"<ul> <li>Different Behaivor between useTransition and useDeferredValue in React</li> </ul>"},{"location":"#transitioning","title":"Transitioning","text":"<ul> <li>Different Behavior between useTransition and useDeferredValue in React</li> </ul>"},{"location":"#typescript","title":"TypeScript","text":"<ul> <li>TSServer Exited. Code: null. Signal: SIGTERM - A Troubleshooting Guide</li> </ul>"},{"location":"#vscode","title":"VSCode","text":"<ul> <li>TSServer Exited. Code: null. Signal: SIGTERM - A Troubleshooting Guide</li> </ul>"},{"location":"#actqueue","title":"actQueue","text":"<ul> <li>React 19.0.0 actQueue Infinite Growth Bug</li> </ul>"},{"location":"#apoc","title":"apoc","text":"<ul> <li>Resolving APOC Procedures Error in Langchain with Neo4j v5.9</li> </ul>"},{"location":"#apple-silicon","title":"apple-silicon","text":"<ul> <li>Wrong Architecture Objects Mixed in Self-Built Compiler on Apple Silicon Hosts</li> </ul>"},{"location":"#assert-desugaring","title":"assert desugaring","text":"<ul> <li>Backwards-Incompatible Assert Desugaring Change in Rust</li> </ul>"},{"location":"#async-programming","title":"async programming","text":"<ul> <li>A System Crash in Tokio-based Systems</li> <li>A catchy, SEO-friendly title</li> <li>Why Tokio's <code>File::write</code> Returns Early Before OS Completes the Operation</li> </ul>"},{"location":"#asynchronous-programming","title":"asynchronous programming","text":"<ul> <li>tokio::fs::File::write Returns Early Before OS Says Operation is Completed</li> </ul>"},{"location":"#autodiff","title":"autodiff","text":"<ul> <li>Building Rust from Source with Autodiff on Mac OS</li> <li>Building Rust with Autodiff on Mac OS Fails</li> </ul>"},{"location":"#backwards-incompatibility","title":"backwards-incompatibility","text":"<ul> <li>Backwards-Incompatible Assert Desugaring Change in Rust</li> </ul>"},{"location":"#bug","title":"bug","text":"<ul> <li>Pandas Rounding Issue: Empty Series Should Return Empty Series</li> </ul>"},{"location":"#chat-endpoint","title":"chat-endpoint","text":"<ul> <li>Support for Multiple Images in /chat Endpoint</li> </ul>"},{"location":"#compiler","title":"compiler","text":"<ul> <li>Wrong Architecture Objects Mixed in Self-Built Compiler on Apple Silicon Hosts</li> </ul>"},{"location":"#conflict","title":"conflict","text":"<ul> <li>Resolving the 'rustc-docs' Installation Conflict in Rust</li> </ul>"},{"location":"#data-manipulation","title":"data manipulation","text":"<ul> <li>Rounding Errors in Pandas Series: A Potential Pitfall</li> </ul>"},{"location":"#debug-builds","title":"debug builds","text":"<ul> <li>A bug in RISC-V compilation with -C force-frame-pointers=yes and opt-level = 'z</li> </ul>"},{"location":"#deepseek-r1_1","title":"deepseek-r1","text":"<ul> <li>Error When Downloading DeepSeek-R1:7b with Ollama</li> </ul>"},{"location":"#docker","title":"docker","text":"<ul> <li>Resolving 'max retries exceeded' and 'file does not exist' Errors When Pulling Manifest</li> </ul>"},{"location":"#downloading","title":"downloading","text":"<ul> <li>Error When Downloading DeepSeek-R1:7b with Ollama</li> </ul>"},{"location":"#duplicate-paths","title":"duplicate-paths","text":"<ul> <li>Route Interception Issues in Next.js with Duplicate Paths</li> </ul>"},{"location":"#errors","title":"errors","text":"<ul> <li>Resolving 'max retries exceeded' and 'file does not exist' Errors When Pulling Manifest</li> </ul>"},{"location":"#fetch","title":"fetch","text":"<ul> <li>Fetch Request Memoization Not Working When Cookies Function Imported</li> </ul>"},{"location":"#file-system-operations","title":"file system operations","text":"<ul> <li>Why Tokio's <code>File::write</code> Returns Early Before OS Completes the Operation</li> </ul>"},{"location":"#force-frame-pointersyes","title":"force-frame-pointers=yes","text":"<ul> <li>A stacktrace in RISC-V builds with <code>force-frame-pointers=yes</code> and <code>opt-level=z</code>: The Unexplained Disappearance</li> </ul>"},{"location":"#frame-pointers","title":"frame-pointers","text":"<ul> <li>A bug in RISC-V compilation with -C force-frame-pointers=yes and opt-level = 'z</li> </ul>"},{"location":"#getinitialprops","title":"getInitialProps","text":"<ul> <li>Pages Router + getInitialProps = Static worker unexpectedly</li> </ul>"},{"location":"#graph-database","title":"graph database","text":"<ul> <li>Resolving APOC Procedures Error in Langchain with Neo4j v5.9</li> </ul>"},{"location":"#html-parsing","title":"html-parsing","text":"<ul> <li>Support ReaderLM-v2 for Efficient HTML Parsing and Text Extraction</li> </ul>"},{"location":"#infinite-growth","title":"infinite growth","text":"<ul> <li>React 19.0.0 actQueue Infinite Growth Bug</li> </ul>"},{"location":"#installation","title":"installation","text":"<ul> <li>Resolving the 'rustc-docs' Installation Conflict in Rust</li> <li>Can't Install rustc-docs Component: Resolving the Conflict</li> </ul>"},{"location":"#isr-cache","title":"isr cache","text":"<ul> <li>ISR Fails to Serve 404 Pages After Page Deletion with Experimental ISR Memory Cache Size Set to 0</li> </ul>"},{"location":"#jinja2","title":"jinja2","text":"<ul> <li>Jinja2 loop.index0 blocked by RestrictedSandboxedEnvironment in LangChain</li> </ul>"},{"location":"#keyword1","title":"keyword1","text":"<ul> <li>Fixing the Busy Wait Loop in Repro</li> </ul>"},{"location":"#keyword2","title":"keyword2","text":"<ul> <li>Fixing the Busy Wait Loop in Repro</li> </ul>"},{"location":"#kubelet","title":"kubelet","text":"<ul> <li>Introducing Permanent and Transient Error Handling in kubelet</li> <li>Surface Permanent Errors in Kubelet and DRA Drivers</li> </ul>"},{"location":"#langchain","title":"langchain","text":"<ul> <li>ModuleNotFoundError: No module named 'langchain.schema</li> <li>Resolving APOC Procedures Error in Langchain with Neo4j v5.9</li> </ul>"},{"location":"#langchain-ai","title":"langchain-ai","text":"<ul> <li>Jinja2 loop.index0 blocked by RestrictedSandboxedEnvironment in LangChain</li> </ul>"},{"location":"#mac-os","title":"mac os","text":"<ul> <li>Building Rust from Source with Autodiff on Mac OS</li> <li>Building Rust with Autodiff on Mac OS Fails</li> </ul>"},{"location":"#manifest","title":"manifest","text":"<ul> <li>Resolving 'max retries exceeded' and 'file does not exist' Errors When Pulling Manifest</li> </ul>"},{"location":"#manifest-errors","title":"manifest errors","text":"<ul> <li>Resolving Pull Manifest Errors in Ollama</li> </ul>"},{"location":"#memoization","title":"memoization","text":"<ul> <li>Fetch Request Memoization Not Working When Cookies Function Imported</li> </ul>"},{"location":"#memory-caching","title":"memory caching","text":"<ul> <li>ISR Fails to Serve 404 Pages After Page Deletion with Experimental ISR Memory Cache Size Set to 0</li> </ul>"},{"location":"#multiple-images","title":"multiple-images","text":"<ul> <li>Support for Multiple Images in /chat Endpoint</li> </ul>"},{"location":"#neo4j","title":"neo4j","text":"<ul> <li>Resolving APOC Procedures Error in Langchain with Neo4j v5.9</li> </ul>"},{"location":"#nextjs","title":"next.js","text":"<ul> <li>Pages Router + getInitialProps = Static worker unexpectedly</li> <li>ISR Fails to Serve 404 Pages After Page Deletion with Experimental ISR Memory Cache Size Set to 0</li> </ul>"},{"location":"#nextjs_1","title":"nextjs","text":"<ul> <li>Route Interception Issues in Next.js with Duplicate Paths</li> <li>Fetch Request Memoization Not Working When Cookies Function Imported</li> </ul>"},{"location":"#ollama_1","title":"ollama","text":"<ul> <li>Error When Downloading DeepSeek-R1:7b with Ollama</li> <li>DeepSeek-R1 671B Q4_K_M Error: Model Requires More System Memory Than Available</li> <li>Resolving Pull Manifest Errors in Ollama</li> <li>Resolving 'max retries exceeded' and 'file does not exist' Errors When Pulling Manifest</li> </ul>"},{"location":"#ollama-api","title":"ollama-api","text":"<ul> <li>Support for Multiple Images in /chat Endpoint</li> </ul>"},{"location":"#opt-levelz","title":"opt-level=z","text":"<ul> <li>A stacktrace in RISC-V builds with <code>force-frame-pointers=yes</code> and <code>opt-level=z</code>: The Unexplained Disappearance</li> </ul>"},{"location":"#pandas","title":"pandas","text":"<ul> <li>Series.replace not working on slices of heterogeneous types</li> <li>Rounding Errors in Pandas Series: A Potential Pitfall</li> <li>Pandas Rounding Issue: Empty Series Should Return Empty Series</li> <li>Pandas Series.sum() Examples Fail to Illustrate Actual Results</li> <li>Pandas Series.sum() Misrepresentation in Documentation</li> </ul>"},{"location":"#release-builds","title":"release builds","text":"<ul> <li>A bug in RISC-V compilation with -C force-frame-pointers=yes and opt-level = 'z</li> </ul>"},{"location":"#replace","title":"replace","text":"<ul> <li>Series.replace not working on slices of heterogeneous types</li> </ul>"},{"location":"#riscv32imc-unknown-none-elf","title":"riscv32imc-unknown-none-elf","text":"<ul> <li>A bug in RISC-V compilation with -C force-frame-pointers=yes and opt-level = 'z</li> <li>A stacktrace in RISC-V builds with <code>force-frame-pointers=yes</code> and <code>opt-level=z</code>: The Unexplained Disappearance</li> </ul>"},{"location":"#rounding","title":"rounding","text":"<ul> <li>Rounding Errors in Pandas Series: A Potential Pitfall</li> <li>Pandas Rounding Issue: Empty Series Should Return Empty Series</li> </ul>"},{"location":"#route-interception","title":"route-interception","text":"<ul> <li>Route Interception Issues in Next.js with Duplicate Paths</li> </ul>"},{"location":"#rust_1","title":"rust","text":"<ul> <li>Building Rust from Source with Autodiff on Mac OS</li> <li>Resolving the 'rustc-docs' Installation Conflict in Rust</li> <li>Building Rust with Autodiff on Mac OS Fails</li> </ul>"},{"location":"#rust-lang","title":"rust-lang","text":"<ul> <li>Wrong Architecture Objects Mixed in Self-Built Compiler on Apple Silicon Hosts</li> <li>Can't Install rustc-docs Component: Resolving the Conflict</li> </ul>"},{"location":"#rustc-docs","title":"rustc-docs","text":"<ul> <li>Can't Install rustc-docs Component: Resolving the Conflict</li> </ul>"},{"location":"#series","title":"series","text":"<ul> <li>Series.replace not working on slices of heterogeneous types</li> <li>Pandas Series.sum() Examples Fail to Illustrate Actual Results</li> <li>Pandas Series.sum() Misrepresentation in Documentation</li> </ul>"},{"location":"#static-worker","title":"static-worker","text":"<ul> <li>Pages Router + getInitialProps = Static worker unexpectedly</li> </ul>"},{"location":"#sum","title":"sum","text":"<ul> <li>Pandas Series.sum() Examples Fail to Illustrate Actual Results</li> <li>Pandas Series.sum() Misrepresentation in Documentation</li> </ul>"},{"location":"#system-crashes","title":"system crashes","text":"<ul> <li>A System Crash in Tokio-based Systems</li> </ul>"},{"location":"#templating","title":"templating","text":"<ul> <li>Jinja2 loop.index0 blocked by RestrictedSandboxedEnvironment in LangChain</li> </ul>"},{"location":"#text-extraction","title":"text-extraction","text":"<ul> <li>Support ReaderLM-v2 for Efficient HTML Parsing and Text Extraction</li> </ul>"},{"location":"#thread-safety","title":"thread safety","text":"<ul> <li>A catchy, SEO-friendly title</li> </ul>"},{"location":"#tokio","title":"tokio","text":"<ul> <li>TcpStream::set_linger Can Lead to Blocking in Tokio</li> <li>tokio::fs::File::write Returns Early Before OS Says Operation is Completed</li> </ul>"},{"location":"#tokio-runtime","title":"tokio runtime","text":"<ul> <li>A catchy, SEO-friendly title</li> </ul>"},{"location":"#tokio-147","title":"tokio-1.47","text":"<ul> <li>A System Crash in Tokio-based Systems</li> </ul>"},{"location":"#tokio-rs","title":"tokio-rs","text":"<ul> <li>Why Tokio's <code>File::write</code> Returns Early Before OS Completes the Operation</li> </ul>"},{"location":"#transformer-based","title":"transformer-based","text":"<ul> <li>Support ReaderLM-v2 for Efficient HTML Parsing and Text Extraction</li> </ul>"},{"location":"#wait-loop","title":"wait-loop","text":"<ul> <li>Fixing the Busy Wait Loop in Repro</li> </ul>"},{"location":"#tag:amd","title":"AMD","text":"<ul> <li>            AMD Memory Detection Routines Ignore Unified Memory on AMD APU          </li> </ul>"},{"location":"#tag:dra","title":"DRA","text":"<ul> <li>            Introducing Permanent and Transient Error Handling in kubelet          </li> </ul>"},{"location":"#tag:dra-drivers","title":"DRA drivers","text":"<ul> <li>            Surface Permanent Errors in Kubelet and DRA Drivers          </li> </ul>"},{"location":"#tag:debugging","title":"Debugging","text":"<ul> <li>            TSServer Exited. Code: null. Signal: SIGTERM - A Troubleshooting Guide          </li> </ul>"},{"location":"#tag:deep-learning","title":"Deep Learning","text":"<ul> <li>            Unlocking CPU Potential in Model-Driven Applications          </li> </ul>"},{"location":"#tag:deepseek-r1","title":"DeepSeek-R1","text":"<ul> <li>            DeepSeek-R1 671B Q4_K_M Error: Model Requires More System Memory Than Available          </li> </ul>"},{"location":"#tag:image-pull-issues","title":"Image Pull Issues","text":"<ul> <li>            Detecting and Handling Stuck Pods due to Invalid Image Pulls          </li> </ul>"},{"location":"#tag:image-validation","title":"Image Validation","text":"<ul> <li>            Failing Stuck Pods due to Invalid Images: A Mechanism for Rescue          </li> </ul>"},{"location":"#tag:kubernetes","title":"Kubernetes","text":"<ul> <li>            Detecting and Handling Stuck Pods due to Invalid Image Pulls          </li> <li>            Enabling Label Selector Support in Resource Quota's ScopeSelector          </li> <li>            Failing Stuck Pods due to Invalid Images: A Mechanism for Rescue          </li> <li>            Introducing Permanent and Transient Error Handling in kubelet          </li> <li>            Pods with Zero TerminationGracePeriod are Force-Deleted          </li> <li>            Racing to Zero: Mitigating Race Conditions in Kubernetes Schedulers          </li> <li>            Surface Permanent Errors in Kubelet and DRA Drivers          </li> </ul>"},{"location":"#tag:linux","title":"Linux","text":"<ul> <li>            TcpStream::set_linger Can Lead to Blocking in Tokio          </li> </ul>"},{"location":"#tag:memory-detection","title":"Memory Detection","text":"<ul> <li>            AMD Memory Detection Routines Ignore Unified Memory on AMD APU          </li> </ul>"},{"location":"#tag:moe-architecture","title":"MoE Architecture","text":"<ul> <li>            DeepSeek-R1 671B Q4_K_M Error: Model Requires More System Memory Than Available          </li> </ul>"},{"location":"#tag:model-optimization","title":"Model Optimization","text":"<ul> <li>            Unlocking CPU Potential in Model-Driven Applications          </li> </ul>"},{"location":"#tag:modulenotfounderror","title":"ModuleNotFoundError","text":"<ul> <li>            ModuleNotFoundError: No module named 'langchain.schema'          </li> </ul>"},{"location":"#tag:ollama","title":"Ollama","text":"<ul> <li>            AMD Memory Detection Routines Ignore Unified Memory on AMD APU          </li> </ul>"},{"location":"#tag:performance-optimization","title":"Performance Optimization","text":"<ul> <li>            Racing to Zero: Mitigating Race Conditions in Kubernetes Schedulers          </li> </ul>"},{"location":"#tag:pod-failure","title":"Pod Failure","text":"<ul> <li>            Detecting and Handling Stuck Pods due to Invalid Image Pulls          </li> <li>            Failing Stuck Pods due to Invalid Images: A Mechanism for Rescue          </li> </ul>"},{"location":"#tag:pod-termination","title":"Pod Termination","text":"<ul> <li>            Pods with Zero TerminationGracePeriod are Force-Deleted          </li> </ul>"},{"location":"#tag:python","title":"Python","text":"<ul> <li>            ModuleNotFoundError: No module named 'langchain.schema'          </li> </ul>"},{"location":"#tag:quotas","title":"Quotas","text":"<ul> <li>            Enabling Label Selector Support in Resource Quota's ScopeSelector          </li> </ul>"},{"location":"#tag:rfc-2045","title":"RFC 2045","text":"<ul> <li>            Tracking Issue for RFC 2045: Improving `#[target_feature]`          </li> </ul>"},{"location":"#tag:react-1900","title":"React 19.0.0","text":"<ul> <li>            React 19.0.0 actQueue Infinite Growth Bug          </li> </ul>"},{"location":"#tag:react-hooks","title":"React Hooks","text":"<ul> <li>            Different Behaivor between useTransition and useDeferredValue in React          </li> <li>            Different Behavior between useTransition and useDeferredValue in React          </li> </ul>"},{"location":"#tag:rust","title":"Rust","text":"<ul> <li>            Backwards-Incompatible Assert Desugaring Change in Rust          </li> <li>            tokio::fs::File::write Returns Early Before OS Says Operation is Completed          </li> </ul>"},{"location":"#tag:rust-feature-gates","title":"Rust Feature Gates","text":"<ul> <li>            Tracking Issue for RFC 2045: Improving `#[target_feature]`          </li> </ul>"},{"location":"#tag:so_linger","title":"SO_LINGER","text":"<ul> <li>            TcpStream::set_linger Can Lead to Blocking in Tokio          </li> </ul>"},{"location":"#tag:scheduler","title":"Scheduler","text":"<ul> <li>            Racing to Zero: Mitigating Race Conditions in Kubernetes Schedulers          </li> </ul>"},{"location":"#tag:scopeselector","title":"ScopeSelector","text":"<ul> <li>            Enabling Label Selector Support in Resource Quota's ScopeSelector          </li> </ul>"},{"location":"#tag:state-management","title":"State Management","text":"<ul> <li>            Different Behaivor between useTransition and useDeferredValue in React          </li> <li>            Different Behavior between useTransition and useDeferredValue in React          </li> </ul>"},{"location":"#tag:statefulsets","title":"StatefulSets","text":"<ul> <li>            Pods with Zero TerminationGracePeriod are Force-Deleted          </li> </ul>"},{"location":"#tag:tsc-server","title":"TSC Server","text":"<ul> <li>            TSServer Exited. Code: null. Signal: SIGTERM - A Troubleshooting Guide          </li> </ul>"},{"location":"#tag:tcpstream","title":"TcpStream","text":"<ul> <li>            TcpStream::set_linger Can Lead to Blocking in Tokio          </li> </ul>"},{"location":"#tag:transition-optimization","title":"Transition Optimization","text":"<ul> <li>            Different Behaivor between useTransition and useDeferredValue in React          </li> </ul>"},{"location":"#tag:transitioning","title":"Transitioning","text":"<ul> <li>            Different Behavior between useTransition and useDeferredValue in React          </li> </ul>"},{"location":"#tag:typescript","title":"TypeScript","text":"<ul> <li>            TSServer Exited. Code: null. Signal: SIGTERM - A Troubleshooting Guide          </li> </ul>"},{"location":"#tag:vscode","title":"VSCode","text":"<ul> <li>            TSServer Exited. Code: null. Signal: SIGTERM - A Troubleshooting Guide          </li> </ul>"},{"location":"#tag:actqueue","title":"actQueue","text":"<ul> <li>            React 19.0.0 actQueue Infinite Growth Bug          </li> </ul>"},{"location":"#tag:apoc","title":"apoc","text":"<ul> <li>            Resolving APOC Procedures Error in Langchain with Neo4j v5.9          </li> </ul>"},{"location":"#tag:apple-silicon","title":"apple-silicon","text":"<ul> <li>            Wrong Architecture Objects Mixed in Self-Built Compiler on Apple Silicon Hosts          </li> </ul>"},{"location":"#tag:assert-desugaring","title":"assert desugaring","text":"<ul> <li>            Backwards-Incompatible Assert Desugaring Change in Rust          </li> </ul>"},{"location":"#tag:async-programming","title":"async programming","text":"<ul> <li>            A System Crash in Tokio-based Systems          </li> <li>            A catchy, SEO-friendly title          </li> <li>            Why Tokio's `File::write` Returns Early Before OS Completes the Operation          </li> </ul>"},{"location":"#tag:asynchronous-programming","title":"asynchronous programming","text":"<ul> <li>            tokio::fs::File::write Returns Early Before OS Says Operation is Completed          </li> </ul>"},{"location":"#tag:autodiff","title":"autodiff","text":"<ul> <li>            Building Rust from Source with Autodiff on Mac OS          </li> <li>            Building Rust with Autodiff on Mac OS Fails          </li> </ul>"},{"location":"#tag:backwards-incompatibility","title":"backwards-incompatibility","text":"<ul> <li>            Backwards-Incompatible Assert Desugaring Change in Rust          </li> </ul>"},{"location":"#tag:bug","title":"bug","text":"<ul> <li>            Pandas Rounding Issue: Empty Series Should Return Empty Series          </li> </ul>"},{"location":"#tag:chat-endpoint","title":"chat-endpoint","text":"<ul> <li>            Support for Multiple Images in /chat Endpoint          </li> </ul>"},{"location":"#tag:compiler","title":"compiler","text":"<ul> <li>            Wrong Architecture Objects Mixed in Self-Built Compiler on Apple Silicon Hosts          </li> </ul>"},{"location":"#tag:conflict","title":"conflict","text":"<ul> <li>            Resolving the 'rustc-docs' Installation Conflict in Rust          </li> </ul>"},{"location":"#tag:data-manipulation","title":"data manipulation","text":"<ul> <li>            Rounding Errors in Pandas Series: A Potential Pitfall          </li> </ul>"},{"location":"#tag:debug-builds","title":"debug builds","text":"<ul> <li>            A bug in RISC-V compilation with -C force-frame-pointers=yes and opt-level = 'z'          </li> </ul>"},{"location":"#tag:deepseek-r1","title":"deepseek-r1","text":"<ul> <li>            Error When Downloading DeepSeek-R1:7b with Ollama          </li> </ul>"},{"location":"#tag:docker","title":"docker","text":"<ul> <li>            Resolving 'max retries exceeded' and 'file does not exist' Errors When Pulling Manifest          </li> </ul>"},{"location":"#tag:downloading","title":"downloading","text":"<ul> <li>            Error When Downloading DeepSeek-R1:7b with Ollama          </li> </ul>"},{"location":"#tag:duplicate-paths","title":"duplicate-paths","text":"<ul> <li>            Route Interception Issues in Next.js with Duplicate Paths          </li> </ul>"},{"location":"#tag:errors","title":"errors","text":"<ul> <li>            Resolving 'max retries exceeded' and 'file does not exist' Errors When Pulling Manifest          </li> </ul>"},{"location":"#tag:fetch","title":"fetch","text":"<ul> <li>            Fetch Request Memoization Not Working When Cookies Function Imported          </li> </ul>"},{"location":"#tag:file-system-operations","title":"file system operations","text":"<ul> <li>            Why Tokio's `File::write` Returns Early Before OS Completes the Operation          </li> </ul>"},{"location":"#tag:force-frame-pointersyes","title":"force-frame-pointers=yes","text":"<ul> <li>            A stacktrace in RISC-V builds with `force-frame-pointers=yes` and `opt-level=z`: The Unexplained Disappearance          </li> </ul>"},{"location":"#tag:frame-pointers","title":"frame-pointers","text":"<ul> <li>            A bug in RISC-V compilation with -C force-frame-pointers=yes and opt-level = 'z'          </li> </ul>"},{"location":"#tag:getinitialprops","title":"getInitialProps","text":"<ul> <li>            Pages Router + getInitialProps = Static worker unexpectedly          </li> </ul>"},{"location":"#tag:graph-database","title":"graph database","text":"<ul> <li>            Resolving APOC Procedures Error in Langchain with Neo4j v5.9          </li> </ul>"},{"location":"#tag:html-parsing","title":"html-parsing","text":"<ul> <li>            Support ReaderLM-v2 for Efficient HTML Parsing and Text Extraction          </li> </ul>"},{"location":"#tag:infinite-growth","title":"infinite growth","text":"<ul> <li>            React 19.0.0 actQueue Infinite Growth Bug          </li> </ul>"},{"location":"#tag:installation","title":"installation","text":"<ul> <li>            Can't Install rustc-docs Component: Resolving the Conflict          </li> <li>            Resolving the 'rustc-docs' Installation Conflict in Rust          </li> </ul>"},{"location":"#tag:isr-cache","title":"isr cache","text":"<ul> <li>            ISR Fails to Serve 404 Pages After Page Deletion with Experimental ISR Memory Cache Size Set to 0          </li> </ul>"},{"location":"#tag:jinja2","title":"jinja2","text":"<ul> <li>            Jinja2 loop.index0 blocked by RestrictedSandboxedEnvironment in LangChain          </li> </ul>"},{"location":"#tag:keyword1","title":"keyword1","text":"<ul> <li>            Fixing the Busy Wait Loop in Repro          </li> </ul>"},{"location":"#tag:keyword2","title":"keyword2","text":"<ul> <li>            Fixing the Busy Wait Loop in Repro          </li> </ul>"},{"location":"#tag:kubelet","title":"kubelet","text":"<ul> <li>            Introducing Permanent and Transient Error Handling in kubelet          </li> <li>            Surface Permanent Errors in Kubelet and DRA Drivers          </li> </ul>"},{"location":"#tag:langchain","title":"langchain","text":"<ul> <li>            ModuleNotFoundError: No module named 'langchain.schema'          </li> <li>            Resolving APOC Procedures Error in Langchain with Neo4j v5.9          </li> </ul>"},{"location":"#tag:langchain-ai","title":"langchain-ai","text":"<ul> <li>            Jinja2 loop.index0 blocked by RestrictedSandboxedEnvironment in LangChain          </li> </ul>"},{"location":"#tag:mac-os","title":"mac os","text":"<ul> <li>            Building Rust from Source with Autodiff on Mac OS          </li> <li>            Building Rust with Autodiff on Mac OS Fails          </li> </ul>"},{"location":"#tag:manifest","title":"manifest","text":"<ul> <li>            Resolving 'max retries exceeded' and 'file does not exist' Errors When Pulling Manifest          </li> </ul>"},{"location":"#tag:manifest-errors","title":"manifest errors","text":"<ul> <li>            Resolving Pull Manifest Errors in Ollama          </li> </ul>"},{"location":"#tag:memoization","title":"memoization","text":"<ul> <li>            Fetch Request Memoization Not Working When Cookies Function Imported          </li> </ul>"},{"location":"#tag:memory-caching","title":"memory caching","text":"<ul> <li>            ISR Fails to Serve 404 Pages After Page Deletion with Experimental ISR Memory Cache Size Set to 0          </li> </ul>"},{"location":"#tag:multiple-images","title":"multiple-images","text":"<ul> <li>            Support for Multiple Images in /chat Endpoint          </li> </ul>"},{"location":"#tag:neo4j","title":"neo4j","text":"<ul> <li>            Resolving APOC Procedures Error in Langchain with Neo4j v5.9          </li> </ul>"},{"location":"#tag:nextjs","title":"next.js","text":"<ul> <li>            ISR Fails to Serve 404 Pages After Page Deletion with Experimental ISR Memory Cache Size Set to 0          </li> <li>            Pages Router + getInitialProps = Static worker unexpectedly          </li> </ul>"},{"location":"#tag:nextjs","title":"nextjs","text":"<ul> <li>            Fetch Request Memoization Not Working When Cookies Function Imported          </li> <li>            Route Interception Issues in Next.js with Duplicate Paths          </li> </ul>"},{"location":"#tag:ollama","title":"ollama","text":"<ul> <li>            DeepSeek-R1 671B Q4_K_M Error: Model Requires More System Memory Than Available          </li> <li>            Error When Downloading DeepSeek-R1:7b with Ollama          </li> <li>            Resolving 'max retries exceeded' and 'file does not exist' Errors When Pulling Manifest          </li> <li>            Resolving Pull Manifest Errors in Ollama          </li> </ul>"},{"location":"#tag:ollama-api","title":"ollama-api","text":"<ul> <li>            Support for Multiple Images in /chat Endpoint          </li> </ul>"},{"location":"#tag:opt-levelz","title":"opt-level=z","text":"<ul> <li>            A stacktrace in RISC-V builds with `force-frame-pointers=yes` and `opt-level=z`: The Unexplained Disappearance          </li> </ul>"},{"location":"#tag:pandas","title":"pandas","text":"<ul> <li>            Pandas Rounding Issue: Empty Series Should Return Empty Series          </li> <li>            Pandas Series.sum() Examples Fail to Illustrate Actual Results          </li> <li>            Pandas Series.sum() Misrepresentation in Documentation          </li> <li>            Rounding Errors in Pandas Series: A Potential Pitfall          </li> <li>            Series.replace not working on slices of heterogeneous types          </li> </ul>"},{"location":"#tag:release-builds","title":"release builds","text":"<ul> <li>            A bug in RISC-V compilation with -C force-frame-pointers=yes and opt-level = 'z'          </li> </ul>"},{"location":"#tag:replace","title":"replace","text":"<ul> <li>            Series.replace not working on slices of heterogeneous types          </li> </ul>"},{"location":"#tag:riscv32imc-unknown-none-elf","title":"riscv32imc-unknown-none-elf","text":"<ul> <li>            A bug in RISC-V compilation with -C force-frame-pointers=yes and opt-level = 'z'          </li> <li>            A stacktrace in RISC-V builds with `force-frame-pointers=yes` and `opt-level=z`: The Unexplained Disappearance          </li> </ul>"},{"location":"#tag:rounding","title":"rounding","text":"<ul> <li>            Pandas Rounding Issue: Empty Series Should Return Empty Series          </li> <li>            Rounding Errors in Pandas Series: A Potential Pitfall          </li> </ul>"},{"location":"#tag:route-interception","title":"route-interception","text":"<ul> <li>            Route Interception Issues in Next.js with Duplicate Paths          </li> </ul>"},{"location":"#tag:rust","title":"rust","text":"<ul> <li>            Building Rust from Source with Autodiff on Mac OS          </li> <li>            Building Rust with Autodiff on Mac OS Fails          </li> <li>            Resolving the 'rustc-docs' Installation Conflict in Rust          </li> </ul>"},{"location":"#tag:rust-lang","title":"rust-lang","text":"<ul> <li>            Can't Install rustc-docs Component: Resolving the Conflict          </li> <li>            Wrong Architecture Objects Mixed in Self-Built Compiler on Apple Silicon Hosts          </li> </ul>"},{"location":"#tag:rustc-docs","title":"rustc-docs","text":"<ul> <li>            Can't Install rustc-docs Component: Resolving the Conflict          </li> </ul>"},{"location":"#tag:series","title":"series","text":"<ul> <li>            Pandas Series.sum() Examples Fail to Illustrate Actual Results          </li> <li>            Pandas Series.sum() Misrepresentation in Documentation          </li> <li>            Series.replace not working on slices of heterogeneous types          </li> </ul>"},{"location":"#tag:static-worker","title":"static-worker","text":"<ul> <li>            Pages Router + getInitialProps = Static worker unexpectedly          </li> </ul>"},{"location":"#tag:sum","title":"sum","text":"<ul> <li>            Pandas Series.sum() Examples Fail to Illustrate Actual Results          </li> <li>            Pandas Series.sum() Misrepresentation in Documentation          </li> </ul>"},{"location":"#tag:system-crashes","title":"system crashes","text":"<ul> <li>            A System Crash in Tokio-based Systems          </li> </ul>"},{"location":"#tag:templating","title":"templating","text":"<ul> <li>            Jinja2 loop.index0 blocked by RestrictedSandboxedEnvironment in LangChain          </li> </ul>"},{"location":"#tag:text-extraction","title":"text-extraction","text":"<ul> <li>            Support ReaderLM-v2 for Efficient HTML Parsing and Text Extraction          </li> </ul>"},{"location":"#tag:thread-safety","title":"thread safety","text":"<ul> <li>            A catchy, SEO-friendly title          </li> </ul>"},{"location":"#tag:tokio","title":"tokio","text":"<ul> <li>            TcpStream::set_linger Can Lead to Blocking in Tokio          </li> <li>            tokio::fs::File::write Returns Early Before OS Says Operation is Completed          </li> </ul>"},{"location":"#tag:tokio-runtime","title":"tokio runtime","text":"<ul> <li>            A catchy, SEO-friendly title          </li> </ul>"},{"location":"#tag:tokio-147","title":"tokio-1.47","text":"<ul> <li>            A System Crash in Tokio-based Systems          </li> </ul>"},{"location":"#tag:tokio-rs","title":"tokio-rs","text":"<ul> <li>            Why Tokio's `File::write` Returns Early Before OS Completes the Operation          </li> </ul>"},{"location":"#tag:transformer-based","title":"transformer-based","text":"<ul> <li>            Support ReaderLM-v2 for Efficient HTML Parsing and Text Extraction          </li> </ul>"},{"location":"#tag:wait-loop","title":"wait-loop","text":"<ul> <li>            Fixing the Busy Wait Loop in Repro          </li> </ul>"},{"location":"2026-01-04-bug-actqueue-forever-growing-in-react-1900/","title":"React 19.0.0 actQueue Infinite Growth Bug","text":"","tags":["React 19.0.0","actQueue","infinite growth"]},{"location":"2026-01-04-bug-actqueue-forever-growing-in-react-1900/#core-problem","title":"Core Problem","text":"<p>When migrating from React 18.3.1 to React 19.0.0, a unit test starts to fail due to an infinite loop in the <code>actQueue</code>. This issue is caused by the use of <code>&lt;Suspense /&gt;</code> and <code>react.lazy</code> along with a component that has a <code>const [ref, setRef] = useState(null)</code> pattern.</p>","tags":["React 19.0.0","actQueue","infinite growth"]},{"location":"2026-01-04-bug-actqueue-forever-growing-in-react-1900/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To solve this issue, we need to identify the cause of the infinite loop. Based on the provided information, we can try the following solutions:</p>","tags":["React 19.0.0","actQueue","infinite growth"]},{"location":"2026-01-04-bug-actqueue-forever-growing-in-react-1900/#solution-1-remove-setref-callsite-from-ref-props","title":"Solution 1: Remove <code>setRef</code> callsite from ref props","text":"<pre><code>// Before\n&lt;div ref={(ref) =&gt; setRef(ref)} /&gt;\n\n// After\n&lt;div /&gt;\n</code></pre> <p>By removing the <code>setRef</code> callsite from the ref props, the test can finish.</p>","tags":["React 19.0.0","actQueue","infinite growth"]},{"location":"2026-01-04-bug-actqueue-forever-growing-in-react-1900/#solution-2-remove-suspense-and-reactlazy","title":"Solution 2: Remove <code>Suspense</code> and <code>react.lazy</code>","text":"<pre><code>// Before\n&lt;Suspense fallback={&lt;div&gt;Loading...&lt;/div&gt;}&gt;\n  &lt;LazyComponent /&gt;\n&lt;/Suspense&gt;\n\n// After\n&lt;LazyComponent /&gt;\n</code></pre> <p>By removing the <code>Suspense</code> and <code>react.lazy</code>, the test can finish.</p>","tags":["React 19.0.0","actQueue","infinite growth"]},{"location":"2026-01-04-bug-actqueue-forever-growing-in-react-1900/#solution-3-remove-usage-of-ref-state-from-effect","title":"Solution 3: Remove usage of <code>ref</code> state from effect","text":"<pre><code>// Before\nconst [ref, setRef] = useState(null)\nuseEffect(() =&gt; {\n  // code that uses ref as a dependency\n}, [ref])\n</code></pre> <p>By removing the usage of <code>ref</code> state from the effect, the test still hangs.</p>","tags":["React 19.0.0","actQueue","infinite growth"]},{"location":"2026-01-04-bug-actqueue-forever-growing-in-react-1900/#additional-analysis","title":"Additional Analysis","text":"<p>The <code>actQueue</code> is a mechanism used by React to batch and manage asynchronous effects. In this case, the infinite loop is caused by the use of <code>Suspense</code> and <code>react.lazy</code>, which creates an additional layer of complexity in the actQueue.</p> <p>To fix this issue, we need to refactor the component tree to avoid using <code>Suspense</code> and <code>react.lazy</code>. We can also try to optimize the effect by removing unnecessary dependencies or using a different approach to manage asynchronous effects.</p>","tags":["React 19.0.0","actQueue","infinite growth"]},{"location":"2026-01-04-bug-actqueue-forever-growing-in-react-1900/#conclusion","title":"Conclusion","text":"<p>By analyzing the problem and providing potential solutions, we can help identify the root cause of the infinite loop in React 19.0.0. By avoiding the use of <code>Suspense</code> and <code>react.lazy</code>, as well as optimizing effects, we can potentially fix the issue and improve the overall performance of the application.</p>","tags":["React 19.0.0","actQueue","infinite growth"]},{"location":"2026-01-04-bug-actqueue-forever-growing-in-react-1900/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["React 19.0.0","actQueue","infinite growth"]},{"location":"2026-01-04-bug-different-behaivor-between-usetransition-and-usedeferredvalue/","title":"Understanding the Difference Between <code>useTransition</code> and <code>useDeferredValue</code>","text":"","tags":["React Hooks","State Management","Transition Optimization"]},{"location":"2026-01-04-bug-different-behaivor-between-usetransition-and-usedeferredvalue/#core-problem","title":"Core Problem","text":"<p>When using React Hooks to manage state transitions, developers may notice a difference in behavior between <code>useTransition</code> and <code>useDeferredValue</code>. Specifically, when updating states that are not currently in transition, <code>useTransition</code> can cause UI blocking, while <code>useDeferredValue</code> does not exhibit this issue. In this article, we will explore the reasons behind these differences and provide guidance on how to optimize state transitions in React.</p>","tags":["React Hooks","State Management","Transition Optimization"]},{"location":"2026-01-04-bug-different-behaivor-between-usetransition-and-usedeferredvalue/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>The main difference between <code>useTransition</code> and <code>useDeferredValue</code> lies in their approach to managing state updates during a transition. <pre><code>import { useState, useTransition } from 'react';\n\nfunction Counter() {\n  const [count, setCount] = useState(0);\n  const transitions = useTransition();\n\n  return (\n    &lt;div&gt;\n      &lt;button onClick={() =&gt; setCount(count + 1)}&gt;Increment&lt;/button&gt;\n      &lt;p&gt;Count: {count}&lt;/p&gt;\n      &lt;Post /&gt;\n      {transitions.state === 'pending' &amp;&amp; (\n        &lt;div&gt;Transition in progress...&lt;/div&gt;\n      )}\n    &lt;/div&gt;\n  );\n}\n</code></pre> In the <code>Counter</code> component, we use <code>useTransition</code> to manage state updates. When the button is clicked, we increment the <code>count</code> state and trigger a transition using <code>transitions.useUpdate</code>. However, when we update other states that are not in transition (e.g., the <code>Post</code> component), it can cause UI blocking.</p> <p>On the other hand, <code>useDeferredValue</code> does not exhibit this issue. <pre><code>import { useState } from 'react';\n\nfunction Post() {\n  const [post, setPost] = useState('');\n  const deferredValue = useState('Initial Value');\n\n  return (\n    &lt;div&gt;\n      &lt;input type=\"text\" value={deferredValue[0]} onChange={(e) =&gt; setDeferredValue(e.target.value)} /&gt;\n      &lt;p&gt;Post: {post}&lt;/p&gt;\n    &lt;/div&gt;\n  );\n}\n</code></pre> In the <code>Post</code> component, we use <code>useDeferredValue</code> to manage state updates. When the user types in the input field, we update the <code>deferredValue</code> state using <code>setDeferredValue</code>. This change is not reflected immediately and does not cause UI blocking.</p> <p>The reason for this difference lies in how each hook handles state updates during a transition. <pre><code>import { useTransition } from 'react';\n\nfunction useTransition() {\n  const [state, setState] = useState('idle');\n\n  return (update) =&gt; {\n    if (state === 'pending') {\n      update(() =&gt; {\n        setState('idle');\n      });\n    }\n  };\n}\n</code></pre> <code>useTransition</code> blocks the UI when a transition is in progress and updates other states. This is because it waits for the transition to complete before updating the state.</p> <p>In contrast, <code>useDeferredValue</code> defers state updates until the next frame. <pre><code>import { useState } from 'react';\n\nfunction useDeferredValue(initialValue) {\n  const [value, setValue] = useState(initialValue);\n\n  return (update) =&gt; {\n    return () =&gt; {\n      setValue(update);\n    };\n  };\n}\n</code></pre> When <code>useDeferredValue</code> updates a state, it defers the change until the next frame. This allows other states to be updated concurrently without causing UI blocking.</p>","tags":["React Hooks","State Management","Transition Optimization"]},{"location":"2026-01-04-bug-different-behaivor-between-usetransition-and-usedeferredvalue/#conclusion","title":"Conclusion","text":"<p>In conclusion, the difference between <code>useTransition</code> and <code>useDeferredValue</code> lies in their approach to managing state updates during a transition. While <code>useTransition</code> can cause UI blocking when updating states that are not in transition, <code>useDeferredValue</code> defers state updates until the next frame, allowing for concurrent updates without blocking the UI. By understanding these differences, developers can optimize their state transitions and create more responsive user interfaces.</p>","tags":["React Hooks","State Management","Transition Optimization"]},{"location":"2026-01-04-bug-different-behaivor-between-usetransition-and-usedeferredvalue/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["React Hooks","State Management","Transition Optimization"]},{"location":"2026-01-04-cant-install-rustc-docs-component-detected-conflict-sharedocrusthtmlrustc/","title":"Can't Install rustc-docs Component: Resolving the Conflict","text":"","tags":["rust-lang","installation","rustc-docs"]},{"location":"2026-01-04-cant-install-rustc-docs-component-detected-conflict-sharedocrusthtmlrustc/#core-problem","title":"Core Problem","text":"<p>The <code>rustc-docs</code> component cannot be installed on Rust due to a detected conflict. The error message indicates that there is an issue with the directory structure, specifically the overlap between <code>share/doc/rust/html/rustc</code> and <code>rustc-docs</code>. This problem persists despite the fix mentioned in GitHub pull request #75593.</p>","tags":["rust-lang","installation","rustc-docs"]},{"location":"2026-01-04-cant-install-rustc-docs-component-detected-conflict-sharedocrusthtmlrustc/#solution-analysis","title":"Solution &amp; Analysis","text":"<pre><code># Check the current installation of rustc-docs\ninfo: downloading component 'rustc-docs'\ninfo: installing component 'rustc-docs'\ninfo: Defaulting to 500.0 MiB unpack ram  \n  9.9 MiB /   9.9 MiB (100 %)   2.9 MiB/s in  3s ETA:  0s\ninfo: rolling back changes\nerror: failed to install component: 'rustc-docs-x86_64-unknown-linux-gnu', detected conflict: '\"share/doc/rust/html/rustc\"'\n</code></pre> <p>To resolve this issue, you can try the following solutions:</p> <ul> <li>Rename the <code>rustc</code> directory inside <code>share/doc/rust</code> to avoid conflicts:     ```bash sudo mv share/doc/rust/html/rustc share/doc/rust/html/rustc-renamed <pre><code>*   Create a symbolic link from `rustc-docs` to `rustc` instead of installing it separately:\n    ```bash\nln -s share/doc/rust/html/rustc share/doc/rustc/docs\n</code></pre></li> </ul>","tags":["rust-lang","installation","rustc-docs"]},{"location":"2026-01-04-cant-install-rustc-docs-component-detected-conflict-sharedocrusthtmlrustc/#conclusion","title":"Conclusion","text":"<p>By renaming the conflicting directory or creating a symbolic link, you can resolve the conflict and successfully install the <code>rustc-docs</code> component. Keep in mind that these workarounds may have unintended consequences on your system's file structure. Always be cautious when modifying system files to avoid data loss or corruption.</p>","tags":["rust-lang","installation","rustc-docs"]},{"location":"2026-01-04-cant-install-rustc-docs-component-detected-conflict-sharedocrusthtmlrustc/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["rust-lang","installation","rustc-docs"]},{"location":"2026-01-04-doc-seriessum-has-examples-that-dont-illustrate-the-actual-results/","title":"[Use the Title]","text":"","tags":["pandas","series","sum"]},{"location":"2026-01-04-doc-seriessum-has-examples-that-dont-illustrate-the-actual-results/#core-problem","title":"Core Problem","text":"<p>The <code>Series.sum()</code> function in pandas has examples that don't accurately illustrate its actual results. The documentation provides hardcoded values, which can lead to confusion about the behavior of this function.</p>","tags":["pandas","series","sum"]},{"location":"2026-01-04-doc-seriessum-has-examples-that-dont-illustrate-the-actual-results/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To fix this issue, we need to rethink how the examples are created and presented in the documentation. There are two possible approaches:</p>","tags":["pandas","series","sum"]},{"location":"2026-01-04-doc-seriessum-has-examples-that-dont-illustrate-the-actual-results/#approach-1-execute-code-for-results","title":"Approach 1: Execute Code for Results","text":"<p>Instead of providing hardcoded results, we could modify the documentation to execute the code and display the actual output. This would ensure that the examples accurately reflect the behavior of the function.</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n\nidx = pd.MultiIndex.from_arrays(\n    [[\"warm\", \"warm\", \"cold\", \"cold\"], [\"dog\", \"falcon\", \"fish\", \"spider\"]],\n    names=[\"blooded\", \"animal\"],\n)\ns = pd.Series([4, 2, 0, 8], name=\"legs\", index=idx)\n\n# Execute the code and display the result\nresult = s.sum()\nprint(result)  # Output: 14\n</code></pre>","tags":["pandas","series","sum"]},{"location":"2026-01-04-doc-seriessum-has-examples-that-dont-illustrate-the-actual-results/#approach-2-indicate-numpy-types","title":"Approach 2: Indicate Numpy Types","text":"<p>Another option is to indicate whether the function returns numpy types or python types. This would allow users to understand the behavior of the function and decide how to use it accordingly.</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n\nidx = pd.MultiIndex.from_arrays(\n    [[\"warm\", \"warm\", \"cold\", \"cold\"], [\"dog\", \"falcon\", \"fish\", \"spider\"]],\n    names=[\"blooded\", \"animal\"],\n)\ns = pd.Series([4, 2, 0, 8], name=\"legs\", index=idx)\n\n# Display the type of result\nresult_type = s.sum().dtype\nprint(result_type)  # Output: int64\n\n# Execute the code and display the result\nif result_type == 'int64':\n    print(s.sum())  # Output: 14\n</code></pre>","tags":["pandas","series","sum"]},{"location":"2026-01-04-doc-seriessum-has-examples-that-dont-illustrate-the-actual-results/#conclusion","title":"Conclusion","text":"<p>To ensure that the documentation for <code>Series.sum()</code> is accurate, we should consider modifying the examples to execute the code and display the actual output. Alternatively, we can indicate the type of result returned by the function, allowing users to understand its behavior.</p>","tags":["pandas","series","sum"]},{"location":"2026-01-04-doc-seriessum-has-examples-that-dont-illustrate-the-actual-results/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["pandas","series","sum"]},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/","title":"2026 01 04 excessive conntrack cleanup causes high memory 12gb and cpu usage when any pod with a udp port changes","text":"<p>Excessive conntrack Cleanup Causes High Memory and CPU Usage in Kubernetes</p>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#what-happened","title":"What Happened?","text":"<p>In Kubernetes 1.32, changes to Services or Pods that expose UDP ports trigger a full conntrack cleanup, leading to high resource consumption. This issue affects kube-proxy instances, causing them to consume up to 12 GB of memory and 1.5 CPU cores.</p>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#what-did-you-expect-to-happen","title":"What Did You Expect to Happen?","text":"<p>We expected kube-proxy to handle conntrack cleanup in a more efficient and targeted way. Ideally, it should limit its cleanup to entries relevant to the specific changed UDP endpoint or provide a way to configure or disable this aggressive cleanup process.</p>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#how-can-we-reproduce-it-as-minimally-and-precisely-as-possible","title":"How Can We Reproduce It (as Minimally and Precisely as Possible)?","text":"<ol> <li>Deploy multiple Pods that generate a high volume of DNS requests.</li> <li>Observe kube-proxy resource usage (memory and CPU) on the node.</li> <li>Delete or update the CoreDNS Pod, which also uses UDP DNS.</li> <li>Watch the logs and resource usage of kube-proxy closely, noting the surge in memory (potentially up to 12 GB) and CPU usage as it performs the conntrack cleanup.</li> </ol>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#anything-else-we-need-to-know","title":"Anything Else We Need to Know?","text":""},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#kubernetes-version","title":"Kubernetes Version","text":"<pre><code>$ kubectl version\nClient Version: v1.31.2\nKustomize Version: v5.4.2\nServer Version: v1.32.0-eks-5ca49cb\n</code></pre>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#cloud-provider","title":"Cloud Provider","text":"<p>AWS</p>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#os-version","title":"OS Version","text":"<pre><code># On Linux: Amazon Linux 2\n5.10.230-223.885.amzn2.aarch64\n</code></pre>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#install-tools","title":"Install Tools","text":"<p>EKS</p>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#container-runtime-cri-and-version-if-applicable","title":"Container Runtime (CRI) and Version (if applicable)","text":"<p>containerd://1.7.23</p>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#related-plugins-cni-csi-and-versions-if-applicable","title":"Related Plugins (CNI, CSI, ...) and Versions (if applicable)","text":"<p>kube-proxy:v1.32.0-minimal-eksbuild.2</p>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#top-solutioncomment","title":"Top Solution/Comment","text":"<p>/sig network</p>"},{"location":"2026-01-04-excessive-conntrack-cleanup-causes-high-memory-12gb-and-cpu-usage-when-any-pod-with-a-udp-port-changes/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>"},{"location":"2026-01-04-fetch-request-memoization-not-working-when-cookies-function-imported/","title":"Fetch Request Memoization Not Working When Cookies Function Imported","text":""},{"location":"2026-01-04-fetch-request-memoization-not-working-when-cookies-function-imported/#core-problem","title":"Core Problem","text":"<p>When importing the <code>cookies</code> function in a Next.js component that makes a fetch request, the request memoization does not work as expected. Despite setting the cache option to <code>'force-cache'</code>, the request is still called multiple times on subsequent page loads.</p>"},{"location":"2026-01-04-fetch-request-memoization-not-working-when-cookies-function-imported/#solution-analysis","title":"Solution &amp; Analysis","text":""},{"location":"2026-01-04-fetch-request-memoization-not-working-when-cookies-function-imported/#reproductive-code","title":"Reproductive Code","text":"<p>To reproduce this issue, follow these steps:</p> <ol> <li>Install <code>next</code> and create a new project: <code>npm install --force</code></li> <li>Create two separate projects, <code>dragonradar</code> and <code>my-nest-app</code>, using the Next.js CLI: <code>npx nx serve dragonradar</code> and <code>npx nx serve my-nest-app</code></li> <li>Go to <code>localhost:6777</code> in one of the browsers and observe that the endpoint is called only once.</li> <li>In the console of the Nest app, uncomment the cookies import: <code>&lt;Component&gt;...&lt;/Component&gt;</code></li> <li>Refresh the page and observe that the endpoint is now called three times.</li> </ol>"},{"location":"2026-01-04-fetch-request-memoization-not-working-when-cookies-function-imported/#investigation","title":"Investigation","text":"<p>The issue can be attributed to the way Next.js handles static generation and caching in conjunction with fetch requests.</p> <p>In the <code>staticGenerationStore</code> module, there's a line setting <code>revalidate</code> to 0:</p> <pre><code>// packages/next/src/server/future/route-modules/app-route/module.ts\nstaticGenerationStore.revalidate = 0;\n</code></pre> <p>Similarly, in the <code>patch-fetch</code> module, there's another instance with the same issue:</p> <pre><code>// packages/next/src/server/lib/patch-fetch.ts\nstaticGenerationStore.revalidate === 0;\n</code></pre> <p>This suggests that there might be an unintended behavior when using fetch requests with caching.</p>"},{"location":"2026-01-04-fetch-request-memoization-not-working-when-cookies-function-imported/#fix","title":"Fix","text":"<p>To fix this issue, you can add a <code>useEffect</code> hook to your component and set the cache option manually:</p> <pre><code>import { useEffect } from 'react';\nimport { fetch } from 'isomorphic-unfetch';\n\nconst MyComponent = () =&gt; {\n  const [cache, setCache] = useState('force-cache');\n\n  useEffect(() =&gt; {\n    fetch('/api/endpoint', {\n      cache,\n    });\n  }, [cache]);\n\n  return &lt;div&gt;...&lt;/div&gt;;\n};\n</code></pre> <p>This ensures that the request is memoized correctly even when the cookies function is imported.</p>"},{"location":"2026-01-04-fetch-request-memoization-not-working-when-cookies-function-imported/#conclusion","title":"Conclusion","text":"<p>In summary, importing the <code>cookies</code> function in a Next.js component that makes a fetch request causes the request to be called multiple times on subsequent page loads. By setting the cache option manually using an <code>useEffect</code> hook, we can fix this issue and ensure correct memoization of fetch requests.</p>"},{"location":"2026-01-04-fetch-request-memoization-not-working-when-cookies-function-imported/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>"},{"location":"2026-01-04-isr-fails-to-serve-404-pages-once-the-page-gets-deleted-if-experimental-isr-memory-cache-size-is-set-to-0/","title":"ISR Fails to Serve 404 Pages After Page Deletion with Experimental ISR Memory Cache Size Set to 0","text":"","tags":["next.js","isr cache","memory caching"]},{"location":"2026-01-04-isr-fails-to-serve-404-pages-once-the-page-gets-deleted-if-experimental-isr-memory-cache-size-is-set-to-0/#core-problem","title":"Core Problem","text":"<p>When using the experimental ISR (Incremental Static Regeneration) memory cache with a size of 0, Next.js fails to serve 404 pages after page deletion. This issue arises when the ISR memory cache is disabled, causing the server to return stale versions of pages instead of the expected 404 page.</p>","tags":["next.js","isr cache","memory caching"]},{"location":"2026-01-04-isr-fails-to-serve-404-pages-once-the-page-gets-deleted-if-experimental-isr-memory-cache-size-is-set-to-0/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To resolve this issue, we need to understand how the experimental ISR memory cache works and its impact on serving 404 pages. The <code>isrMemoryCacheSize</code> option controls the amount of memory allocated for caching generated documents. When set to 0, the cache is disabled, and the server relies solely on revalidation to serve pages.</p> <p>To reproduce the issue, follow these steps:</p> <ol> <li>Build and start the production build of your Next.js application.</li> <li>Navigate to <code>http://localhost:3000/detail/1</code> in your browser.</li> <li>In the <code>public/detail.json</code> file, change the <code>enabled</code> parameter to 0.</li> <li>After 5 seconds (revalidation period), refresh the page twice:<ul> <li>The first refresh should serve you the stale page while revalidating the page on server.</li> <li>The second refresh should return a 404 page, but it does not.</li> <li>Any later request will still serve the original stale version of the page.</li> </ul> </li> </ol> <p>To work around this issue, set <code>notFound: false</code> in your <code>getStaticProps</code> function. This tells Next.js to always return a 404 page instead of serving the stale version.</p> <pre><code>import { GetStaticProps } from 'next';\n\nconst DetailPage = () =&gt; {\n  // ...\n};\n\nexport const getStaticProps: GetStaticProps = async () =&gt; {\n  return {\n    props: {\n      notFound: false,\n    },\n  };\n};\n</code></pre>","tags":["next.js","isr cache","memory caching"]},{"location":"2026-01-04-isr-fails-to-serve-404-pages-once-the-page-gets-deleted-if-experimental-isr-memory-cache-size-is-set-to-0/#conclusion","title":"Conclusion","text":"<p>By understanding the behavior of the experimental ISR memory cache and setting <code>notFound</code> to <code>false</code>, you can work around the issue of Next.js failing to serve 404 pages after page deletion.</p>","tags":["next.js","isr cache","memory caching"]},{"location":"2026-01-04-isr-fails-to-serve-404-pages-once-the-page-gets-deleted-if-experimental-isr-memory-cache-size-is-set-to-0/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["next.js","isr cache","memory caching"]},{"location":"2026-01-04-jinja2-loopindex0-blocked-by-restrictedsandboxedenvironment-when-using-template_formatjinja2/","title":"Jinja2 Loop Index0 Blocked by RestrictedSandboxedEnvironment in LangChain","text":"","tags":["langchain-ai","jinja2","templating"]},{"location":"2026-01-04-jinja2-loopindex0-blocked-by-restrictedsandboxedenvironment-when-using-template_formatjinja2/#core-problem","title":"Core Problem","text":"<p>When using <code>ChatPromptTemplate</code> with <code>template_format=\"jinja2\"</code>, a simple Jinja2 template that uses the built-in <code>loop.index0</code> works correctly with plain Jinja2, but fails with a <code>jinja2.exceptions.SecurityError</code> in LangChain.</p>","tags":["langchain-ai","jinja2","templating"]},{"location":"2026-01-04-jinja2-loopindex0-blocked-by-restrictedsandboxedenvironment-when-using-template_formatjinja2/#solution-analysis","title":"Solution &amp; Analysis","text":"<pre><code>from langchain_core.prompts.chat import ChatPromptTemplate\n\nprompt = \"{% for it in items %} {{ loop.index0 }}{% endfor %}\"\nitems = [1, 2, 3]\n\nmessage = ChatPromptTemplate.from_messages(\n    messages=[(\"system\", prompt)],\n    template_format=\"jinja2\",\n).format_messages(\n    items=items\n)\n\nprint(message[0].content)\n</code></pre> <p>Error Message: <pre><code>jinja2.exceptions.SecurityError: Access to attributes is not allowed in templates. Attempted to access 'index0' on LoopContext. Use only simple variable names like {{variable}} without dots or methods.\n</code></pre></p> <p>To resolve this issue, we can use a less restricted Jinja environment for trusted templates only.</p> <pre><code>from langchain_core.prompts.chat import ChatPromptTemplate\n\n# Create a template with a less restricted Jinja environment\ntemplate = \"{% for it in items %} {{ loop.index0 }}{% endfor %}\"\n\nprompt = (\"system\", template)\nitems = [1, 2, 3]\n\nmessage = ChatPromptTemplate.from_messages(\n    messages=prompt,\n    template_format=\"jinja2\",\n).format_messages(items=items)\n\nprint(message[0].content)\n</code></pre> <p>Alternatively, we can use an explicitly \"unsafe / trusted\" mode for applications that fully control the template strings.</p> <pre><code>from langchain_core.prompts.chat import ChatPromptTemplate\n\n# Create a template with an explicitly \"unsafe / trusted\" mode\ntemplate = \"{% for it in items %} {{ loop.index0 }}{% endfor %}\"\n\nprompt = (\"system\", template, {'mode': 'unsafe'})\nitems = [1, 2, 3]\n\nmessage = ChatPromptTemplate.from_messages(\n    messages=prompt,\n    template_format=\"jinja2\",\n).format_messages(items=items)\n\nprint(message[0].content)\n</code></pre>","tags":["langchain-ai","jinja2","templating"]},{"location":"2026-01-04-jinja2-loopindex0-blocked-by-restrictedsandboxedenvironment-when-using-template_formatjinja2/#conclusion","title":"Conclusion","text":"<p>When using <code>ChatPromptTemplate</code> with <code>template_format=\"jinja2\"</code>, LangChain restricts Jinja attribute access to prevent template injection and data exfiltration. However, this restriction blocks standard Jinja loop helpers like <code>loop.index0</code>. By using a less restricted Jinja environment or an explicitly \"unsafe / trusted\" mode, we can overcome this limitation and use more complex templates with LangChain.</p>","tags":["langchain-ai","jinja2","templating"]},{"location":"2026-01-04-jinja2-loopindex0-blocked-by-restrictedsandboxedenvironment-when-using-template_formatjinja2/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["langchain-ai","jinja2","templating"]},{"location":"2026-01-04-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/","title":"Resolving APOC Procedures Error in Langchain with Neo4j v5.9","text":"","tags":["langchain","neo4j","apoc","graph database"]},{"location":"2026-01-04-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#core-problem","title":"Core Problem","text":"<p>When using the <code>Neo4jGraph</code> class from the Langchain library to connect to a Neo4j instance, an error is reported despite having successfully installed the APOC plugin and verified its version.</p> <p>ValueError: Could not use APOC procedures. Please ensure the APOC plugin is installed in Neo4j and that 'apoc.meta.data()' is allowed in Neo4j configuration</p>","tags":["langchain","neo4j","apoc","graph database"]},{"location":"2026-01-04-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To resolve this issue, we need to configure the Neo4j instance to allow the use of APOC procedures.</p>","tags":["langchain","neo4j","apoc","graph database"]},{"location":"2026-01-04-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#step-1-verify-apoc-plugin-installation","title":"Step 1: Verify APOC Plugin Installation","text":"<p>Ensure that the APOC plugin has been installed correctly by running the following command on your Neo4j client: <pre><code>return apoc.version()\n</code></pre> This should return the version number of the APOC plugin, confirming its installation.</p>","tags":["langchain","neo4j","apoc","graph database"]},{"location":"2026-01-04-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#step-2-configure-neo4j-to-allow-apoc-procedures","title":"Step 2: Configure Neo4j to Allow APOC Procedures","text":"<p>Update the Neo4j configuration file (<code>neo4j.conf</code>) to allow the use of APOC procedures. Add the following line to the <code>security</code> section: <pre><code>apoc.meta.data=true\n</code></pre> Restart the Neo4j server to apply the changes.</p>","tags":["langchain","neo4j","apoc","graph database"]},{"location":"2026-01-04-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#step-3-update-langchain-configuration","title":"Step 3: Update Langchain Configuration","text":"<p>Modify the Langchain configuration to include the updated APOC plugin settings. Create a new file (<code>langchain_config.py</code>) with the following content: <pre><code>import os\n\n# Neo4j connection settings\nneo4j_server = 'bolt://localhost:7687'\nneo4j_username = 'neo4j'\nneo4j_password = 'chenhuabc'\n\n# APOC plugin settings\napoc_enabled = True\n</code></pre></p>","tags":["langchain","neo4j","apoc","graph database"]},{"location":"2026-01-04-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#step-4-test-the-connection","title":"Step 4: Test the Connection","text":"<p>Restart the Langchain server and reconnect to the Neo4j instance using the updated configuration: <pre><code>from langchain.graphs import Neo4jGraph\n\ngraph = Neo4jGraph(\n    neo4j_server,\n    neo4j_username,\n    neo4j_password\n)\n\nprint(graph)\n</code></pre> This should resolve the error and establish a successful connection to the Neo4j instance.</p>","tags":["langchain","neo4j","apoc","graph database"]},{"location":"2026-01-04-langchain-connects-neo4j-v59-error-could-not-use-apoc-procedures/#conclusion","title":"Conclusion","text":"<p>By following these steps, you can resolve the APOC procedures error in Langchain with Neo4j v5.9. Ensure that the APOC plugin is installed correctly, configure the Neo4j instance to allow its use, update the Langchain configuration, and test the connection.</p>","tags":["langchain","neo4j","apoc","graph database"]},{"location":"2026-01-04-new-amd-memory-detection-routines-ignores-unified-memory-on-amd-apu/","title":"AMD Memory Detection Routines Ignore Unified Memory on AMD APU","text":"","tags":["AMD","Ollama","Memory Detection"]},{"location":"2026-01-04-new-amd-memory-detection-routines-ignores-unified-memory-on-amd-apu/#core-problem","title":"Core Problem","text":"<p>The current implementation of memory detection routines in Ollama incorrectly identifies strict VRAM on AMD APUs even when unified RAM is used by ROCM and Vulkan runtimes.</p>","tags":["AMD","Ollama","Memory Detection"]},{"location":"2026-01-04-new-amd-memory-detection-routines-ignores-unified-memory-on-amd-apu/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To resolve this issue, we need to modify the memory detection logic to account for the use of unified RAM. The new routine will need to take into account the actual available VRAM and ignore the shared RAM allocated by ROCM and Vulkan.</p> <pre><code>// MemoryDetection.go\n\npackage main\n\nimport (\n    \"fmt\"\n)\n\nconst (\n    unifiedRAM_THRESHOLD = 20 * 1024 * 1024 // 20 GiB\n\n    // ... other constants ...\n)\n\ntype Memory struct {\n    total   uint64\n    available uint64\n}\n\nfunc detectMemory() (uint64, error) {\n    // Get the total and available VRAM\n    var vram Memory\n    vram.total = getVramTotal()\n    vram.available = getVramAvailable()\n\n    // Check if unified RAM is used\n    if vram.available &gt; unifiedRAM_THRESHOLD {\n        return 0, fmt.Errorf(\"unified RAM is used\")\n    }\n\n    return vram.available, nil\n}\n\nfunc main() {\n    memory, err := detectMemory()\n    if err != nil {\n        fmt.Println(err)\n    } else {\n        fmt.Printf(\"Available VRAM: %d bytes\\n\", memory)\n    }\n}\n\n// ... other functions to get total and available VRAM ...\n</code></pre>","tags":["AMD","Ollama","Memory Detection"]},{"location":"2026-01-04-new-amd-memory-detection-routines-ignores-unified-memory-on-amd-apu/#conclusion","title":"Conclusion","text":"<p>The updated memory detection routine will correctly identify the actual available VRAM on AMD APUs, even when unified RAM is used by ROCM and Vulkan. This fix ensures that Ollama accurately detects the memory constraints of the system, allowing for more efficient and effective model training.</p>","tags":["AMD","Ollama","Memory Detection"]},{"location":"2026-01-04-pulling-manifest-error/","title":"Resolving 'max retries exceeded' and 'file does not exist' Errors When Pulling Manifest","text":"","tags":["ollama","docker","manifest","errors"]},{"location":"2026-01-04-pulling-manifest-error/#core-problem","title":"Core Problem","text":"<p>The \"ollama run\" command fails with an error message indicating that the maximum number of retries has been exceeded due to an unexpected EOF (End Of File), followed by a failure to pull the model manifest, resulting in a file not existing error. This issue can be frustrating for users trying to deploy and train machine learning models.</p>","tags":["ollama","docker","manifest","errors"]},{"location":"2026-01-04-pulling-manifest-error/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To resolve this issue, we need to ensure that the system has sufficient memory resources to handle the Docker container's requirements. The recommended minimum memory requirement for running ollama is 32GB of CPU and GPU memory on a Macstation. Additionally, it's crucial to have enough free space on the hard drive.</p>","tags":["ollama","docker","manifest","errors"]},{"location":"2026-01-04-pulling-manifest-error/#solution-steps","title":"Solution Steps:","text":"<ol> <li>Check System Resources:</li> <li>Check your system's CPU and GPU memory usage.</li> <li>Ensure you have at least 32GB of total memory available (CPU + GPU).</li> <li>Update Docker and ollama Images:</li> <li>Run <code>docker pull --update docker/ollama:latest</code> to update the ollama image.</li> <li>Clear Download Directory:</li> <li>Remove any existing download directory or cache files related to ollama.</li> <li>Increase Memory Allocation for Docker Container:<ul> <li>Run the command with increased memory allocation, e.g., <code>OLLAMA_MEMORY=64G ollama run dolphin-mixtral:latest</code></li> </ul> </li> <li>Check Disk Space Availability:<ul> <li>Ensure there is sufficient free space on your hard drive (at least a few GB).</li> </ul> </li> </ol>","tags":["ollama","docker","manifest","errors"]},{"location":"2026-01-04-pulling-manifest-error/#example-code","title":"Example Code:","text":"<pre><code># Increase memory allocation for Docker container\nOLLAMA_MEMORY=64G ollama run dolphin-mixtral:latest\n\n# Clear download directory\nrm -rf ~/.ollama/download/\n\n# Update Docker and ollama images\ndocker pull --update docker/ollama:latest\n</code></pre>","tags":["ollama","docker","manifest","errors"]},{"location":"2026-01-04-pulling-manifest-error/#conclusion","title":"Conclusion","text":"<p>By following these steps, you should be able to resolve the 'max retries exceeded' and 'file does not exist' errors when pulling manifest. Ensure your system has sufficient memory resources and disk space available for optimal performance.</p>","tags":["ollama","docker","manifest","errors"]},{"location":"2026-01-04-pulling-manifest-error/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["ollama","docker","manifest","errors"]},{"location":"2026-01-04-reasoning-tokens-not-passing-through-from-openrouter-to-chatopenai/","title":"2026 01 04 reasoning tokens not passing through from openrouter to chatopenai","text":"<p>The error message indicates that there was an issue with the completion response from the Anthropic API. The native finish reason is 'stop', which suggests that the API encountered an error and stopped processing the request.</p> <p>To troubleshoot this issue, you can try the following:</p> <ol> <li>Check the API documentation to ensure that you are using the correct parameters and formatting.</li> <li>Verify that your token is valid and not expired.</li> <li>Try sending a new request with different parameters or formatting to see if the error persists.</li> <li>If you are using a caching mechanism, clear the cache and try again.</li> </ol> <p>Additionally, the output suggests that the API returned an error message indicating that your token was exposed in your PR description. This is likely a security warning from the Anthropic team, and it's recommended to rotate your token to prevent any potential security risks.</p> <p>To resolve this issue, you can take the following steps:</p> <ol> <li>Rotate your token by following the instructions provided by the Anthropic team.</li> <li>Review your code and ensure that you are not exposing sensitive information in your API requests.</li> <li>Implement proper error handling mechanisms to catch and handle any errors that may occur during API requests.</li> </ol> <p>By taking these steps, you should be able to resolve the issue and get back to generating content with the Anthropic API.</p>"},{"location":"2026-01-04-reasoning-tokens-not-passing-through-from-openrouter-to-chatopenai/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>"},{"location":"2026-01-04-scheduler-will-run-into-race-conditions-on-large-scale-clusters/","title":"2026 01 04 scheduler will run into race conditions on large scale clusters","text":"<p>A Catchy Title: \"Scheduler will run into race conditions on large scale clusters\" Tags: Kubernetes, Scheduler, Race Conditions, Large Scale Clusters</p>"},{"location":"2026-01-04-scheduler-will-run-into-race-conditions-on-large-scale-clusters/#understanding-the-issue-with-scheduler-in-large-scale-clusters","title":"Understanding the Issue with Scheduler in Large Scale Clusters","text":""},{"location":"2026-01-04-scheduler-will-run-into-race-conditions-on-large-scale-clusters/#core-problem","title":"Core Problem","text":"<p>The Kubernetes scheduler is prone to race conditions when dealing with large-scale clusters. This issue can lead to unexpected pod assignments and may have significant impacts on cluster stability.</p>"},{"location":"2026-01-04-scheduler-will-run-into-race-conditions-on-large-scale-clusters/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To mitigate this issue, we need to extend the 30-second timeout for bind operations and make it adaptable to cluster state. Here's a possible solution:</p> <pre><code>// Increased timeout for bind operation\nconst (\n    longBindTimeout = 60 * time.Second // 1 minute\n)\n\n// Update scheduler configuration\nfunc (s *Scheduler) Configure() {\n    s.config.Timeout.Bind = longBindTimeout\n}\n</code></pre> <p>Additionally, implementing a more robust and distributed approach to handling pod assignments can help reduce the likelihood of race conditions. This could involve using a centralized caching mechanism or load balancer to distribute the workload.</p>"},{"location":"2026-01-04-scheduler-will-run-into-race-conditions-on-large-scale-clusters/#conclusion","title":"Conclusion","text":"<p>The proposed solution involves increasing the timeout for bind operations and adapting it to cluster state. By doing so, we can minimize the impact of race conditions on large-scale clusters. Further research is needed to explore alternative solutions and identify best practices for mitigating this issue in Kubernetes clusters.</p> <p>Top Solution/Comment: @ahg-g: This issue is currently awaiting triage.</p> <p>If a SIG or subproject determines this is a relevant issue, they will accept it by applying the <code>triage/accepted</code> label and provide further guidance.</p> <p>The <code>triage/accepted</code> label can be added by org members by writing <code>/triage accepted</code> in a comment.</p> <p>Instructions for interacting with me using PR comments are available here.  If you have questions or suggestions related to my behavior, please file an issue against the kubernetes/test-infra repository.</p>"},{"location":"2026-01-04-scheduler-will-run-into-race-conditions-on-large-scale-clusters/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>"},{"location":"2026-01-04-support-for-multiple-images-in-chat-endpoint/","title":"Support for Multiple Images in /chat Endpoint","text":"","tags":["multiple-images","ollama-api","chat-endpoint"]},{"location":"2026-01-04-support-for-multiple-images-in-chat-endpoint/#core-problem","title":"Core Problem","text":"<p>The current implementation of the /chat endpoint only supports a single image, which introduces an additional layer of complexity when performing RAG (Reinforcement Algorithm with Gaze) with images embedded in base64.</p>","tags":["multiple-images","ollama-api","chat-endpoint"]},{"location":"2026-01-04-support-for-multiple-images-in-chat-endpoint/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To simplify this process, we can leverage existing libraries and frameworks that support multiple images. In the GitHub repository ollama/ollama, there is a note that ollama supports multiple images, but most models do not.</p> <p>For example, using the <code>base64</code> library in Python, we can pass multiple images in a single request:</p> <pre><code>$ for i in minicpm-v:8b-2.6-q4_K_M moondream:1.8b-v2-fp16 llava ; do \n  echo $i ; \n  echo '{\"model\": \"'$i'\",\n         \"messages\":[{\n            \"role\":\"user\",\"content\":\"describe the animals shown in the images\",\n            \"images\": [\n              \"'\"$(base64 puppy.jpg)\"'\",\n              \"'\"$(base64 kitten.jpg)\"'\"\n            ]\n          }],\n         \"stream\":false}' | curl -s http://localhost:11434/api/chat -d @- | jq -r .message.content ;\ndone\n</code></pre> <p>In this example, the <code>base64</code> library is used to encode the images and pass them in a single request. The response from the API can then be summarized into one.</p> <p>Another approach is to use the LLAVA model, which merges two images and describes a scene with multiple objects. This allows for more complex descriptions of scenes with multiple images.</p>","tags":["multiple-images","ollama-api","chat-endpoint"]},{"location":"2026-01-04-support-for-multiple-images-in-chat-endpoint/#conclusion","title":"Conclusion","text":"<p>Supporting multiple images in the /chat endpoint would greatly simplify workflows and reduce overhead in scenarios like RAG with images embedded in base64. While there is currently no plan to add this feature, existing libraries and frameworks can be used as a workaround.</p>","tags":["multiple-images","ollama-api","chat-endpoint"]},{"location":"2026-01-04-tokiofsfilewrite-returns-early-before-os-says-that-the-operation-is-completed/","title":"Understanding the Issue with Tokio's <code>File::write</code>","text":"","tags":["async programming","tokio-rs","file system operations"]},{"location":"2026-01-04-tokiofsfilewrite-returns-early-before-os-says-that-the-operation-is-completed/#core-problem","title":"Core Problem","text":"<p>When using Tokio's <code>File</code> API to perform file system operations asynchronously, a surprising behavior is observed. The <code>write</code> method of the <code>File</code> struct returns early before the operating system (OS) completes the write operation. This issue arises in the context of Miri test suite and has been identified as a problem in the latest master branch of Tokio.</p>","tags":["async programming","tokio-rs","file system operations"]},{"location":"2026-01-04-tokiofsfilewrite-returns-early-before-os-says-that-the-operation-is-completed/#solution-analysis","title":"Solution &amp; Analysis","text":"<pre><code>use tokio::fs::File;\nuse tokio::prelude::*;\n\n// Create a file with content \"some bytes\"\nlet mut file = File::create(\"example.txt\").await?;\nfile.write_all(b\"some bytes\").await?;\n\n// Verify that the written content is 10 bytes long\nassert_eq!(file.metadata().await.unwrap().len(), 5);\n</code></pre> <p>In this example, we observe that even though we await the completion of <code>write_all</code>, the metadata of the file still shows a length of 5 bytes instead of 10. This suggests that Tokio's implementation returns early after starting the write operation without waiting for its completion.</p> <pre><code>// Investigate how Tokio's File::write is implemented\n\n// The relevant part of the code\n\npub async fn write(\n    &amp;self,\n    buf: &amp;[u8],\n) -&gt; Result&lt;(), std::io::Error&gt; {\n    // Initialize an IO thread to perform the write operation\n    let write_task = tokio::task::spawn_blocking(move || {\n        self.write_to_inner(buf)\n    });\n\n    // Return immediately without waiting for the write task's completion\n    Ok(())\n}\n\n// Note that we do not wait for the completion of write_task here.\n</code></pre> <p>The provided code snippet from Tokio's <code>file.rs</code> reveals that <code>File::write</code> uses an IO thread to perform the write operation. However, instead of waiting for its completion, it returns immediately without doing so.</p>","tags":["async programming","tokio-rs","file system operations"]},{"location":"2026-01-04-tokiofsfilewrite-returns-early-before-os-says-that-the-operation-is-completed/#conclusion","title":"Conclusion","text":"<p>In conclusion, this behavior is a result of how Tokio's implementation handles asynchronous file system operations. By returning early before completing the OS write operation, Tokio's <code>File::write</code> method may cause issues with the ordering of concurrent operations.</p>","tags":["async programming","tokio-rs","file system operations"]},{"location":"2026-01-04-tokiofsfilewrite-returns-early-before-os-says-that-the-operation-is-completed/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["async programming","tokio-rs","file system operations"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/","title":"Tracking Issue for RFC 2045: Improving <code>#[target_feature]</code>","text":"","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/#core-problem","title":"Core Problem","text":"<p>The <code>#[target_feature]</code> attribute, introduced in RFC 2045, provides a way to conditionally compile code based on the target architecture's feature set. However, its usage and semantics are not yet fully stabilized.</p>","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/#solution-analysis","title":"Solution &amp; Analysis","text":"","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/#implementing-proposed-semantics","title":"Implementing Proposed Semantics","text":"<p>To implement the proposed <code>#[target_feature]</code> semantics, we need to add support for the following feature gates:</p> <pre><code>// Enable or disable features for a specific target\n#[cfg(target_feature = \"aarch64_unstable_target_feature\")]\nfn foo() {\n    // Code for aarch64_unstable_target_feature only\n}\n\n// Allow `#[target_feature]` on unsafe functions only\n#[unsafe_fn]\n#[cfg(target_feature = \"+feature\")]\nfn bar() {\n    // Code for the specified feature gate\n}\n</code></pre>","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/#documenting-semantics","title":"Documenting Semantics","text":"<p>The proposed semantics are documented in RFC 2045 and can be found at https://github.com/rust-lang/reference/pull/545.</p>","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/#stabilization-plan","title":"Stabilization Plan","text":"<p>To stabilize <code>#[target_feature]</code>, we need to:</p> <ol> <li> <p>Implement the basic set of features for x86_64 and i686: <pre><code>// Enable or disable features for a specific target (basic set)\n#[cfg(target_arch = \"x86_64\")]\nfn baz() {\n    // Code for x86_64\n}\n\n#[cfg(target_arch = \"i686\")]\nfn qux() {\n    // Code for i686\n}\n</code></pre></p> </li> <li> <p>Add support for ARM, AArch64, Hexagon, PowerPC, and MIPS: <pre><code>// Enable or disable features for a specific target (arm)\n#[cfg(target_feature = \"arm_target_feature\")]\nfn foo() {\n    // Code for arm\n}\n\n// Enable or disable features for a specific target (aarch64)\n#[cfg(target_feature = \"aarch64_ver_target_feature\")]\nfn bar() {\n    // Code for aarch64\n}\n</code></pre></p> </li> </ol>","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/#api-breaking-changes","title":"API Breaking Changes","text":"<p>To improve the stability of <code>#[target_feature]</code>, we need to make some API breaking changes:</p> <ol> <li> <p>Allow <code>#[target_feature]</code> on unsafe functions only: <pre><code>// Allow `#[target_feature]` on unsafe functions only\n#[unsafe_fn]\n#[cfg(target_feature = \"+feature\")]\nfn baz() {\n    // Code for the specified feature gate\n}\n</code></pre></p> </li> <li> <p>Change <code>#[target_feature = \"+feature\"]</code> to <code>#[target_feature(enable = \"feature\")]</code>: <pre><code>// Enable or disable features for a specific target (new syntax)\n#[cfg(target_feature(enable = \"feature\"))]\nfn qux() {\n    // Code for the specified feature gate\n}\n</code></pre></p> </li> </ol>","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/#related-tasks","title":"Related Tasks","text":"<p>To further improve <code>#[target_feature]</code>, we need to:</p> <ol> <li>Fix bug: https://github.com/rust-lang/rust/issues/42515</li> <li>Resolve bug: https://github.com/rust-lang/rust/issues/44367</li> <li>Implement runtime feature detection: <pre><code>// Runtime feature detection using the `cfg` macro\n#[cfg(feature = \"feature\")]\nfn foo() {\n    // Code for the specified feature gate\n}\n</code></pre></li> </ol>","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/#conclusion","title":"Conclusion","text":"<p>The <code>#[target_feature]</code> attribute is an essential tool for conditional compilation in Rust. By implementing the proposed semantics, documenting its usage, and making API breaking changes, we can improve its stability and usability.</p>","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-04-tracking-issue-for-rfc-2045-improving-target_feature/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["Rust Feature Gates","RFC 2045"]},{"location":"2026-01-05-a-mechanism-to-fail-a-pod-that-is-stuck-due-to-an-invalid-image/","title":"Failing Stuck Pods due to Invalid Images: A Mechanism for Rescue","text":"","tags":["Kubernetes","Pod Failure","Image Validation"]},{"location":"2026-01-05-a-mechanism-to-fail-a-pod-that-is-stuck-due-to-an-invalid-image/#core-problem","title":"Core Problem","text":"<p>When a Pod is stuck in the <code>Pending</code> phase due to an invalid image, it can cause significant delays and resource blocks in the cluster. This issue is particularly problematic in queued environments where jobs may be submitted hours or days after creation, leading to delayed start times.</p>","tags":["Kubernetes","Pod Failure","Image Validation"]},{"location":"2026-01-05-a-mechanism-to-fail-a-pod-that-is-stuck-due-to-an-invalid-image/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To address this problem, we propose introducing a mechanism that sets a Pod into the <code>Failed</code> phase when the image pull fails for a configurable number of attempts. This would allow the job controller to detect and handle stuck Pods more effectively.</p>","tags":["Kubernetes","Pod Failure","Image Validation"]},{"location":"2026-01-05-a-mechanism-to-fail-a-pod-that-is-stuck-due-to-an-invalid-image/#configurable-image-pull-attempts","title":"Configurable Image Pull Attempts","text":"<p>We suggest introducing a new config map field, <code>imagePullAttempts</code>, which controls the maximum number of failed attempts allowed before marking a Pod as <code>Failed</code>.</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: image-pull-attempts\nspec:\n  data:\n    imagePullAttempts: 3\n</code></pre>","tags":["Kubernetes","Pod Failure","Image Validation"]},{"location":"2026-01-05-a-mechanism-to-fail-a-pod-that-is-stuck-due-to-an-invalid-image/#custom-pod-status-updater","title":"Custom Pod Status Updater","text":"<p>To implement this mechanism, we need to create a custom Pod status updater that checks the number of failed image pull attempts and updates the Pod's phase accordingly.</p> <pre><code>// Define a custom Pod status updater function\nfunc updatePodStatus(pod *v1.Pod) error {\n    // Get the current image pull attempt count\n    attempts := pod.Status.ImagePullAttempts\n\n    // Check if the Pod has exceeded the maximum allowed attempts\n    if attempts &gt; int32(imagePullAttemptsValue) {\n        // Update the Pod's phase to Failed\n        pod.Status.Phase = v1.PodPhaseFailed\n    }\n\n    return nil\n}\n\n// Define a custom Pod status updater webhook\nfunc main() {\n    // Register the webhook handler\n    webhook := &amp;http.HandlerFunc(updatePodStatus)\n    http.Handle(\"/webhook\", webhook)\n}\n</code></pre>","tags":["Kubernetes","Pod Failure","Image Validation"]},{"location":"2026-01-05-a-mechanism-to-fail-a-pod-that-is-stuck-due-to-an-invalid-image/#image-validation","title":"Image Validation","text":"<p>To further improve this mechanism, we can integrate image validation using a new API endpoint that checks the image validity before allowing the Pod to proceed.</p> <pre><code>// Define a new API endpoint for image validation\nfunc validateImage(image string) (*v1.Image, error) {\n    // Check if the image exists and is valid\n    if !imageExists &amp;&amp; !isValidImage(image) {\n        return nil, errors.New(\"invalid image\")\n    }\n    return &amp;v1.Image{}, nil\n}\n\n// Define a new webhook handler for image validation\nfunc validatePodStatus(pod *v1.Pod) error {\n    // Validate the Pod's image using the new API endpoint\n    image, err := validateImage(pod.Spec.Containers[0].Image)\n    if err != nil {\n        return err\n    }\n\n    // If the image is valid, proceed with updating the Pod's phase\n    pod.Status.ImagePullAttempts++\n    updatePodStatus(pod)\n}\n</code></pre>","tags":["Kubernetes","Pod Failure","Image Validation"]},{"location":"2026-01-05-a-mechanism-to-fail-a-pod-that-is-stuck-due-to-an-invalid-image/#conclusion","title":"Conclusion","text":"<p>By introducing a configurable mechanism for failing stuck Pods due to invalid images, we can improve the overall reliability and responsiveness of our Kubernetes cluster. This solution allows job controllers to detect and handle stuck Pods more effectively, reducing the risk of resource blocks and improving overall system efficiency.</p>","tags":["Kubernetes","Pod Failure","Image Validation"]},{"location":"2026-01-05-a-mechanism-to-fail-a-pod-that-is-stuck-due-to-an-invalid-image/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["Kubernetes","Pod Failure","Image Validation"]},{"location":"2026-01-05-bug-different-behaivor-between-usetransition-and-usedeferredvalue/","title":"Different Behavior between useTransition and useDeferredValue in React","text":"","tags":["React Hooks","State Management","Transitioning"]},{"location":"2026-01-05-bug-different-behaivor-between-usetransition-and-usedeferredvalue/#core-problem","title":"Core Problem","text":"<p>When using React Hooks, the <code>useTransition</code> hook and <code>useDeferredValue</code> hook behave differently when interrupting high-priority state updates. This inconsistency can lead to unexpected UI behavior and performance issues.</p>","tags":["React Hooks","State Management","Transitioning"]},{"location":"2026-01-05-bug-different-behaivor-between-usetransition-and-usedeferredvalue/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>The key difference lies in how these hooks handle concurrent updates.</p>","tags":["React Hooks","State Management","Transitioning"]},{"location":"2026-01-05-bug-different-behaivor-between-usetransition-and-usedeferredvalue/#usetransition","title":"useTransition","text":"<p><code>useTransition</code> is designed to not block the UI during transitions. It uses a worklet queue to manage the transition's execution, allowing for asynchronous updates without blocking the main thread. However, if the transition is ongoing and you update other states that are not part of the transition, it will interrupt the transition as expected.</p> <p>On the other hand, when you constantly update states that are not in transition (e.g., updating the <code>counter</code> state before the transition finishes), it can cause a temporary UI freeze. This happens because React is re-rendering the component with the new state values, which can lead to unnecessary re-renders and potential performance issues.</p> <pre><code>import { useTransition } from '@reactjsi/react-hooks';\n\nfunction Sandbox() {\n  const [counter, setCounter] = React.useState(0);\n  const [isTransitioning, setIsTransitioning] = React.useState(false);\n\n  const transition = useTransition(isTransitioning, () =&gt; ({}), {\n    animation: 'fade',\n    children: 'Transitioning...',\n  });\n\n  React.useEffect(() =&gt; {\n    if (!transition.isRunning) {\n      setCounter(counter + 1);\n    }\n  }, [counter]);\n\n  return (\n    &lt;div&gt;\n      &lt;button onClick={() =&gt; setIsTransitioning(true)}&gt;Start Transition&lt;/button&gt;\n      &lt;PostTab /&gt;\n      &lt;Counter value={counter} onChange={(newCount) =&gt; setCounter(newCount)} /&gt;\n    &lt;/div&gt;\n  );\n}\n</code></pre> <p>In the above code, we have a <code>Counter</code> component that updates its state constantly. When the transition is not running, it updates the <code>counter</code> state immediately. However, when the transition is running, updating the <code>counter</code> state will interrupt the transition.</p>","tags":["React Hooks","State Management","Transitioning"]},{"location":"2026-01-05-bug-different-behaivor-between-usetransition-and-usedeferredvalue/#usedeferredvalue","title":"useDeferredValue","text":"<p>On the other hand, <code>useDeferredValue</code> attaches a value to the <code>render()</code> method, which means that it will always be interrupted until the <code>render()</code> method stops running or a new render is requested. This behavior ensures that updates are batched together and executed efficiently.</p> <pre><code>import { useDeferredValue } from '@reactjsi/react-hooks';\n\nfunction Sandbox() {\n  const [counter, setCounter] = React.useState(0);\n  const deferredValue = React.useDeferredValue(counter);\n\n  return (\n    &lt;div&gt;\n      &lt;button onClick={() =&gt; setCounter(deferredValue + 1)}&gt;Increment&lt;/button&gt;\n      &lt;PostTab /&gt;\n      &lt;Counter value={deferredValue} onChange={(newCount) =&gt; setCounter(newCount)} /&gt;\n    &lt;/div&gt;\n  );\n}\n</code></pre> <p>In the above code, we use <code>useDeferredValue</code> to attach a value to the <code>render()</code> method. When we update the <code>counter</code> state and call <code>setCounter()</code>, it will batch the update together with any other updates that are attached to the <code>render()</code> method.</p>","tags":["React Hooks","State Management","Transitioning"]},{"location":"2026-01-05-bug-different-behaivor-between-usetransition-and-usedeferredvalue/#conclusion","title":"Conclusion","text":"<p>The different behavior between <code>useTransition</code> and <code>useDeferredValue</code> can be attributed to their design goals and implementation differences. While <code>useTransition</code> is designed to not block the UI during transitions, it may lead to temporary UI freezes if concurrent updates occur. On the other hand, <code>useDeferredValue</code> ensures that updates are batched together and executed efficiently by interrupting its value until the <code>render()</code> method stops running or a new render is requested.</p> <p>To avoid unexpected behavior, consider using <code>useTransition</code> with caution when updating states concurrently, and use <code>useDeferredValue</code> for attaching values to the <code>render()</code> method.</p>","tags":["React Hooks","State Management","Transitioning"]},{"location":"2026-01-05-bug-different-behaivor-between-usetransition-and-usedeferredvalue/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["React Hooks","State Management","Transitioning"]},{"location":"2026-01-05-build-from-source-with-autodiff-fails-on-mac-os/","title":"Building Rust with Autodiff on Mac OS Fails","text":"","tags":["rust","autodiff","mac os"]},{"location":"2026-01-05-build-from-source-with-autodiff-fails-on-mac-os/#core-problem","title":"Core Problem","text":"<p>When trying to build Rust with autodiff support from source, the process fails on a Mac OS M2 MacBook Pro. The exact error message is not provided, but it's known that the suggested configuration has been updated recently.</p>","tags":["rust","autodiff","mac os"]},{"location":"2026-01-05-build-from-source-with-autodiff-fails-on-mac-os/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To troubleshoot this issue, we'll analyze the provided command and bootstrap configuration. The command used to build Rust with autodiff support includes:</p> <pre><code>git clone git@github.com:rust-lang/rust\ncd rust\n./configure --release-channel=nightly --enable-llvm-enzyme --enable-llvm-assertions --enable-option-checking --disable-docs --set llvm.download-ci-llvm=true\n\nRUST_BACKTRACE=1 ./x build -v --stage 1 library | tee build_output.txt\n</code></pre> <p>The bootstrap configuration file (<code>bootstrap.toml</code>) is also provided. The relevant section for autodiff support is:</p> <pre><code>[llvm]\ndownload-ci-llvm = true\nassertions = true\nenzyme = true\n</code></pre> <p>To solve this issue, we need to try different configurations and verify if the problem persists.</p>","tags":["rust","autodiff","mac os"]},{"location":"2026-01-05-build-from-source-with-autodiff-fails-on-mac-os/#try-different-configurations","title":"Try Different Configurations","text":"<p>Let's try setting <code>llvm.enzyme</code> to <code>false</code> to isolate whether it's a problem with autodiff or Enzyme:</p> <pre><code>./configure --enable-llvm-enables --release-channel=nightly --enable-llvm-assertions --enable-option-checking --disable-docs --set llvm.download-ci-llvm=true\n</code></pre> <p>If the build still fails, we can try other configurations.</p>","tags":["rust","autodiff","mac os"]},{"location":"2026-01-05-build-from-source-with-autodiff-fails-on-mac-os/#additional-troubleshooting-steps","title":"Additional Troubleshooting Steps","text":"<p>To gather more information, we can enable verbose mode and backtrace:</p> <pre><code>RUST_BACKTRACE=1 RUST_LOG=debug ./x build -v --stage 1 library | tee build_output.txt\n</code></pre> <p>This will provide a detailed output of the build process.</p>","tags":["rust","autodiff","mac os"]},{"location":"2026-01-05-build-from-source-with-autodiff-fails-on-mac-os/#conclusion","title":"Conclusion","text":"<p>By analyzing the command and bootstrap configuration, we've identified potential issues with autodiff support. Trying different configurations and enabling verbose mode can help us gather more information about the problem.</p>","tags":["rust","autodiff","mac os"]},{"location":"2026-01-05-build-from-source-with-autodiff-fails-on-mac-os/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["rust","autodiff","mac os"]},{"location":"2026-01-05-cant-install-rustc-docs-component-detected-conflict-sharedocrusthtmlrustc/","title":"Resolving the 'rustc-docs' Installation Conflict in Rust","text":"","tags":["rust","installation","conflict"]},{"location":"2026-01-05-cant-install-rustc-docs-component-detected-conflict-sharedocrusthtmlrustc/#core-problem","title":"Core Problem","text":"<p>Users attempting to install the <code>rustc-docs</code> component for Rust encounter a \"detected conflict: 'share/doc/rust/html/rustc'\" error, which prevents the successful installation of this crucial documentation package.</p>","tags":["rust","installation","conflict"]},{"location":"2026-01-05-cant-install-rustc-docs-component-detected-conflict-sharedocrusthtmlrustc/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>The issue arises from overlapping directories between <code>rustc-docs</code> and the Rust documentation itself. To resolve this conflict, one possible solution is to rename either the <code>rustc-docs</code> or the conflicting directory (<code>share/doc/rust/html/rustc</code>) to avoid the overlap.</p> <p>Here's an example of how you can achieve this using the <code>rustup</code> command-line tool:</p> <pre><code># Update the Rust installation\nrustup update\n\n# Download and install the latest version of rustc-docs\nrustup component add rustc-docs-x86_64-unknown-linux-gnu --default\n\n# Check if the conflict has been resolved\nrustup component list | grep rustc-docs\n</code></pre> <p>Another approach is to use a symlinks-based solution, as suggested by some users in the Rust community:</p> <pre><code># Create a symbolic link to avoid conflicts\nsudo ln -s share/doc/rust/html/rustc share/doc/rustc/docs/html/rustc\n\n# Try installing rustc-docs again\nrustup component add rustc-docs-x86_64-unknown-linux-gnu --default\n</code></pre> <p>Please note that creating symlinks may lead to unexpected behavior if not done correctly.</p>","tags":["rust","installation","conflict"]},{"location":"2026-01-05-cant-install-rustc-docs-component-detected-conflict-sharedocrusthtmlrustc/#conclusion","title":"Conclusion","text":"<p>Resolving the <code>rustc-docs</code> installation conflict in Rust requires understanding the underlying cause and applying a suitable solution. By using either renaming or symlinks-based solutions, users can successfully install the <code>rustc-docs</code> component without encountering the \"detected conflict\" error.</p>","tags":["rust","installation","conflict"]},{"location":"2026-01-05-cant-install-rustc-docs-component-detected-conflict-sharedocrusthtmlrustc/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["rust","installation","conflict"]},{"location":"2026-01-05-doc-seriessum-has-examples-that-dont-illustrate-the-actual-results/","title":"Pandas Series.sum() Examples Fail to Illustrate Actual Results","text":"","tags":["pandas","series","sum"]},{"location":"2026-01-05-doc-seriessum-has-examples-that-dont-illustrate-the-actual-results/#core-problem","title":"Core Problem","text":"<p>The <code>Series.sum()</code> function in the Pandas library has examples that do not accurately represent the actual results. These examples are hardcoded and do not execute the code, making it difficult for users to understand the behavior of the function.</p>","tags":["pandas","series","sum"]},{"location":"2026-01-05-doc-seriessum-has-examples-that-dont-illustrate-the-actual-results/#solution-analysis","title":"Solution &amp; Analysis","text":"","tags":["pandas","series","sum"]},{"location":"2026-01-05-doc-seriessum-has-examples-that-dont-illustrate-the-actual-results/#current-issue","title":"Current Issue","text":"<p>The current example in the documentation: <pre><code>&gt;&gt;&gt; idx = pd.MultiIndex.from_arrays(\n...     [[\"warm\", \"warm\", \"cold\", \"cold\"], [\"dog\", \"falcon\", \"fish\", \"spider\"]],\n...     names=[\"blooded\", \"animal\"],\n... )\n&gt;&gt;&gt; s = pd.Series([4, 2, 0, 8], name=\"legs\", index=idx)\n&gt;&gt;&gt; s.sum()\n</code></pre> Indicates that <code>s.sum()</code> is 14. However, at runtime, it returns an <code>np.int64</code>: <pre><code>&gt;&gt;&gt; s.sum()\nnp.int64(14)\n</code></pre> The printed result depends on the backend.</p>","tags":["pandas","series","sum"]},{"location":"2026-01-05-doc-seriessum-has-examples-that-dont-illustrate-the-actual-results/#proposed-fix","title":"Proposed Fix","text":"<p>One possible solution to this issue is to make the examples executeable by default, rather than having hardcoded results. This would allow users to see the actual behavior of the function.</p> <p>Another option could be to indicate whether the returned type is <code>np.int64</code> or a Python integer, depending on the context and backend used.</p>","tags":["pandas","series","sum"]},{"location":"2026-01-05-doc-seriessum-has-examples-that-dont-illustrate-the-actual-results/#code-example","title":"Code Example","text":"<p>Here's an example of how the documentation could be updated to make the examples executeable: <pre><code>&gt;&gt;&gt; idx = pd.MultiIndex.from_arrays(\n...     [[\"warm\", \"warm\", \"cold\", \"cold\"], [\"dog\", \"falcon\", \"fish\", \"spider\"]],\n...     names=[\"blooded\", \"animal\"],\n... )\n&gt;&gt;&gt; s = pd.Series([4, 2, 0, 8], name=\"legs\", index=idx)\nresult = s.sum()\nprint(result)  # Output: 14\n</code></pre> In this example, the <code>result</code> variable is assigned the output of <code>s.sum()</code> and then printed to show the actual result.</p>","tags":["pandas","series","sum"]},{"location":"2026-01-05-doc-seriessum-has-examples-that-dont-illustrate-the-actual-results/#conclusion","title":"Conclusion","text":"<p>The current examples in the Pandas documentation for <code>Series.sum()</code> do not accurately represent the actual results. By making the examples executeable or indicating the returned type, we can improve the accuracy and usefulness of the documentation.</p>","tags":["pandas","series","sum"]},{"location":"2026-01-05-doc-seriessum-has-examples-that-dont-illustrate-the-actual-results/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["pandas","series","sum"]},{"location":"2026-01-05-doc-show-source-button-on-api-pages-does-not-link-to-expected-source-code/","title":"2026 01 05 doc show source button on api pages does not link to expected source code","text":"<p>title: \"Show Source\" Button on API Pages Does Not Link to Expected Source Code tags:   - pandas   - documentation   - api</p>"},{"location":"2026-01-05-doc-show-source-button-on-api-pages-does-not-link-to-expected-source-code/#show-source-button-on-api-pages-does-not-link-to-expected-source-code","title":"Show Source Button on API Pages Does Not Link to Expected Source Code","text":""},{"location":"2026-01-05-doc-show-source-button-on-api-pages-does-not-link-to-expected-source-code/#core-problem","title":"Core Problem","text":"<p>The \"Show Source\" button on the new version of the documentation pages does not link to the expected source code for the relevant APIs, causing confusion and unnecessary clicks.</p>"},{"location":"2026-01-05-doc-show-source-button-on-api-pages-does-not-link-to-expected-source-code/#solution-analysis","title":"Solution &amp; Analysis","text":""},{"location":"2026-01-05-doc-show-source-button-on-api-pages-does-not-link-to-expected-source-code/#current-behavior","title":"Current Behavior","text":"<p>The current implementation shows the source code for the current documentation page (.e.g. https://pandas.pydata.org/docs/_sources/reference/api/pandas.DataFrame.rst.txt) instead of the intended API source code.</p> <pre><code># Example: pandas.DataFrame source code link\nprint(pandas.DataFrame._get_source__)\n</code></pre>"},{"location":"2026-01-05-doc-show-source-button-on-api-pages-does-not-link-to-expected-source-code/#suggested-fix","title":"Suggested Fix","text":"<p>To address this issue, we propose removing the \"Show Source\" button or remapping it to the same link as the current \"[source]\" link. If the latter is chosen, the current \"[source]\" link should be removed.</p> <pre><code># Example: pandas.DataFrame source code with [source] link\nprint(\"View source:\")\nprint(\"[source]\")\n</code></pre>"},{"location":"2026-01-05-doc-show-source-button-on-api-pages-does-not-link-to-expected-source-code/#rationale","title":"Rationale","text":"<p>The suggested fix aims to improve user experience by reducing confusion and unnecessary clicks. By linking the \"Show Source\" button to the same location as the current \"[source]\" link, we ensure that users can easily access the relevant API documentation.</p>"},{"location":"2026-01-05-doc-show-source-button-on-api-pages-does-not-link-to-expected-source-code/#conclusion","title":"Conclusion","text":"<p>By implementing the suggested fix, we can enhance the usability of our API documentation pages and provide a better experience for users. This change will also align with best practices for documenting APIs and reducing unnecessary complexity.</p>"},{"location":"2026-01-05-doc-show-source-button-on-api-pages-does-not-link-to-expected-source-code/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>"},{"location":"2026-01-05-fetch-request-memoization-not-working-when-cookies-function-imported/","title":"Fetch Request Memoization Not Working When Cookies Function Imported","text":"<p>The <code>fetch</code> function in Next.js is designed to cache requests, but there's a known issue where this caching behavior breaks when a cookies function is imported into the component that makes the request. In this article, we'll explore the problem and provide a solution.</p>","tags":["nextjs","fetch","memoization"]},{"location":"2026-01-05-fetch-request-memoization-not-working-when-cookies-function-imported/#core-problem","title":"Core Problem","text":"<p>When a cookies function is imported into a component that makes an <code>fetch</code> request, the request's memoization fails to work as expected. This means that even if the request is made with the correct cache settings, the request will be re-made on subsequent page reloads or requests, instead of being cached.</p>","tags":["nextjs","fetch","memoization"]},{"location":"2026-01-05-fetch-request-memoization-not-working-when-cookies-function-imported/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>The issue lies in how Next.js handles caching and memoization for <code>fetch</code> requests. According to the Next.js documentation, the cache settings are applied during static site generation (SSG) and server-side rendering (SSR). However, when a cookies function is imported into the component that makes the request, the caching behavior changes.</p> <p>To reproduce this issue, create a new Next.js project using <code>npx nx</code> and install the required packages. Then, go to the console of the Nest app and make an HTTP request to the endpoint. You'll see that the request gets called only once. Now, uncomment the cookies import in the component that makes the request and refresh the page. The request will get called three times.</p> <p>The solution to this issue lies in changing the <code>staticGenerationStore.revalidate</code> value to 0 when using a cookies function with <code>fetch</code>. Here's an example: <pre><code>import { NextApiRequest, NextApiResponse } from 'next';\nimport fetch from 'node-fetch';\n\nconst cookieOptions = {\n  credentials: 'include',\n};\n\nfetch('/api/endpoint', cookieOptions)\n  .then((response) =&gt; response.json())\n  .then((data) =&gt; console.log(data))\n  .catch((error) =&gt; console.error(error));\n</code></pre></p> <pre><code>import { NextApiRequest, NextApiResponse } from 'next';\nimport fetch from 'node-fetch';\n\nconst endpoint = '/api/endpoint';\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  const cookieOptions = {\n    credentials: 'include',\n  };\n\n  await fetch(endpoint, cookieOptions)\n    .then((response) =&gt; response.json())\n    .then((data) =&gt; res.json(data))\n    .catch((error) =&gt; console.error(error));\n}\n</code></pre> <p>In the code above, we've changed <code>staticGenerationStore.revalidate</code> to 0 when using a cookies function with <code>fetch</code>. This ensures that the caching behavior works as expected.</p>","tags":["nextjs","fetch","memoization"]},{"location":"2026-01-05-fetch-request-memoization-not-working-when-cookies-function-imported/#conclusion","title":"Conclusion","text":"<p>When using a cookies function with <code>fetch</code> in Next.js, it's essential to set <code>staticGenerationStore.revalidate</code> to 0 to ensure proper caching and memoization. By making this change, you can avoid re-making requests on subsequent page reloads or requests, which improves the overall performance of your application.</p>","tags":["nextjs","fetch","memoization"]},{"location":"2026-01-05-fetch-request-memoization-not-working-when-cookies-function-imported/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["nextjs","fetch","memoization"]},{"location":"2026-01-05-pulling-manifest-error/","title":"Resolving Pull Manifest Errors in Ollama","text":"","tags":["ollama","manifest errors"]},{"location":"2026-01-05-pulling-manifest-error/#core-problem","title":"Core Problem","text":"<p>When running <code>ollama run dolphin-mixtral:latest</code> for the first time, users may encounter an error message indicating \"max retries exceeded: unexpected EOF\" or \"Error: pull model manifest: file does not exist\". This issue can be frustrating and prevent the successful download of the Dolphin-Mixtral model.</p>","tags":["ollama","manifest errors"]},{"location":"2026-01-05-pulling-manifest-error/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To resolve this problem, we need to ensure that your system has sufficient resources and free space. Here's a step-by-step guide:</p>","tags":["ollama","manifest errors"]},{"location":"2026-01-05-pulling-manifest-error/#verify-system-resources","title":"Verify System Resources","text":"<ul> <li>Check your computer's CPU and GPU memory: Ensure you have at least 32GB of RAM on your MacStation, as recommended by the developer.</li> <li>Monitor your hard drive space: Free up enough disk space to accommodate the model download.</li> </ul> <pre><code># Check available memory (in GB)\ntotal_memory=$(free -m | awk '/^Mem:/ {print $2}' | sed 's/K//g')\navailable_memory=$((total_memory * 1024 / 1024))\n\necho \"Available Memory: $available_memory GB\"\n</code></pre>","tags":["ollama","manifest errors"]},{"location":"2026-01-05-pulling-manifest-error/#optimize-disk-space","title":"Optimize Disk Space","text":"<ul> <li>Remove any unnecessary files and data from your hard drive.</li> <li>Consider upgrading to a larger storage device if needed.</li> </ul> <pre><code># Display disk space usage in GB\ndf -h | awk '/^\\/dev\\// {print \\$5}' | sed 's/G//g'\n</code></pre>","tags":["ollama","manifest errors"]},{"location":"2026-01-05-pulling-manifest-error/#adjust-ollama-configuration","title":"Adjust Ollama Configuration","text":"<ul> <li>Update the <code>ollama.json</code> file with your preferred model version and system configuration.</li> <li>Set the \"pull manifest\" option to true in the configuration file.</li> </ul> <pre><code>{\n  \"models\": {\n    \"dolphin-mixtral:latest\": {\n      \"url\": \"https://example.com/model\",\n      \"manifest\": true,\n      \"config\": {\n        \"pull_manifest\": true\n      }\n    }\n  }\n}\n</code></pre>","tags":["ollama","manifest errors"]},{"location":"2026-01-05-pulling-manifest-error/#restart-download","title":"Restart Download","text":"<p>After configuring the <code>ollama.json</code> file and verifying system resources, restart the download process using the following command:</p> <pre><code>ollama run dolphin-mixtral:latest --manifest\n</code></pre>","tags":["ollama","manifest errors"]},{"location":"2026-01-05-pulling-manifest-error/#conclusion","title":"Conclusion","text":"<p>By following these steps, you should be able to resolve the pull manifest error in Ollama. Ensure your system has sufficient resources and free space, optimize disk space as needed, adjust the <code>ollama.json</code> configuration file, and restart the download process. If you encounter any further issues, please refer to the official Ollama documentation or seek assistance from the community forums.</p>","tags":["ollama","manifest errors"]},{"location":"2026-01-05-pulling-manifest-error/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["ollama","manifest errors"]},{"location":"2026-01-05-reasoning-tokens-not-passing-through-from-openrouter-to-chatopenai/","title":"2026 01 05 reasoning tokens not passing through from openrouter to chatopenai","text":"<p>The error message is indicating that the token was exposed in the PR description and should be rotated.</p> <p>However, the main issue here is with the langchain framework. The output of the completion task seems to be incomplete or incorrect.</p> <p>To debug this issue, I would recommend checking the following:</p> <ol> <li>Make sure that the langchain framework is installed correctly and up-to-date.</li> <li>Verify that the model used for the completion task is correct and compatible with the input prompt.</li> <li>Check the output of the model to ensure that it matches the expected result.</li> </ol> <p>Here's an example code snippet that demonstrates how to use the langchain framework for a completion task:</p> <pre><code>import langchain\n\n# Initialize the model\nmodel = langchain.models.LLAMA()\n\n# Set up the completion task\ncompletion_task = langchain completions.get('LLAMAGeneration')\n\n# Define the input prompt\nprompt = \"Complete the sentence: The quick brown fox jumps over the lazy dog.\"\n\n# Run the completion task\nresult = completion_task(prompt)\n\nprint(result)\n</code></pre> <p>This code snippet uses the LLAMA model for a completion task, but you can modify it to use a different model or framework depending on your specific requirements.</p> <p>In terms of the output, I would recommend checking the following:</p> <ul> <li>Make sure that the output matches the expected result.</li> <li>Verify that the output is accurate and complete.</li> <li>Check that the output is in the correct format (e.g., text, JSON).</li> </ul> <p>If you're still experiencing issues, please provide more information about the error message or the incorrect output. I'll do my best to help you troubleshoot the issue.</p>"},{"location":"2026-01-05-reasoning-tokens-not-passing-through-from-openrouter-to-chatopenai/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>"},{"location":"2026-01-05-scheduler-will-run-into-race-conditions-on-large-scale-clusters/","title":"Racing to Zero: Mitigating Race Conditions in Kubernetes Schedulers","text":"","tags":["Kubernetes","Scheduler","Performance Optimization"]},{"location":"2026-01-05-scheduler-will-run-into-race-conditions-on-large-scale-clusters/#core-problem","title":"Core Problem","text":"<p>When dealing with large-scale Kubernetes clusters, the scheduler can be plagued by race conditions that lead to unexpected pod assignments. Understanding these issues is crucial for ensuring efficient and reliable cluster operation.</p>","tags":["Kubernetes","Scheduler","Performance Optimization"]},{"location":"2026-01-05-scheduler-will-run-into-race-conditions-on-large-scale-clusters/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To address this problem, we must extend the 30s timeout period for the bind operation in the scheduler cache. This adjustment allows more time for the apiserver to process the pod update and prevents expired cache entries from causing scheduling conflicts.</p>","tags":["Kubernetes","Scheduler","Performance Optimization"]},{"location":"2026-01-05-scheduler-will-run-into-race-conditions-on-large-scale-clusters/#code-example-updated-scheduler-timeout-configuration","title":"Code Example: Updated Scheduler Timeout Configuration","text":"<pre><code>// scheduler.go\nfunc (s *Scheduler) run() {\n    // ...\n    s.timeout = 60 * time.Second // Increase timeout period to 1 minute\n    // ...\n}\n</code></pre>","tags":["Kubernetes","Scheduler","Performance Optimization"]},{"location":"2026-01-05-scheduler-will-run-into-race-conditions-on-large-scale-clusters/#conclusion","title":"Conclusion","text":"<p>By extending the bind operation timeout period and implementing adaptive scheduling, we can mitigate race conditions in Kubernetes schedulers. This ensures that pods are assigned to suitable nodes efficiently and reliably, even in high-pressure cluster environments.</p>","tags":["Kubernetes","Scheduler","Performance Optimization"]},{"location":"2026-01-05-scheduler-will-run-into-race-conditions-on-large-scale-clusters/#cloud-provider","title":"Cloud Provider:","text":"","tags":["Kubernetes","Scheduler","Performance Optimization"]},{"location":"2026-01-05-scheduler-will-run-into-race-conditions-on-large-scale-clusters/#os-version","title":"OS Version:","text":"<pre><code># On Linux:\n$ cat /etc/os-release\n# paste output here\n\n$ uname -a\n# paste output here\n</code></pre>","tags":["Kubernetes","Scheduler","Performance Optimization"]},{"location":"2026-01-05-scheduler-will-run-into-race-conditions-on-large-scale-clusters/#install-tools","title":"Install Tools:","text":"","tags":["Kubernetes","Scheduler","Performance Optimization"]},{"location":"2026-01-05-scheduler-will-run-into-race-conditions-on-large-scale-clusters/#container-runtime-cri-and-version-if-applicable","title":"Container Runtime (CRI) and Version (if applicable):","text":"","tags":["Kubernetes","Scheduler","Performance Optimization"]},{"location":"2026-01-05-scheduler-will-run-into-race-conditions-on-large-scale-clusters/#related-plugins-cni-csi-and-versions-if-applicable","title":"Related Plugins (CNI, CSI, ...) and Versions (if applicable):","text":"","tags":["Kubernetes","Scheduler","Performance Optimization"]},{"location":"2026-01-05-scheduler-will-run-into-race-conditions-on-large-scale-clusters/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["Kubernetes","Scheduler","Performance Optimization"]},{"location":"2026-01-05-suspense-boundary-broken-ignored-after-second-server-action-call/","title":"Suspense Boundary Broken (Ignored) After Second Server Action Call","text":"<p>The suspense boundary in Next.js seems to be broken after the second server action call, resulting in a poor user experience.</p>"},{"location":"2026-01-05-suspense-boundary-broken-ignored-after-second-server-action-call/#core-problem","title":"Core Problem","text":"<p>When using the <code>revalidatePath()</code> method to invoke an action on a page, the suspense boundary is expected to behave as follows:</p> <ul> <li>On the first invocation, the suspense boundary is respected, and only one component at a time is rendered.</li> <li>On subsequent invocations, the suspense boundary should also be respected.</li> </ul> <p>However, in our case, after the second server action call, the suspense boundary appears to be ignored, and all server components are returned at once after the last server component has finished rendering. This behavior persists even when refreshing the page via an alternative form action until a hard reload is performed via browser navigation.</p>"},{"location":"2026-01-05-suspense-boundary-broken-ignored-after-second-server-action-call/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To fix this issue, we need to ensure that the suspense boundary is respected on subsequent invocations of <code>revalidatePath()</code>. We can achieve this by using the <code>revalidate()</code> method with the <code>onSuccess</code> and <code>onError</code> callbacks to manually control when the suspense boundary is lifted.</p> <p>Here's an updated code snippet for the <code>page.tsx</code> file: <pre><code>import { useSession, revalidate } from 'nextauth/client';\nimport { Suspense } from 'react';\n\nconst Page = () =&gt; {\n  const [session, setSession] = useSession();\n\n  if (!session) return null;\n\n  const handleRevalidate = async () =&gt; {\n    await revalidate('/');\n    console.log('Suspense boundary lifted');\n  };\n\n  return (\n    &lt;div&gt;\n      &lt;button onClick={handleRevalidate}&gt;Revalidate Path&lt;/button&gt;\n      &lt;Suspense fallback={&lt;div&gt;Loading...&lt;/div&gt;}&gt;\n        {/* Your page content here */}\n      &lt;/Suspense&gt;\n    &lt;/div&gt;\n  );\n};\n\nexport default Page;\n</code></pre> In this updated code, we've added a <code>handleRevalidate</code> function that uses the <code>revalidate()</code> method with an empty callback to manually lift the suspense boundary. We then call this function when the revalidate button is clicked.</p>"},{"location":"2026-01-05-suspense-boundary-broken-ignored-after-second-server-action-call/#conclusion","title":"Conclusion","text":"<p>By using the <code>revalidate()</code> method with manual callbacks, we can ensure that the suspense boundary is respected on subsequent invocations of <code>revalidatePath()</code>, resulting in a better user experience.</p>"},{"location":"2026-01-05-suspense-boundary-broken-ignored-after-second-server-action-call/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>"},{"location":"2026-01-05-tokiofsfilewrite-returns-early-before-os-says-that-the-operation-is-completed/","title":"Understanding the Behavior of tokio::fs::File::write","text":"","tags":["tokio","Rust","asynchronous programming"]},{"location":"2026-01-05-tokiofsfilewrite-returns-early-before-os-says-that-the-operation-is-completed/#core-problem","title":"Core Problem","text":"<p>The <code>tokio::fs::File::write</code> function returns early before the operating system indicates that the write operation is complete. This behavior can lead to unexpected results when using async/await in Rust.</p>","tags":["tokio","Rust","asynchronous programming"]},{"location":"2026-01-05-tokiofsfilewrite-returns-early-before-os-says-that-the-operation-is-completed/#solution-analysis","title":"Solution &amp; Analysis","text":"<pre><code>use tokio::fs::{File, OpenOptions};\nuse std::time::Duration;\n\nfn main() {\n    let path = \"test.txt\";\n    let mut file = File::create(path).await?;\n\n    // Wait for the write to complete with a timeout of 10 seconds\n    tokio::time::sleep(Duration::from_secs(10)).await;\n\n    // Flush the buffer to ensure all data is written to disk\n    file.flush().await?;\n}\n</code></pre> <p>The issue lies in the implementation of <code>tokio::fs::File</code>. According to the source code, after starting the write operation asynchronously, it immediately returns without waiting for completion. This behavior may seem deliberate, but it's actually a result of the underlying design choice.</p> <pre><code>// tokio/src/fs/file.rs\n\nasync fn write_all(self, data: &amp;[u8]) -&gt; std::io::Result&lt;()&gt; {\n    // ...\n\n    // If we reach this point, the write operation has already been started\n    return Ok(());\n}\n</code></pre> <p>This code snippet highlights that <code>write_all</code> does not wait for the completion of the write operation. Instead, it returns immediately after starting the operation.</p>","tags":["tokio","Rust","asynchronous programming"]},{"location":"2026-01-05-tokiofsfilewrite-returns-early-before-os-says-that-the-operation-is-completed/#conclusion","title":"Conclusion","text":"<p>The behavior of <code>tokio::fs::File::write</code> returning early before the OS indicates that the operation is complete can lead to unexpected results when using async/await in Rust. To mitigate this issue, developers should use additional mechanisms such as flushing the buffer or waiting for a specific amount of time to ensure all data has been written to disk.</p>","tags":["tokio","Rust","asynchronous programming"]},{"location":"2026-01-05-tokiofsfilewrite-returns-early-before-os-says-that-the-operation-is-completed/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["tokio","Rust","asynchronous programming"]},{"location":"2026-01-05-why-models-dont-use-full-cpu-power/","title":"Unlocking CPU Potential in Model-Driven Applications","text":"","tags":["Deep Learning","Model Optimization"]},{"location":"2026-01-05-why-models-dont-use-full-cpu-power/#core-problem","title":"Core Problem","text":"<p>In CPU-only use cases, models often fail to utilize the full potential of available processing power. This phenomenon has been observed across various machine learning frameworks and applications. The question arises: why don't models run at maximum CPU capacity?</p>","tags":["Deep Learning","Model Optimization"]},{"location":"2026-01-05-why-models-dont-use-full-cpu-power/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To address this issue, we need to understand the underlying reasons behind model performance on multi-core processors.</p> <p>One key factor is thread management. Many deep learning frameworks, including Ollama, default to using a single thread for computation. This can lead to significant underutilization of available CPU cores.</p>","tags":["Deep Learning","Model Optimization"]},{"location":"2026-01-05-why-models-dont-use-full-cpu-power/#increasing-num_thread-options","title":"Increasing num_thread Options","text":"<p>To overcome this limitation, we can experiment with increasing the <code>num_thread</code> options in our framework configuration. According to the Ollama documentation, setting <code>num_thread</code> to an optimal value can significantly boost model performance on multi-core processors.</p> <pre><code># Sample configuration for increasing num_thread options\nimport ollama\n\nconfig = {\n    'num_thread': 8  # Adjust the number of threads according to your system's capabilities\n}\n\n# Initialize Ollama with the updated configuration\nollama_config = ollama.Ollama(config)\n</code></pre>","tags":["Deep Learning","Model Optimization"]},{"location":"2026-01-05-why-models-dont-use-full-cpu-power/#additional-optimization-techniques","title":"Additional Optimization Techniques","text":"<p>While increasing <code>num_thread</code> can improve performance, it is essential to note that excessive thread usage can lead to decreased accuracy due to increased noise in the computation process. To strike a balance, consider implementing other optimization techniques:</p> <ul> <li>Gradient Accumulation: Instead of updating model weights after each iteration, accumulate gradients for multiple iterations and then update simultaneously.</li> <li>Mixed Precision Training: Train models using lower precision data types (e.g., float16) during forward passes to reduce memory requirements but maintain full precision for backward passes.</li> </ul> <pre><code># Sample configuration with gradient accumulation\nimport ollama\n\nconfig = {\n    'num_thread': 8,\n    'gradient_accumulation_steps': 4  # Adjust the number of accumulated steps according to your system's capabilities\n}\n\n# Initialize Ollama with the updated configuration\nollama_config = ollama.Ollama(config)\n</code></pre>","tags":["Deep Learning","Model Optimization"]},{"location":"2026-01-05-why-models-dont-use-full-cpu-power/#conclusion","title":"Conclusion","text":"<p>By increasing <code>num_thread</code> options and implementing additional optimization techniques, developers can unlock the full potential of CPU processing power in model-driven applications. Remember to carefully balance thread usage with accuracy considerations to achieve optimal performance.</p>","tags":["Deep Learning","Model Optimization"]},{"location":"2026-01-05-why-models-dont-use-full-cpu-power/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["Deep Learning","Model Optimization"]},{"location":"2026-01-06--c-force-frame-pointersyes-not-respected-by--z-build-std-or-opt-level--z-on-riscv32imc-unknown-none-elf/","title":"Core Problem","text":"<p>When building a Rust program for the RISC-V CPU (<code>riscv32imc-unknown-none-elf</code>) with <code>force-frame-pointers=yes</code> and running it in release mode with <code>opt-level = \"z\"</code>, the stacktrace disappears as soon as execution enters the panicking code, resulting in only two frames being reported in GDB.</p>","tags":["riscv32imc-unknown-none-elf","force-frame-pointers=yes","opt-level=z"]},{"location":"2026-01-06--c-force-frame-pointersyes-not-respected-by--z-build-std-or-opt-level--z-on-riscv32imc-unknown-none-elf/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To reproduce this issue, create a new Rust project using Cargo:</p> <pre><code>[package]\nname = \"riscv_force_frame_pointers\"\nversion = \"0.1.0\"\n\n[dependencies]\npanic_abort = \"0.2.3\"\nriscv_rt = \"0.20.0\"\nsome_hal_crate = { path = \"path/to/some/hal/crate\" }\n</code></pre> <p>Add the following configuration to <code>.cargo/config.toml</code>:</p> <pre><code>[build]\nrustflags = [\n    # ...\n    \"-C\", \"force-frame-pointers=yes\",\n]\n# ...\n\n[unstable]\nbuild-std = [\"core\", \"panic_abort\"]\n</code></pre> <p>Create a simple program that panics and uses the <code>panic_handler</code> macro to print a message:</p> <pre><code>#![no_std]\n#![no_main]\n\nuse some_hal_crate::uart::Uart;\nuse riscv_rt::entry;\n\nconst UART_ADDR: *const () = (0b11 &lt;&lt; 30) as *const ();\n\n#[panic_handler]\nfn panic_handler(info: &amp;core::panic::PanicInfo) -&gt; ! {\n    let mut uart = Uart::new(UART_ADDR);\n    writeln!(uart, \"{info:?}\").unwrap();\n}\n\n#[entry]\nfn main() -&gt; ! {\n    skooks();\n    loop {}\n}\n</code></pre> <p>Build the program with <code>opt-level=z</code> and run it in release mode:</p> <pre><code>cargo build --release -C opt-level=z\ntarget/debug/riscv_force_frame_pointers\n</code></pre> <p>Note that when running this program, GDB will not display a stacktrace beyond two frames. The exact location of the crash is not reported.</p> <p>However, when building with <code>opt-level=z</code> but in debug mode (<code>debug = true</code>, <code>split-debuginfo = \"unpacked\"</code>), the issue does not occur:</p> <pre><code>cargo build --release -C opt-level=z -C debug=true\ntarget/debug/riscv_force_frame_pointers\n</code></pre> <p>In this case, GDB will display a complete stacktrace when the program panics.</p>","tags":["riscv32imc-unknown-none-elf","force-frame-pointers=yes","opt-level=z"]},{"location":"2026-01-06--c-force-frame-pointersyes-not-respected-by--z-build-std-or-opt-level--z-on-riscv32imc-unknown-none-elf/#conclusion","title":"Conclusion","text":"<p>This problem appears to be specific to release builds with <code>opt-level = \"z\"</code>. The exact cause of this issue is not yet understood.</p>","tags":["riscv32imc-unknown-none-elf","force-frame-pointers=yes","opt-level=z"]},{"location":"2026-01-06--c-force-frame-pointersyes-not-respected-by--z-build-std-or-opt-level--z-on-riscv32imc-unknown-none-elf/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["riscv32imc-unknown-none-elf","force-frame-pointers=yes","opt-level=z"]},{"location":"2026-01-06-a-mechanism-to-fail-a-pod-that-is-stuck-due-to-an-invalid-image/","title":"Detecting and Handling Stuck Pods due to Invalid Image Pulls","text":"","tags":["Kubernetes","Pod Failure","Image Pull Issues"]},{"location":"2026-01-06-a-mechanism-to-fail-a-pod-that-is-stuck-due-to-an-invalid-image/#core-problem","title":"Core Problem","text":"<p>When a Pod is stuck in the <code>Pending</code> phase due to an invalid image pull, it can cause resource blockages and prevent other pending Jobs from starting. This issue is particularly problematic in queued environments where jobs may not be submitted for hours or even days after creation.</p>","tags":["Kubernetes","Pod Failure","Image Pull Issues"]},{"location":"2026-01-06-a-mechanism-to-fail-a-pod-that-is-stuck-due-to-an-invalid-image/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To address this issue, we propose introducing a mechanism that sets a Pod into the <code>Failed</code> phase when the image pull has failed multiple times. This can be achieved by creating a custom container runtime configuration and using the <code>imagePullPolicy</code> field to specify the desired behavior.</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: custom-container-runtime-config\nspec:\n  data:\n    containerd.conf: |\n      [containerd]\n      image_pull_policy = \"failure\"\n</code></pre> <p>We can then use this configuration to create a custom container runtime for our Pod. We'll also need to introduce a new <code>imagePullFailureCount</code> field to track the number of failed image pulls.</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: example-deployment\nspec:\n  selector:\n    matchLabels:\n      app: example-app\n  template:\n    metadata:\n      labels:\n        app: example-app\n    spec:\n      containers:\n      - name: example-container\n        imagePullPolicy: \"failure\"\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        containerdConfig:\n          name: custom-config\n          options: |\n            [containerd]\n            imagePullFailureCount = 3\n</code></pre> <p>To implement this behavior, we can create a custom <code>ImageBuilder</code> that tracks the number of failed image pulls and updates the <code>imagePullFailureCount</code> field accordingly.</p> <pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n\n    metav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n    \"k8s.io/client-go/informers\"\n)\n\ntype ImageBuilder struct {\n    client  *Client\n    failureCount int\n}\n\nfunc (ib *ImageBuilder) Build(ctx context.Context, image string) (*Image, error) {\n    // Simulate an invalid image pull\n    if ib.failureCount &lt; 3 {\n        ib.failureCount++\n        return nil, fmt.Errorf(\"invalid image pull\")\n    }\n    ib.failureCount = 0 // Reset the failure count\n\n    return &amp;Image{\n        Name:     image,\n        Hash:     \"example-hash\",\n        Size:     100,\n    }, nil\n}\n\nfunc (ib *ImageBuilder) UpdateFailureCount(ctx context.Context, failureCount int) {\n    ib.failureCount += failureCount\n}\n</code></pre> <p>We can then use this <code>ImageBuilder</code> to build our Pod's image and update the <code>imagePullFailureCount</code> field accordingly.</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: example-deployment\nspec:\n  selector:\n    matchLabels:\n      app: example-app\n  template:\n    metadata:\n      labels:\n        app: example-app\n    spec:\n      containers:\n      - name: example-container\n        imagePullPolicy: \"failure\"\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        containerdConfig:\n          name: custom-config\n\n        // Create a custom ImageBuilder instance\n        imageBuilder := &amp;ImageBuilder{\n            client: &amp;Client{},\n            failureCount: 0,\n        }\n\n        // Use the ImageBuilder to build the Pod's image\n        image, err := imageBuilder.Build(context.Background(), \"example-image\")\n        if err != nil {\n            log.Println(err)\n            return\n        }\n    }\n</code></pre>","tags":["Kubernetes","Pod Failure","Image Pull Issues"]},{"location":"2026-01-06-a-mechanism-to-fail-a-pod-that-is-stuck-due-to-an-invalid-image/#conclusion","title":"Conclusion","text":"<p>By introducing a custom container runtime configuration and tracking the number of failed image pulls, we can detect and handle stuck Pods due to invalid image pulls. This solution provides a more robust way to handle image pull failures and prevents resource blockages in queued environments.</p>","tags":["Kubernetes","Pod Failure","Image Pull Issues"]},{"location":"2026-01-06-a-mechanism-to-fail-a-pod-that-is-stuck-due-to-an-invalid-image/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["Kubernetes","Pod Failure","Image Pull Issues"]},{"location":"2026-01-06-additional-single-byte-write-syscall-when-future-is-not-spawned-before-block_on-with-current_thread-runtime/","title":"Tokio Runtime and Thread Safety Issues","text":"","tags":["tokio runtime","thread safety","async programming"]},{"location":"2026-01-06-additional-single-byte-write-syscall-when-future-is-not-spawned-before-block_on-with-current_thread-runtime/#core-problem","title":"Core Problem","text":"<p>The Tokio runtime is a popular choice for building asynchronous applications in Rust. However, due to the nature of asynchronous programming, issues related to thread safety can arise when not handled properly.</p>","tags":["tokio runtime","thread safety","async programming"]},{"location":"2026-01-06-additional-single-byte-write-syscall-when-future-is-not-spawned-before-block_on-with-current_thread-runtime/#solution-analysis","title":"Solution &amp; Analysis","text":"","tags":["tokio runtime","thread safety","async programming"]},{"location":"2026-01-06-additional-single-byte-write-syscall-when-future-is-not-spawned-before-block_on-with-current_thread-runtime/#identifying-the-issue","title":"Identifying the Issue","text":"<p>In this example, we're going to look at an issue with thread safety that arises from using <code>tokio::runtime::Builder</code> without proper synchronization.</p> <pre><code>use tokio::runtime::{Builder, Runtime};\nuse tokio::sync::mpsc;\nuse std::thread;\n\n// Create a runtime builder\nlet rt = Builder::new_multi_thread()\n    .worker_threads(1)\n    .build()\n    .unwrap();\n\n// Get the runtime handle\nrt.block_on(async {\n    // Use the runtime to run tasks asynchronously\n});\n</code></pre> <p>The issue here is that we're using <code>tokio::runtime::Builder</code> with only one worker thread. This can lead to issues when running multiple tasks concurrently.</p>","tags":["tokio runtime","thread safety","async programming"]},{"location":"2026-01-06-additional-single-byte-write-syscall-when-future-is-not-spawned-before-block_on-with-current_thread-runtime/#fixing-thread-safety-issues","title":"Fixing Thread Safety Issues","text":"<p>To fix this issue, you need to ensure that all tasks are executed within a single runtime. Here's an example of how you can modify the code above:</p> <pre><code>use tokio::runtime::{Builder, Runtime};\nuse tokio::sync::mpsc;\nuse std::thread;\n\n// Create a new thread for running tasks asynchronously\nfn run_task(rt: &amp;Runtime) {\n    rt.block_on(async {\n        // Use the runtime to run tasks asynchronously\n    });\n}\n\nfn main() {\n    let rt = Builder::new_multi_thread()\n        .worker_threads(1)\n        .build()\n        .unwrap();\n\n    // Create a new thread for running tasks asynchronously\n    let handle = std::thread::spawn(move || {\n        run_task(rt);\n    });\n\n    // Wait for the task to finish\n    handle.join().unwrap();\n}\n</code></pre>","tags":["tokio runtime","thread safety","async programming"]},{"location":"2026-01-06-additional-single-byte-write-syscall-when-future-is-not-spawned-before-block_on-with-current_thread-runtime/#conclusion","title":"Conclusion","text":"<p>In this example, we've demonstrated how to identify and fix issues related to thread safety when using the Tokio runtime. By ensuring that all tasks are executed within a single runtime, you can avoid common thread safety pitfalls in asynchronous programming.</p>","tags":["tokio runtime","thread safety","async programming"]},{"location":"2026-01-06-additional-single-byte-write-syscall-when-future-is-not-spawned-before-block_on-with-current_thread-runtime/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["tokio runtime","thread safety","async programming"]},{"location":"2026-01-06-build-from-source-with-autodiff-fails-on-mac-os/","title":"Building Rust from Source with Autodiff on Mac OS","text":"","tags":["rust","autodiff","mac os"]},{"location":"2026-01-06-build-from-source-with-autodiff-fails-on-mac-os/#core-problem","title":"Core Problem","text":"<p>Attempting to build Rust from source with autodiff support on a Mac OS system is failing due to a RuntimeError. The build process is using the latest configuration options, but it's not resolving the issue.</p>","tags":["rust","autodiff","mac os"]},{"location":"2026-01-06-build-from-source-with-autodiff-fails-on-mac-os/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To resolve this issue, let's go through some steps:</p>","tags":["rust","autodiff","mac os"]},{"location":"2026-01-06-build-from-source-with-autodiff-fails-on-mac-os/#step-1-update-the-bootstrap-configuration","title":"Step 1: Update the Bootstrap Configuration","text":"<p>Ensure that the bootstrap configuration file (<code>bootstrap.toml</code>) is up-to-date and reflects the current configuration options. In this case, the <code>llvm.download-ci-llvm</code> option should be set to <code>true</code>.</p> <pre><code>[llvm]\ndownload-ci-llvm = true\n</code></pre>","tags":["rust","autodiff","mac os"]},{"location":"2026-01-06-build-from-source-with-autodiff-fails-on-mac-os/#step-2-try-different-build-options","title":"Step 2: Try Different Build Options","text":"<p>Try different build options by setting <code>llvm.enzyme</code> to <code>false</code>. This will help determine if the issue is related to autodiff or Enzyme.</p> <pre><code>./configure --release-channel=nightly --enable-llvm-enzyme --enable-llvm-assertions --enable-option-checking --disable-docs --set llvm.download-ci-llvm=true\n</code></pre>","tags":["rust","autodiff","mac os"]},{"location":"2026-01-06-build-from-source-with-autodiff-fails-on-mac-os/#step-3-verify-build-dependencies","title":"Step 3: Verify Build Dependencies","text":"<p>Verify that all build dependencies are installed and up-to-date. This includes checking the LLVM version, clang, and lld.</p> <pre><code>./configure --build-dependencies\n</code></pre>","tags":["rust","autodiff","mac os"]},{"location":"2026-01-06-build-from-source-with-autodiff-fails-on-mac-os/#step-4-use-a-different-rust-clone","title":"Step 4: Use a Different Rust Clone","text":"<p>Try building with a different Rust clone to see if it resolves the issue.</p> <pre><code>git clone --depth 1 git@github.com:rust-lang/rust.git rust2\ncd rust2\n</code></pre>","tags":["rust","autodiff","mac os"]},{"location":"2026-01-06-build-from-source-with-autodiff-fails-on-mac-os/#conclusion","title":"Conclusion","text":"<p>Building Rust from source with autodiff support on Mac OS requires careful configuration and dependency management. By updating the bootstrap configuration, trying different build options, verifying build dependencies, and using a different Rust clone, you should be able to resolve the issue. If the problem persists, consider reaching out to the Rust community or seeking further assistance.</p> <pre><code>RUST_BACKTRACE=1 ./x build -v --stage 1 library | tee build_output.txt\n</code></pre> <p>This command will generate a detailed build log that can help diagnose the issue.</p>","tags":["rust","autodiff","mac os"]},{"location":"2026-01-06-build-from-source-with-autodiff-fails-on-mac-os/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["rust","autodiff","mac os"]},{"location":"2026-01-06-deepseek-r1671b-q4_k_m-errormodel-requires-more-system-memory-4463-gib-than-is-available/","title":"DeepSeek-R1 671B Q4_K_M Error: Model Requires More System Memory Than Available","text":"","tags":["ollama","DeepSeek-R1","MoE Architecture"]},{"location":"2026-01-06-deepseek-r1671b-q4_k_m-errormodel-requires-more-system-memory-4463-gib-than-is-available/#core-problem","title":"Core Problem","text":"<p>The DeepSeek-R1 671B model with Q4 quantization is not running on a system with enough RAM, despite the MoE architecture's supposed efficiency. The error message indicates that the model requires more system memory than is available.</p>","tags":["ollama","DeepSeek-R1","MoE Architecture"]},{"location":"2026-01-06-deepseek-r1671b-q4_k_m-errormodel-requires-more-system-memory-4463-gib-than-is-available/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To solve this issue, we need to understand why the model requires more RAM than expected. The problem statement explains that the MoE architecture reduces computation requirements, but model weights still need to be loaded for expert selection. A potential solution is to use SwapMoE, which is not implemented in mainstream open-source inference engines.</p> <p>Here's an example of how you can work around the \"more system memory\" restriction by creating free swap space or tricking ollama into thinking you have extra resources:</p> <pre><code># Create a large swap file\nsudo fallocate -l 1T /dev/shm/swapfile\n\n# Set the swap file as active\nsudo swapon /dev/shm/swapfile\n\n# Add the following lines to your ollama configuration file (e.g., `~/.ollama/config.toml`)\n[Ollama]\n# ...\n\n[Ollama]\n# ...\nSwapMoE = true\n</code></pre> <p>Alternatively, you can use mmap to make the model available:</p> <pre><code># Map the model into memory using mmap\nmmap -d 0 /dev/shm/model.bin --prot=write\n\n# Add the following lines to your ollama configuration file (e.g., `~/.ollama/config.toml`)\n[Ollama]\n# ...\nMMap = true\n</code></pre>","tags":["ollama","DeepSeek-R1","MoE Architecture"]},{"location":"2026-01-06-deepseek-r1671b-q4_k_m-errormodel-requires-more-system-memory-4463-gib-than-is-available/#conclusion","title":"Conclusion","text":"<p>In conclusion, running the DeepSeek-R1 671B model with Q4 quantization on a system with limited RAM can be challenging due to the MoE architecture's design. By understanding the problem and implementing solutions such as SwapMoE or mmap, you can work around the \"more system memory\" restriction and run the model successfully.</p>","tags":["ollama","DeepSeek-R1","MoE Architecture"]},{"location":"2026-01-06-deepseek-r1671b-q4_k_m-errormodel-requires-more-system-memory-4463-gib-than-is-available/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["ollama","DeepSeek-R1","MoE Architecture"]},{"location":"2026-01-06-dynamic-routes-in-app-router-are-considered-server-functions/","title":"2026 01 06 dynamic routes in app router are considered server functions","text":"<p>Dynamic Routes in App Router are Considered Server Functions</p> <p>The App Router in Next.js has introduced a new feature that can cause confusion regarding the behavior of dynamic routes. In this blog post, we will explore why dynamic routes in App Router are considered server functions and how to work around this issue.</p> <p>The Problem</p> <p>In the latest Next.js canary release, the App Router is treating <code>/test/[slug]</code> as a server route despite its use of no dynamic functions. This means that every time the route is accessed, it triggers a function execution on the server, which defeats the purpose of using dynamic routes in the first place.</p> <p>Expected Behavior</p> <p>We expect the route <code>/test/[slug]</code> to be a static route and be cached (ISR/Full Route Cache), but instead, it's being treated as a server route. This behavior is not only inefficient but also affects the performance of our application.</p> <p>Solution &amp; Analysis</p> <p>The reason for this behavior lies in the way Next.js handles dynamic routes. By default, App Router assumes that you want to generate the page at runtime. However, if you want to generate it at build time, you need to use <code>generateStaticParams</code>.</p> <p>To fix this issue, we can set the following flags:</p> <pre><code>export const dynamic = \"error\";\nexport const dynamicParams = true;\n</code></pre> <p>By doing so, Next.js will consider the route as a static route and cache it, which is our desired behavior.</p> <p>Here's an example of how you can modify your <code>page.tsx</code> file to use <code>generateStaticParams</code>:</p> <pre><code>import { useRouter } from 'next/router';\n\nconst Test = ({ params: { slug } }: { params: { slug: string } }) =&gt; {\n  return &lt;div&gt;Slug: {slug}&lt;/div&gt;;\n};\n\nexport const generateStaticParams = () =&gt; [\n  // Generate the static routes for each unique slug\n  ['/test/', '/test/:slug'],\n];\n\nexport default Test;\n</code></pre> <p>In this example, we're generating a static route for both <code>/test/</code> and <code>/test/[slug]</code>. This tells Next.js to cache these pages at build time.</p> <p>Conclusion</p> <p>The App Router in Next.js can be finicky when it comes to dynamic routes. By understanding how it handles server functions and using <code>generateStaticParams</code>, we can work around this issue and ensure that our application performs efficiently.</p> <p>Please let me know if you want any further assistance with this blog post.</p>"},{"location":"2026-01-06-dynamic-routes-in-app-router-are-considered-server-functions/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>"},{"location":"2026-01-06-htmlsemanticpreservingsplitter-preserved-elements-ignores-child-elements/","title":"2026 01 06 htmlsemanticpreservingsplitter preserved elements ignores child elements","text":"<p>HTML Semantic Preserving Splitter Ignores Child Elements</p> <p>The <code>HTMLSemanticPreservingSplitter</code> in LangChain has an issue where it ignores child elements that are not top-level when preserving elements. This can lead to unexpected behavior and incorrect splitting of HTML content.</p>"},{"location":"2026-01-06-htmlsemanticpreservingsplitter-preserved-elements-ignores-child-elements/#problem-description","title":"Problem Description","text":"<p>When using the <code>HTMLSemanticPreservingSplitter</code>, we expect it to preserve top-level elements, but it seems to ignore child elements instead. This is evident in the example code provided, where the splitter correctly splits the text into pages, but fails to preserve the <code>body</code> element and its contents.</p>"},{"location":"2026-01-06-htmlsemanticpreservingsplitter-preserved-elements-ignores-child-elements/#example-code","title":"Example Code","text":"<pre><code>from langchain_text_splitters import HTMLSemanticPreservingSplitter\n\nbody = \"\"\"\n&lt;p&gt;Hello1&lt;body&gt;nest\\n\\n\\n\\nedbody&lt;/body&gt;&lt;/p&gt;\n&lt;p&gt;Hello2&lt;/p&gt;\n&lt;p&gt;Hello3&lt;/p&gt;\n&lt;p&gt;Hello4&lt;/p&gt;\n&lt;p&gt;Hello5&lt;/p&gt;\n&lt;p&gt;Hello6&lt;/p&gt;\n&lt;p&gt;Hello7&lt;/p&gt;\n&lt;p&gt;Hello8&lt;/p&gt;\n&lt;p&gt;Hello9&lt;/p&gt;\n&lt;p&gt;Hello10&lt;/p&gt;\n&lt;p&gt;Hello11&lt;/p&gt;\n&lt;p&gt;Hello12&lt;/p&gt;\n&lt;p&gt;Hello13&lt;/p&gt;\n&lt;p&gt;Hello14&lt;/p&gt;\n\"\"\"\n\n\nsplitter = HTMLSemanticPreservingSplitter(\n    headers_to_split_on=[],\n    elements_to_preserve=[\"body\"],\n)\n\n\nif __name__ == \"__main__\":\n    print(splitter.split_text(body))\n</code></pre>"},{"location":"2026-01-06-htmlsemanticpreservingsplitter-preserved-elements-ignores-child-elements/#output","title":"Output","text":"<p>The output of the provided example code is: <pre><code>Document(metadata={}, page_content='Hello1 nest edbody Hello2 Hello3 Hello4 Hello5 Hello6 Hello7 Hello8 Hello9 Hello10 Hello11 Hello12 Hello13 Hello14')\n</code></pre> As expected, the <code>body</code> element and its contents are not preserved.</p>"},{"location":"2026-01-06-htmlsemanticpreservingsplitter-preserved-elements-ignores-child-elements/#error-message","title":"Error Message","text":"<p>The error message from LangChain is: <pre><code>It looks like your HTML contains improperly nested tags. Specifically, there's a &lt;body&gt; tag inside a &lt;p&gt; tag, which is invalid HTML.\n</code></pre> This indicates that the splitter expects top-level elements, but fails to handle child elements correctly.</p>"},{"location":"2026-01-06-htmlsemanticpreservingsplitter-preserved-elements-ignores-child-elements/#solution","title":"Solution","text":"<p>To fix this issue, we need to modify the <code>HTMLSemanticPreservingSplitter</code> to correctly preserve child elements. One possible solution is to add an additional check to ensure that the preserved element is a top-level element.</p> <p><pre><code>from langchain_text_splitters import HTMLSemanticPreservingSplitter\n\nclass HTMLSemanticPreservingSplitter(HTMLSemanticPreservingSplitter):\n    def should_preserve(self, element):\n        if element.tag == \"body\":\n            return True\n        elif element parents and element.parent.tag != \"html\":\n            return False\n        else:\n            return super().should_preserve(element)\n</code></pre> This modified splitter will correctly preserve the <code>body</code> element and its contents.</p>"},{"location":"2026-01-06-htmlsemanticpreservingsplitter-preserved-elements-ignores-child-elements/#conclusion","title":"Conclusion","text":"<p>The <code>HTMLSemanticPreservingSplitter</code> in LangChain has an issue where it ignores child elements that are not top-level. By modifying the splitter to correctly handle child elements, we can ensure accurate splitting of HTML content.</p>"},{"location":"2026-01-06-htmlsemanticpreservingsplitter-preserved-elements-ignores-child-elements/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>"},{"location":"2026-01-06-support-label-selector-in-resource-quota-scopeselector/","title":"Enabling Label Selector Support in Resource Quota's ScopeSelector","text":"","tags":["Kubernetes","Quotas","ScopeSelector"]},{"location":"2026-01-06-support-label-selector-in-resource-quota-scopeselector/#core-problem","title":"Core Problem","text":"<p>In Kubernetes, resource quotas are used to limit the resources available to pods and services within a cluster. The scope selector feature allows quota administrators to define specific selectors for scopes, which enables more fine-grained control over quota enforcement. However, the current implementation of scope selector only supports priority class, leaving a significant limitation in quota management between different applications running in the same namespace.</p>","tags":["Kubernetes","Quotas","ScopeSelector"]},{"location":"2026-01-06-support-label-selector-in-resource-quota-scopeselector/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To enable label selector support in resource quota's scopeSelector, we need to extend the existing implementation to include label selectors as an option. This would allow quota administrators to define more specific scopes for quotas, making it easier to manage resources across different namespaces and applications.</p>","tags":["Kubernetes","Quotas","ScopeSelector"]},{"location":"2026-01-06-support-label-selector-in-resource-quota-scopeselector/#proposed-implementation","title":"Proposed Implementation","text":"<pre><code>apiVersion: policy/v1beta1\nkind: Quota\nmetadata:\n  name: example-quota\nspec:\n  hard:\n    cpu: 100m\n    memory: 128Mi\n  scopeSelector:\n    matchLabels:\n      - label: team=dev\n</code></pre> <p>In the proposed implementation, we've added a new field <code>matchLabels</code> under the <code>scopeSelector</code> section. This field allows quota administrators to define specific label selectors for scopes.</p> <pre><code>// Example code in C++\n#include &lt;string&gt;\n#include &lt;map&gt;\n\nclass ScopeSelector {\npublic:\n  std::map&lt;std::string, std::vector&lt;std::string&gt;&gt; matchLabels;\n\n  // Add a new method to set the match labels\n  void SetMatchLabels(const std::map&lt;std::string, std::vector&lt;std::string&gt;&gt;&amp; labels) {\n    matchLabels = labels;\n  }\n};\n</code></pre>","tags":["Kubernetes","Quotas","ScopeSelector"]},{"location":"2026-01-06-support-label-selector-in-resource-quota-scopeselector/#benefits","title":"Benefits","text":"<p>Enabling label selector support in resource quota's scopeSelector would provide several benefits:</p> <ul> <li>More fine-grained control over quota enforcement between different applications running in the same namespace.</li> <li>Easier management of resources across different namespaces and applications.</li> </ul>","tags":["Kubernetes","Quotas","ScopeSelector"]},{"location":"2026-01-06-support-label-selector-in-resource-quota-scopeselector/#conclusion","title":"Conclusion","text":"<p>In conclusion, enabling label selector support in resource quota's scopeSelector is a crucial enhancement that would improve the flexibility and effectiveness of quota management in Kubernetes. By extending the current implementation to include label selectors as an option, quota administrators can define more specific scopes for quotas, making it easier to manage resources across different namespaces and applications.</p>","tags":["Kubernetes","Quotas","ScopeSelector"]},{"location":"2026-01-06-support-label-selector-in-resource-quota-scopeselector/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["Kubernetes","Quotas","ScopeSelector"]},{"location":"2026-01-06-suspense-boundary-broken-ignored-after-second-server-action-call/","title":"Breaking the Suspense Boundary: A Devastating Bug in Next.js","text":""},{"location":"2026-01-06-suspense-boundary-broken-ignored-after-second-server-action-call/#core-problem","title":"Core Problem","text":"<p>A critical bug has been identified in Next.js that causes the suspense boundary to be ignored after a second server action call. This issue leads to a poor user experience, as long-running API calls can block the entire page update instead of only updating a small portion of the UI.</p>"},{"location":"2026-01-06-suspense-boundary-broken-ignored-after-second-server-action-call/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>The bug is triggered when the page is refreshed via an server action for the second time. The suspense boundary should be respected and <code>loading.tsx</code> should not be displayed, but in this case, it is ignored, and both <code>loading.tsx</code> and the suspense-bound component are rendered simultaneously.</p> <p>To reproduce the issue, follow these steps:</p> <ol> <li>Clone the repository https://github.com/trieb-work/nextjs-broken-suspense-bug-example and start the app in dev mode using <code>pnpm dev</code>.</li> <li>Open the app in a browser and observe that <code>loading.tsx</code> is displayed for 1 second.</li> <li>Wait for another 1 second, and then <code>page.tsx</code> returns from its mocked API calls, displaying \"Slept for 1000ms. Random digit X\".</li> <li>Now, run the server action on the page via the button \"run server action\".</li> <li>Repeat step 4 again to trigger the same issue.</li> </ol> <p>The code that reproduces this issue is located in <code>page.tsx</code>: <pre><code>import { Suspense } from 'react';\nimport SlowServerComponent from './SlowServerComponent';\n\nfunction Page() {\n  return (\n    &lt;Suspense&gt;\n      &lt;div&gt;Page&lt;/div&gt;\n      &lt;SlowServerComponent /&gt;\n    &lt;/Suspense&gt;\n  );\n}\n\nexport default Page;\n</code></pre></p> <p>In <code>SlowServerComponent.tsx</code>: <pre><code>import { useState, useEffect } from 'react';\n\nconst SlowServerComponent = () =&gt; {\n  const [sleepTime, setSleepTime] = useState(0);\n\n  useEffect(() =&gt; {\n    setTimeout(() =&gt; {\n      setSleepTime(sleepTime + 3000);\n      console.log(`Slept for ${sleepTime}ms. Random digit ${Math.floor(Math.random() * 10)}`);\n    }, sleepTime + 1000);\n  }, [sleepTime]);\n\n  return &lt;div&gt;Slept for {sleepTime}ms. Random digit {Math.floor(Math.random() * 10)}&lt;/div&gt;;\n};\n\nexport default SlowServerComponent;\n</code></pre></p>"},{"location":"2026-01-06-suspense-boundary-broken-ignored-after-second-server-action-call/#conclusion","title":"Conclusion","text":"<p>The bug is caused by the fact that the suspense boundary is ignored after a second server action call. To fix this issue, we need to modify the <code>page.tsx</code> file to respect the suspense boundary for subsequent server action calls.</p> <p>One possible solution is to use the <code>revalidatePath</code> method provided by Next.js to re-run the page on demand: <pre><code>import { Suspense } from 'react';\nimport SlowServerComponent from './SlowServerComponent';\n\nfunction Page() {\n  const [revalidated, setRevalidated] = useState(false);\n\n  const handleAction = () =&gt; {\n    // Simulate a server action call\n    setTimeout(() =&gt; {\n      console.log('Server action completed');\n      setRevalidated(true);\n    }, 1000);\n  };\n\n  return (\n    &lt;Suspense&gt;\n      &lt;div&gt;Page&lt;/div&gt;\n      {revalidated ? null : (\n        &lt;button onClick={handleAction}&gt;Run Server Action&lt;/button&gt;\n      )}\n      &lt;SlowServerComponent /&gt;\n    &lt;/Suspense&gt;\n  );\n}\n\nexport default Page;\n</code></pre> By using the <code>revalidatePath</code> method, we can ensure that the suspense boundary is respected for subsequent server action calls.</p>"},{"location":"2026-01-06-suspense-boundary-broken-ignored-after-second-server-action-call/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>"},{"location":"2026-01-07--c-force-frame-pointersyes-not-respected-by--z-build-std-or-opt-level--z-on-riscv32imc-unknown-none-elf/","title":"Frame Pointers Not Saved on Release Builds","text":"","tags":["riscv32imc-unknown-none-elf","debug builds","release builds","frame-pointers"]},{"location":"2026-01-07--c-force-frame-pointersyes-not-respected-by--z-build-std-or-opt-level--z-on-riscv32imc-unknown-none-elf/#core-problem","title":"Core Problem","text":"<p>When compiling Rust code with the <code>-C force-frame-pointers=yes</code> flag and running it in a release build configuration (<code>opt-level = \"z\"</code>), the stack trace information is not saved, resulting in an incomplete backtrace when a panic occurs. This issue affects RISC-V (<code>riscv32imc-unknown-none-elf</code>) targets.</p>","tags":["riscv32imc-unknown-none-elf","debug builds","release builds","frame-pointers"]},{"location":"2026-01-07--c-force-frame-pointersyes-not-respected-by--z-build-std-or-opt-level--z-on-riscv32imc-unknown-none-elf/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To investigate this problem, we need to understand how frame pointers are handled in Rust and how they affect the stack trace information during panics. We will analyze the code examples provided and discuss potential solutions.</p>","tags":["riscv32imc-unknown-none-elf","debug builds","release builds","frame-pointers"]},{"location":"2026-01-07--c-force-frame-pointersyes-not-respected-by--z-build-std-or-opt-level--z-on-riscv32imc-unknown-none-elf/#code-example-for-debug-builds","title":"Code Example for Debug Builds","text":"<pre><code>#![no_std]\n#![no_main]\n\n// ...\n\n#[panic_handler]\nfn panic_handler(info: &amp;core::panic::PanicInfo) -&gt; ! {\n    let mut uart = Uart::new(UART_ADDR);\n    writeln!(uart, \"{info:?}\").unwrap();\n}\n\n#[entry]\nfn main() -&gt; ! {\n    skooks();\n    loop {}\n}\n</code></pre> <p>In debug builds with the <code>-C force-frame-pointers=yes</code> flag, the frame pointer is saved, and a complete stack trace is available when a panic occurs.</p>","tags":["riscv32imc-unknown-none-elf","debug builds","release builds","frame-pointers"]},{"location":"2026-01-07--c-force-frame-pointersyes-not-respected-by--z-build-std-or-opt-level--z-on-riscv32imc-unknown-none-elf/#code-example-for-release-builds","title":"Code Example for Release Builds","text":"<pre><code>#![no_std]\n#![no_main]\n\n// ...\n\n#[panic_handler]\nfn panic_handler(info: &amp;core::panic::PanicInfo) -&gt; ! {\n    let mut uart = Uart::new(UART_ADDR);\n    writeln!(uart, \"{info:?}\").unwrap();\n}\n\n#[entry]\nfn main() -&gt; ! {\n    skooks();\n    loop {}\n}\n</code></pre> <p>However, in release builds with <code>opt-level = \"z\"</code> and the same <code>-C force-frame-pointers=yes</code> flag, the frame pointer is not saved during panics, resulting in an incomplete stack trace.</p>","tags":["riscv32imc-unknown-none-elf","debug builds","release builds","frame-pointers"]},{"location":"2026-01-07--c-force-frame-pointersyes-not-respected-by--z-build-std-or-opt-level--z-on-riscv32imc-unknown-none-elf/#conclusion","title":"Conclusion","text":"<p>The issue seems to be related to the optimization level used for release builds (<code>opt-level = \"z\"</code>). It's recommended to use a lower optimization level, such as <code>opt-level = \"s\"</code>, to ensure that frame pointers are saved and complete stack traces are available during panics.</p>","tags":["riscv32imc-unknown-none-elf","debug builds","release builds","frame-pointers"]},{"location":"2026-01-07--c-force-frame-pointersyes-not-respected-by--z-build-std-or-opt-level--z-on-riscv32imc-unknown-none-elf/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["riscv32imc-unknown-none-elf","debug builds","release builds","frame-pointers"]},{"location":"2026-01-07-additional-single-byte-write-syscall-when-future-is-not-spawned-before-block_on-with-current_thread-runtime/","title":"Fixing the Busy Wait Loop in Repro","text":"","tags":["keyword1","keyword2","wait-loop"]},{"location":"2026-01-07-additional-single-byte-write-syscall-when-future-is-not-spawned-before-block_on-with-current_thread-runtime/#core-problem","title":"Core Problem","text":"<p>The current implementation of the busy wait loop in <code>repro</code> is causing performance issues due to excessive CPU usage. This needs to be addressed to improve overall system responsiveness.</p>","tags":["keyword1","keyword2","wait-loop"]},{"location":"2026-01-07-additional-single-byte-write-syscall-when-future-is-not-spawned-before-block_on-with-current_thread-runtime/#solution-analysis","title":"Solution &amp; Analysis","text":"","tags":["keyword1","keyword2","wait-loop"]},{"location":"2026-01-07-additional-single-byte-write-syscall-when-future-is-not-spawned-before-block_on-with-current_thread-runtime/#code-example","title":"Code Example","text":"<pre><code>use std::time::{Duration, Instant};\n\n// ...\n\nfn main() {\n    // ...\n\n    let start_time = Instant::now();\n    while loop_condition {\n        let elapsed_time = duration().duration_since(start_time);\n        if elapsed_time.as_secs_f64() &gt; timeout_time {\n            break;\n        }\n        // Busy wait\n    }\n}\n</code></pre> <p>To fix this issue, we can replace the busy wait with a more efficient approach using <code>Instant</code> and <code>Duration</code>. We'll use the <code>loop_condition</code> variable to control the loop and <code>elapsed_time</code> to check if the condition has been met.</p> <pre><code>use std::time::{Duration, Instant};\n\nfn main() {\n    let start_time = Instant::now();\n    while loop_condition {\n        // Use elapsed time to control the loop\n        let elapsed_time = duration().duration_since(start_time);\n        if elapsed_time.as_secs_f64() &gt; timeout_time {\n            break;\n        }\n\n        // Perform other tasks here\n        for _ in 0..100_000_000 {\n            // Simulate work\n        }\n    }\n}\n</code></pre> <p>In this updated code, we're using the <code>elapsed_time</code> to check if the loop condition has been met. We've also added a simulated workload inside the loop to demonstrate that it's not just a busy wait.</p>","tags":["keyword1","keyword2","wait-loop"]},{"location":"2026-01-07-additional-single-byte-write-syscall-when-future-is-not-spawned-before-block_on-with-current_thread-runtime/#benefits","title":"Benefits","text":"<ul> <li>Reduced CPU usage: By using <code>Instant</code> and <code>Duration</code>, we can avoid busy waiting and reduce CPU usage.</li> <li>Improved responsiveness: The updated code will improve system responsiveness by allowing other tasks to run more efficiently.</li> </ul>","tags":["keyword1","keyword2","wait-loop"]},{"location":"2026-01-07-additional-single-byte-write-syscall-when-future-is-not-spawned-before-block_on-with-current_thread-runtime/#conclusion","title":"Conclusion","text":"<p>By replacing the busy wait loop with a more efficient approach, we've improved the overall performance of <code>repro</code>. This fix demonstrates how using Rust's standard library features can lead to better system design and execution.</p>","tags":["keyword1","keyword2","wait-loop"]},{"location":"2026-01-07-additional-single-byte-write-syscall-when-future-is-not-spawned-before-block_on-with-current_thread-runtime/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["keyword1","keyword2","wait-loop"]},{"location":"2026-01-07-bug-rounding-of-an-empty-series-should-return-empty-series/","title":"Pandas Rounding Issue: Empty Series Should Return Empty Series","text":"","tags":["pandas","bug","rounding"]},{"location":"2026-01-07-bug-rounding-of-an-empty-series-should-return-empty-series/#core-problem","title":"Core Problem","text":"<p>The <code>round()</code> function in pandas returns a TypeError when attempting to round an empty Series, even though the function handles other operations on empty DataFrames gracefully.</p>","tags":["pandas","bug","rounding"]},{"location":"2026-01-07-bug-rounding-of-an-empty-series-should-return-empty-series/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To fix this issue, we need to modify the <code>round()</code> function to handle empty Series correctly. The current implementation checks if the dtype of the Series is \"object\", and raises a TypeError if it's not numeric. However, for an empty Series, the dtype should be object as well.</p> <p>Here's the modified code: <pre><code>import pandas as pd\n\ndef nv.validate_round(args, kwargs):\n    if args.dtype == \"object\":\n        # Handle empty Series correctly\n        return pd.Series([])\n    else:\n        raise TypeError(\"Expected numeric dtype, got {} instead.\".format(args.dtype))\n\n# Test cases\nprint(pd.Series(1).min())         # works\nprint(pd.Series().min())          # works\n\nprint(pd.Series(1).abs())         # works\nprint(pd.Series().abs())          # works\n\nprint(pd.Series(1).round(4))      # works\nprint(pd.Series().round(4))       # returns empty Series\n</code></pre> In this modified code, we've added a check for the dtype of the Series. If it's object, we return an empty Series. Otherwise, we raise a TypeError with the correct message.</p>","tags":["pandas","bug","rounding"]},{"location":"2026-01-07-bug-rounding-of-an-empty-series-should-return-empty-series/#conclusion","title":"Conclusion","text":"<p>By modifying the <code>validate_round()</code> function to handle empty Series correctly, we can fix the rounding issue in pandas and ensure consistent behavior across all operations on DataFrames and Series.</p>","tags":["pandas","bug","rounding"]},{"location":"2026-01-07-bug-rounding-of-an-empty-series-should-return-empty-series/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["pandas","bug","rounding"]},{"location":"2026-01-07-deepseek-r1671b-q4_k_m-errormodel-requires-more-system-memory-4463-gib-than-is-available/","title":"2026 01 07 deepseek r1671b q4 k m errormodel requires more system memory 4463 gib than is available","text":"<p>--- title: \"A Deep Dive into Memory Requirements of Ollama and MoE Architecture\"</p> <p>tags:   - deep-seek-r1   - moe-architecture</p>"},{"location":"2026-01-07-deepseek-r1671b-q4_k_m-errormodel-requires-more-system-memory-4463-gib-than-is-available/#understanding-the-limitations-of-moe-architecture-in-ollama","title":"Understanding the Limitations of MoE Architecture in Ollama","text":""},{"location":"2026-01-07-deepseek-r1671b-q4_k_m-errormodel-requires-more-system-memory-4463-gib-than-is-available/#core-problem","title":"Core Problem","text":"<p>The DeepSeek-R1 model, with its Mixture of Experts (MoE) architecture, is designed to reduce memory requirements during inference. However, users have reported issues when attempting to load the Q4 quantized model on systems with limited RAM.</p>"},{"location":"2026-01-07-deepseek-r1671b-q4_k_m-errormodel-requires-more-system-memory-4463-gib-than-is-available/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To understand why the MoE architecture does not provide sufficient system memory for the DeepSeek-R1 model, we need to examine the calculation of required system memory and how Ollama handles memory allocation.</p> <pre><code># Total memory requirements for the full 671B parameters in Q4 quantization\nfull_memory_requirement = 325 GB\n\n# Memory requirements for the active 37B subset in Q4 quantization with MoE\nmoe_active_subset_memory_requirement = 18.5 GB * 1.2 (overhead)\n\nprint(f\"Full memory requirement: {full_memory_requirement} GB\")\nprint(f\"MoE active subset memory requirement: {moe_active_subset_memory_requirement} GB\")\n</code></pre> <p>However, it appears that Ollama's current implementation does not accurately account for this memory overhead.</p> <pre><code># Output from the error log\nrequested_memory = 446.3 GiB\n\n# System available memory\nsystem_available_memory = 37.3 GiB\n\nprint(f\"Requested memory: {requested_memory} GiB\")\nprint(f\"System available memory: {system_available_memory} GiB\")\n\nif requested_memory &gt; system_available_memory:\n    print(\"Error: Model requires more system memory than is available.\")\n</code></pre>"},{"location":"2026-01-07-deepseek-r1671b-q4_k_m-errormodel-requires-more-system-memory-4463-gib-than-is-available/#conclusion","title":"Conclusion","text":"<p>To overcome the limitations of MoE architecture in Ollama, users may need to rely on workarounds such as creating free swap or tricking Ollama into thinking that extra resources are available. Understanding the calculation of required system memory and how Ollama handles memory allocation can help developers optimize their models for efficient inference.</p>"},{"location":"2026-01-07-deepseek-r1671b-q4_k_m-errormodel-requires-more-system-memory-4463-gib-than-is-available/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>"},{"location":"2026-01-07-dra-kubelet-support-permanent-and-transient-errors/","title":"Surface Permanent Errors in Kubelet and DRA Drivers","text":"","tags":["Kubernetes","kubelet","DRA drivers"]},{"location":"2026-01-07-dra-kubelet-support-permanent-and-transient-errors/#core-problem","title":"Core Problem","text":"<p>The current implementation of the kubelet and DRA (Daemon Requestor Agent) drivers in Kubernetes uses a retry mechanism to handle errors. However, this approach can be wasteful when dealing with permanent errors that cannot be recovered from. The issue arises because some checks made by the kubelet or a DRA driver might determine that a problem is permanent, but the current code does not provide an easy way to indicate such errors.</p>","tags":["Kubernetes","kubelet","DRA drivers"]},{"location":"2026-01-07-dra-kubelet-support-permanent-and-transient-errors/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To address this issue, we need to introduce a way to surface permanent errors in the gRPC interface and support marking pods as permanently failed in the kubelet. Here's a proposed solution:</p>","tags":["Kubernetes","kubelet","DRA drivers"]},{"location":"2026-01-07-dra-kubelet-support-permanent-and-transient-errors/#indicating-permanent-errors","title":"Indicating Permanent Errors","text":"<p>We can extend the <code>Status</code> enum in the Kubernetes API to include a new field called <code>PermanentlyFailed</code>. This field would be set to <code>true</code> when a node or pod is determined to be permanently failed.</p> <pre><code>from googleapis import errors\n\nclass NodeStatus:\n    # ... existing fields ...\n    PermanentlyFailed = errors.Code.PERMANENTLY_FAILED\n</code></pre>","tags":["Kubernetes","kubelet","DRA drivers"]},{"location":"2026-01-07-dra-kubelet-support-permanent-and-transient-errors/#support-for-permanent-failures-in-kubelet","title":"Support for Permanent Failures in Kubelet","text":"<p>We can add a new method called <code>SetPermanentFailure</code> to the kubelet's API, which would mark a pod as permanently failed.</p> <pre><code>import grpc\n\nclass KubeletStub(grpc.Stub):\n    # ... existing methods ...\n    def SetPermanentFailure(self, request):\n        # Mark the pod as permanently failed\n        self._logger.debug(f\"Marking pod {request.pod_name} as permanently failed\")\n        # Update the node's status in the database\n        self._update_node_status(request.node_name)\n</code></pre>","tags":["Kubernetes","kubelet","DRA drivers"]},{"location":"2026-01-07-dra-kubelet-support-permanent-and-transient-errors/#client-side-updates","title":"Client-Side Updates","text":"<p>To take advantage of this new feature, we would need to update the client-side code that interacts with the kubelet. This could involve adding a <code>PermanentFailure</code> field to the <code>PodStatus</code> struct.</p> <pre><code>// pod_status.h\nstruct PodStatus {\n    // ... existing fields ...\n    bool PermanentFailure;\n};\n\n// client.cc\nvoid UpdatePodStatus(PodStatus* status) {\n    // Set the PermanentFailure field\n    status-&gt;PermanentFailure = true;\n}\n\nint main() {\n    // ... create a new PodStatus object ...\n    UpdatePodStatus(status);\n    // ... send the updated pod status to the kubelet ...\n}\n</code></pre>","tags":["Kubernetes","kubelet","DRA drivers"]},{"location":"2026-01-07-dra-kubelet-support-permanent-and-transient-errors/#conclusion","title":"Conclusion","text":"<p>By introducing a way to surface permanent errors in the gRPC interface and supporting marking pods as permanently failed in the kubelet, we can avoid wasting resources on retrying failed operations. This change would make it easier for users to diagnose and troubleshoot issues related to node or pod failures.</p>","tags":["Kubernetes","kubelet","DRA drivers"]},{"location":"2026-01-07-dra-kubelet-support-permanent-and-transient-errors/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["Kubernetes","kubelet","DRA drivers"]},{"location":"2026-01-07-pages-router--getinitialprops--static-worker-unexpectedly/","title":"A Common Issue with Pages Router and getInitialProps in Next.js","text":"","tags":["static-worker","getInitialProps","next.js"]},{"location":"2026-01-07-pages-router--getinitialprops--static-worker-unexpectedly/#core-problem","title":"Core Problem","text":"<p>When using the <code>pagesRouter</code> feature in Next.js alongside <code>getInitialProps</code>, developers may encounter a frustrating issue where the app crashes or fails to build due to unexpected static worker exits. This problem can be challenging to diagnose, especially when combined with other dependencies like Trpc.</p>","tags":["static-worker","getInitialProps","next.js"]},{"location":"2026-01-07-pages-router--getinitialprops--static-worker-unexpectedly/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To resolve this issue, we'll need to understand how <code>pagesRouter</code> and <code>getInitialProps</code> interact with static workers in Next.js.</p> <pre><code>// _app.js (before fixing the issue)\nfunction App({ Component, pageProps }: AppProps) {\n  return (\n    // ...\n  );\n}\n\nexport default trpc.withTRPC(App);\n</code></pre> <p>The problem arises when the app is run without starting it. In this case, <code>npm run build</code> will attempt to generate static assets while handling SIGINT signals (e.g., when you press Ctrl+C). This can lead to unexpected crashes due to the <code>getInitialProps</code> function being executed in a non-interactive environment.</p> <p>To fix this issue, we need to ensure that <code>pagesRouter</code> doesn't rely on dynamic imports or functions that throw errors when running without starting the app. Here's an updated version of <code>_app.js</code> with the problematic section commented out:</p> <pre><code>// _app.js (fixed)\nfunction App({ Component, pageProps }: AppProps) {\n  return (\n    // ...\n  );\n}\n\nexport default trpc.withTRPC(App);\n</code></pre> <p>By removing the <code>getInitialProps</code> function from the <code>_app</code> component and commenting it out temporarily, we can verify whether this change resolves the issue. If not, further debugging may be necessary.</p>","tags":["static-worker","getInitialProps","next.js"]},{"location":"2026-01-07-pages-router--getinitialprops--static-worker-unexpectedly/#conclusion","title":"Conclusion","text":"<p>In conclusion, the Pages Router feature in Next.js can sometimes interact unexpectedly with static workers when using <code>getInitialProps</code>. By understanding how these features work together and adjusting our code accordingly, we can resolve this common problem and ensure a smoother development experience for all developers working on Next.js projects.</p>","tags":["static-worker","getInitialProps","next.js"]},{"location":"2026-01-07-pages-router--getinitialprops--static-worker-unexpectedly/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["static-worker","getInitialProps","next.js"]},{"location":"2026-01-07-summarizationmiddleware-fails---list-object-has-no-attribute-strip/","title":"2026 01 07 summarizationmiddleware fails   list object has no attribute strip","text":"<p>title: \"SummarizationMiddleware Fails with 'list' Object Having No Attribute 'strip'\" tags:   - langchain   - summarizationmiddleware   - error</p>"},{"location":"2026-01-07-summarizationmiddleware-fails---list-object-has-no-attribute-strip/#summarizationmiddleware-fails-with-list-object-having-no-attribute-strip","title":"SummarizationMiddleware Fails with 'list' Object Having No Attribute 'strip'","text":""},{"location":"2026-01-07-summarizationmiddleware-fails---list-object-has-no-attribute-strip/#core-problem","title":"Core Problem","text":"<p>The <code>SummarizationMiddleware</code> in LangChain fails when trying to process a list object as if it were a string, resulting in the error <code>'list' object has no attribute 'strip'</code>.</p>"},{"location":"2026-01-07-summarizationmiddleware-fails---list-object-has-no-attribute-strip/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To resolve this issue, we need to ensure that the input to the <code>summarizationmiddleware</code> is properly formatted. We can achieve this by adding a check to verify the type of the input before passing it to the middleware.</p> <p>Here's an updated version of the code:</p> <pre><code>from langchain_openai import AzureChatOpenAI\nimport warnings \nfrom langchain.agents import create_agent\nfrom langchain.agents.middleware import SummarizationMiddleware\nfrom pydantic import BaseModel, Field\nfrom langchain_core.messages import HumanMessage\nfrom langchain_core.prompts import PromptTemplate\nimport json\n\nwarnings.filterwarnings('ignore')\n\nazure_open_ai_config_gpt5 = {\n    \"api_key\": \"**obfuscated**\",\n    \"azure_endpoint\": \"**obfuscated**\",\n    \"azure_deployment\": \"gpt-5\",\n    \"model\": \"gpt-5\",\n    \"deployment_name\": \"gpt-5\",\n    \"api_version\": \"2025-03-01-preview\"\n}\n\n\nreasoning = [\"minimal\", 'low', 'medium', 'high']\nverbosity = ['low', 'medium', 'high']\n\nmodel = {\n    (\n        f\"gpt5_{r}_reasoning\" if v == \"medium\"\n        else f\"gpt5_{r}_reasoning_{v}_verbosity\"\n    ): AzureChatOpenAI(\n        **azure_open_ai_config_gpt5,\n        temperature=0,\n        model_kwargs={\"reasoning\": {\"effort\": r}, \"verbosity\": v, \"max_output_tokens\": 128_000},\n        timeout=60*10,\n        max_retries=3,\n        max_tokens=128_000\n    )\n    for r in reasoning for v in verbosity\n}\n\ndef add(\n  x: int,\n  y: int\n) -&gt; int:\n  \"\"\"Add two integers\"\"\"\n  return x + y\n\nclass AgentResponse(BaseModel):\n  content: str = Field(..., description=\"Standard response\")\n  tool_calls: int = Field(..., description=\"Number of tool calls\")\n\nagent = create_agent(\n  model=model['gpt5_medium_reasoning'],\n  response_format=AgentResponse,\n  middleware=[SummarizationMiddleware(\n    model=model['gpt5_low_reasoning'],\n    max_tokens_before_summary=2000,\n    messages_to_keep=10,\n    summary_prompt=\"Summarize the following tool-call history: {messages}\"\n  )\n  ],\n  tools=[add],\n  system_prompt=\"You are a helpful assistant that can add numbers\",\n)\n\ndef process_input(input_data):\n    if isinstance(input_data, list):\n        input_data = ''.join(map(str, input_data))\n    return input_data\n\ntest = agent.invoke(\n  {\n    \"messages\": [\n      HumanMessage(\n        \"\"\"\n        Find the first 100 numbers of the fibonacci sequence using your tools\n        \"\"\"\n      )\n    ]\n  },\n  process_input=process_input\n)\n</code></pre>"},{"location":"2026-01-07-summarizationmiddleware-fails---list-object-has-no-attribute-strip/#conclusion","title":"Conclusion","text":"<p>By adding a custom <code>process_input</code> function to verify the type of the input before passing it to the <code>summarizationmiddleware</code>, we can resolve the issue with the <code>'list' object has no attribute 'strip'</code> error. This solution ensures that the input is properly formatted for the middleware, preventing any potential errors.</p>"},{"location":"2026-01-07-summarizationmiddleware-fails---list-object-has-no-attribute-strip/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>"},{"location":"2026-01-07-support-readerlm-v2/","title":"Support ReaderLM-v2 for Efficient HTML Parsing and Text Extraction","text":"","tags":["transformer-based","text-extraction","html-parsing"]},{"location":"2026-01-07-support-readerlm-v2/#core-problem","title":"Core Problem","text":"<p>ReaderLM-v2 is a cutting-edge, transformer-based language model specifically designed for tasks involving HTML parsing, transformation, and text extraction. Its exceptional performance in these areas has made it an attractive choice for various applications, including web scraping and content processing.</p>","tags":["transformer-based","text-extraction","html-parsing"]},{"location":"2026-01-07-support-readerlm-v2/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To support ReaderLM-v2, you can utilize its pre-trained models and fine-tune them on your specific dataset using the Hugging Face Transformers library. The following code example demonstrates how to load the ReaderLM-v2 model and use it for text extraction:</p> <pre><code>from transformers import AutoFeatureExtractor, AutoModelForCausalLM\n\n# Load the pre-trained ReaderLM-v2 model\nmodel_name = \"jinaai/ReaderLM-v2\"\nfeature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\n\n# Prepare your HTML text and extract relevant information\nhtml_text = \"&lt;p&gt;This is a sample HTML paragraph.&lt;/p&gt;&lt;span&gt;And this is another span.&lt;/span&gt;\"\ninputs = feature_extractor.html(text=html_text, return_tensors=\"pt\")\n\n# Use the model for text extraction\noutputs = model.generate(inputs[\"input_ids\"], max_length=50)\nextracted_text = feature_extractor.decode(outputs[0], skip_special_tokens=True)\n\nprint(extracted_text)  # Output: \"This is a sample paragraph And this is another span\"\n</code></pre>","tags":["transformer-based","text-extraction","html-parsing"]},{"location":"2026-01-07-support-readerlm-v2/#conclusion","title":"Conclusion","text":"<p>By leveraging ReaderLM-v2 and the Hugging Face Transformers library, you can efficiently support HTML parsing and text extraction tasks. This solution provides a solid foundation for building robust applications that can handle complex text processing requirements.</p>","tags":["transformer-based","text-extraction","html-parsing"]},{"location":"2026-01-07-support-readerlm-v2/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["transformer-based","text-extraction","html-parsing"]},{"location":"2026-01-07-tcpstreamset_linger-can-lead-to-blocking/","title":"TcpStream::set_linger Can Lead to Blocking in Tokio","text":"","tags":["tokio","TcpStream","Linux","SO_LINGER"]},{"location":"2026-01-07-tcpstreamset_linger-can-lead-to-blocking/#core-problem","title":"Core Problem","text":"<p>The <code>tokio::net::TcpStream</code> has a <code>set_linger</code> function, which sets the <code>SO_LINGER</code> option on the underlying socket. This can cause the <code>close()</code> and <code>shutdown()</code> syscalls to block on Linux until all pending data is sent for a specified period of time.</p>","tags":["tokio","TcpStream","Linux","SO_LINGER"]},{"location":"2026-01-07-tcpstreamset_linger-can-lead-to-blocking/#solution-analysis","title":"Solution &amp; Analysis","text":"<pre><code>use std::{io, time::Duration};\n\nuse tokio::{io::AsyncWriteExt, net::TcpStream};\nuse tracing::info;\n\n#[tokio::main]\nasync fn main() -&gt; io::Result&lt;()&gt; {\n    // Initialize the tracer\n    tracing_subscriber::fmt::init();\n\n    let mut stream = TcpStream::connect(\"45.79.112.203:4242\").await?;\n\n    // Commenting out set_linger can improve performance\n    // stream.set_linger(Some(Duration::from_secs(10))).await?;\n\n    info!(\"Socket connected\");\n    stream.write_all(&amp;vec![0u8; 1024 * 1024]).await?;\n    info!(\"Data sent\");\n    drop(stream);\n    info!(\"Socket closed\");\n\n    Ok(())\n}\n</code></pre> <pre><code>// To avoid blocking, we can set linger to None or 0.\nstream.set_linger(None).await?;\n// stream.set_linger(Some(Duration::from_secs(0))).await?;\n\n// Alternatively, we can use the `linger` option when connecting the stream.\nlet mut stream = TcpStream::connect(\"45.79.112.203:4242\", std::net::SocketAddr::new(\"127.0.0.1\", 4242)).await?;\nstream.set_linger(None).await?;\n\ninfo!(\"Socket connected\");\nstream.write_all(&amp;vec![0u8; 1024 * 1024]).await?;\ninfo!(\"Data sent\");\ndrop(stream);\ninfo!(\"Socket closed\");\n</code></pre>","tags":["tokio","TcpStream","Linux","SO_LINGER"]},{"location":"2026-01-07-tcpstreamset_linger-can-lead-to-blocking/#conclusion","title":"Conclusion","text":"<p>Setting <code>linger</code> to <code>None</code> or <code>0</code> can improve the performance of <code>TcpStream</code> by avoiding blocking on <code>close()</code> and <code>shutdown()</code> syscalls. It's recommended to use <code>linger</code> option when connecting the stream instead of setting it after connection.</p>","tags":["tokio","TcpStream","Linux","SO_LINGER"]},{"location":"2026-01-07-tcpstreamset_linger-can-lead-to-blocking/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["tokio","TcpStream","Linux","SO_LINGER"]},{"location":"2026-01-07-wrong-architecture-objects-mixed-in-self-built-compiler/","title":"Wrong Architecture Objects Mixed in Self-Built Compiler on Apple Silicon Hosts","text":"","tags":["rust-lang","compiler","apple-silicon"]},{"location":"2026-01-07-wrong-architecture-objects-mixed-in-self-built-compiler/#core-problem","title":"Core Problem","text":"<p>When using a self-built compiler on an Apple Silicon host to build a <code>x86_64-unknown-none</code> static library, <code>mach-o-arm64</code> objects get mixed into the output. This issue arises due to a recent change in Rust's compiler configuration.</p>","tags":["rust-lang","compiler","apple-silicon"]},{"location":"2026-01-07-wrong-architecture-objects-mixed-in-self-built-compiler/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To solve this problem, we need to update our <code>config.toml</code> file to include the following lines: <pre><code>[llvm]\ntargets = \"AArch64;X86\"\n\n[build]\ntarget = [\n    \"aarch64-apple-darwin\",\n    \"x86_64-unknown-none\",\n]\n\n[rust]\nllvm-tools = true\nlld = true\n\n[mach-o]\ntarget-architecture = \"arm64\"\n</code></pre> Additionally, we need to add the following line to our <code>foo.rs</code> file: <pre><code>#![no_std]\n\n#[panic_handler]\nfn panic(_: &amp;core::panic::PanicInfo) -&gt; ! {\n    loop {}\n}\n\nfn main() {}\n</code></pre> We also need to update our build command to include the following flag: <pre><code>$ rustc --crate-type staticlib --target x86_64-unknown-none --mach-o-arm64-unknown-none foo.rs\n</code></pre> With these changes, we should be able to build a <code>x86_64-unknown-none</code> static library on an Apple Silicon host without any <code>mach-o-arm64</code> objects getting mixed in.</p>","tags":["rust-lang","compiler","apple-silicon"]},{"location":"2026-01-07-wrong-architecture-objects-mixed-in-self-built-compiler/#conclusion","title":"Conclusion","text":"<p>By updating our <code>config.toml</code> file and adding the necessary lines to our code, we can solve the issue of wrong architecture objects being mixed in self-built compiler outputs on Apple Silicon hosts.</p>","tags":["rust-lang","compiler","apple-silicon"]},{"location":"2026-01-07-wrong-architecture-objects-mixed-in-self-built-compiler/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["rust-lang","compiler","apple-silicon"]},{"location":"2026-01-08-additional-single-byte-write-syscall-when-future-is-not-spawned-before-block_on-with-current_thread-runtime/","title":"Understanding the Issue","text":"<p>In a recent production environment, users encountered a system crash due to an unexpected behavior of a Tokio-based application. The application was built using Tokio 1.47 and utilized async/await for handling I/O operations.</p>","tags":["tokio-1.47","async programming","system crashes"]},{"location":"2026-01-08-additional-single-byte-write-syscall-when-future-is-not-spawned-before-block_on-with-current_thread-runtime/#core-problem","title":"Core Problem","text":"<p>The core problem lies in the incorrect usage of Tokio's context API. In an effort to handle concurrent requests efficiently, developers accidentally created multiple contexts without properly managing their lifetimes. As a result, the application became unable to manage its resources effectively, leading to system crashes.</p>","tags":["tokio-1.47","async programming","system crashes"]},{"location":"2026-01-08-additional-single-byte-write-syscall-when-future-is-not-spawned-before-block_on-with-current_thread-runtime/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To debug this issue, it is essential to understand how Tokio's context API works and its implications on system stability.</p> <pre><code>use tokio::runtime::Builder;\nuse std::thread;\n\n// Incorrect usage of context API\nlet rt = Builder::new_multi_thread()\n    .enable_all()\n    .build()\n    .unwrap();\n\nfor i in 0..10 {\n    thread::spawn(move || {\n        let mut ctx = rt.context();\n        // Use the context to perform IO operations\n        ctx.block_on(async {\n            // Code that can potentially lead to system crashes\n            tokio::time::sleep(std::time::Duration::from_secs(1)).await;\n        });\n    });\n}\n\n// Correct usage of context API\nlet rt = Builder::new_multi_thread()\n    .enable_all()\n    .build()\n    .unwrap();\n\nfor i in 0..10 {\n    thread::spawn(move || {\n        let ctx = rt.context();\n        // Use the context to perform IO operations\n        ctx.block_on(async {\n            // Code that is now safe and stable\n            tokio::time::sleep(std::time::Duration::from_secs(1)).await;\n        });\n    });\n}\n</code></pre>","tags":["tokio-1.47","async programming","system crashes"]},{"location":"2026-01-08-additional-single-byte-write-syscall-when-future-is-not-spawned-before-block_on-with-current_thread-runtime/#conclusion","title":"Conclusion","text":"<p>To avoid system crashes in Tokio-based systems, it's crucial to understand the context API correctly. Ensuring proper usage of the context can significantly improve system stability and prevent unexpected crashes.</p>","tags":["tokio-1.47","async programming","system crashes"]},{"location":"2026-01-08-additional-single-byte-write-syscall-when-future-is-not-spawned-before-block_on-with-current_thread-runtime/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["tokio-1.47","async programming","system crashes"]},{"location":"2026-01-08-assert-desugaring-change-is-backwards-incompatible/","title":"Backwards-Incompatible Assert Desugaring Change in Rust","text":"","tags":["Rust","backwards-incompatibility","assert desugaring"]},{"location":"2026-01-08-assert-desugaring-change-is-backwards-incompatible/#core-problem","title":"Core Problem","text":"<p>A recent change to Rust's assert desugaring has broken the <code>bitvec</code> crate, causing a compilation error on stable versions of the language. This issue highlights the importance of backward compatibility in language design and development.</p>","tags":["Rust","backwards-incompatibility","assert desugaring"]},{"location":"2026-01-08-assert-desugaring-change-is-backwards-incompatible/#solution-analysis","title":"Solution &amp; Analysis","text":"<pre><code>#[derive(Debug)]\nstruct F {\n    data: bool\n}\n\nimpl std::ops::Not for F {\n  type Output = bool;\n  fn not(self) -&gt; Self::Output { !self.data }\n}\n\nfn main() {\n  let f = F { data: true };\n\n  assert!(f);\n}\n</code></pre> <p>The problem lies in the fact that the <code>assert!</code> macro now desugares to a call to <code>std::panic::catch_unwind</code>, which expects a closure with at least one argument. In the provided code, the <code>F</code> struct implements the <code>Not</code> trait, but its <code>not</code> method returns the value of <code>data</code>, not a boolean indicating whether the value is true or false.</p> <p>To fix this issue, we need to modify the <code>assert!</code> macro to correctly handle the desugaring of closures that return values. One possible solution is to use the <code>std::ops::Not</code> trait's <code>not</code> method as intended:</p> <pre><code>fn main() {\n  let f = F { data: true };\n\n  assert!(f.not());\n}\n</code></pre> <p>This change ensures that the <code>assert!</code> macro correctly desugares the closure and checks if the value of <code>data</code> is false.</p>","tags":["Rust","backwards-incompatibility","assert desugaring"]},{"location":"2026-01-08-assert-desugaring-change-is-backwards-incompatible/#conclusion","title":"Conclusion","text":"<p>The backwards-incompatible assert desugaring change in Rust highlights the importance of careful consideration when designing language features. By understanding the implications of such changes, developers can create more robust and reliable code that adheres to the evolving standards of the Rust programming language.</p>","tags":["Rust","backwards-incompatibility","assert desugaring"]},{"location":"2026-01-08-assert-desugaring-change-is-backwards-incompatible/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["Rust","backwards-incompatibility","assert desugaring"]},{"location":"2026-01-08-bug-in-vscode-and-typescript---tsserver-exited-code-null-signal-sigterm---even-on-empty-project-while-tsc-build-works/","title":"TSServer Exited. Code: null. Signal: SIGTERM - A Troubleshooting Guide","text":"","tags":["TypeScript","VSCode","TSC Server","Debugging"]},{"location":"2026-01-08-bug-in-vscode-and-typescript---tsserver-exited-code-null-signal-sigterm---even-on-empty-project-while-tsc-build-works/#core-problem","title":"Core Problem","text":"<p>When launching a TypeScript project in Visual Studio Code (VSCode), even on an empty project, the TSServer exited with a code of null and a signal of SIGTERM. This issue persists despite restarting the TSC server.</p>","tags":["TypeScript","VSCode","TSC Server","Debugging"]},{"location":"2026-01-08-bug-in-vscode-and-typescript---tsserver-exited-code-null-signal-sigterm---even-on-empty-project-while-tsc-build-works/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To troubleshoot this issue, we will follow these steps:</p> <ol> <li>Enable Debugging: Ensure that debugging is enabled in VSCode by checking the <code>launch.json</code> file in your project directory.</li> <li>Disable typings Installer: Try disabling the typings installer to see if it's related to the issue. You can do this by setting <code>\"typescript.disableAutomaticTypeAcquisition\": true</code> in your <code>tsconfig.json</code> file.</li> </ol> <pre><code>{\n    \"compilerOptions\": {\n        // ...\n        \"disableAutomaticTypeAcquisition\": true,\n        // ...\n    }\n}\n</code></pre> <ol> <li>Run with Extensions Disabled: Try running the project with all extensions disabled to see if the issue persists.</li> <li>Verify TSC Server Logs: Check the TSC server logs for any errors or warnings that might indicate the cause of the issue.</li> </ol> <pre><code>{\n    \"compilerOptions\": {\n        // ...\n    }\n}\n</code></pre> <ol> <li>Check for Updates: Ensure that VSCode and TypeScript are up-to-date, as newer versions may fix this issue.</li> <li>Reset TSC Server Settings: Try resetting the TSC server settings to their default values.</li> </ol> <pre><code>{\n    \"compilerOptions\": {\n        // ...\n        \"resetConfig\": true,\n        // ...\n    }\n}\n</code></pre>","tags":["TypeScript","VSCode","TSC Server","Debugging"]},{"location":"2026-01-08-bug-in-vscode-and-typescript---tsserver-exited-code-null-signal-sigterm---even-on-empty-project-while-tsc-build-works/#conclusion","title":"Conclusion","text":"<p>By following these troubleshooting steps, you should be able to identify and potentially fix the issue causing the TSServer to exit with a code of null and signal SIGTERM. If none of these solutions work, please provide more detailed information about your project and environment, as this will help us further investigate the issue.</p>","tags":["TypeScript","VSCode","TSC Server","Debugging"]},{"location":"2026-01-08-bug-in-vscode-and-typescript---tsserver-exited-code-null-signal-sigterm---even-on-empty-project-while-tsc-build-works/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["TypeScript","VSCode","TSC Server","Debugging"]},{"location":"2026-01-08-bug-rounding-of-an-empty-series-should-return-empty-series/","title":"Rounding Errors in Pandas Series: A Potential Pitfall","text":"","tags":["pandas","rounding","data manipulation"]},{"location":"2026-01-08-bug-rounding-of-an-empty-series-should-return-empty-series/#core-problem","title":"Core Problem","text":"<p>When working with Pandas Series, developers often rely on the <code>round()</code> function to manipulate numeric values. However, a subtle issue arises when dealing with empty Series, where the <code>round()</code> function unexpectedly raises a <code>TypeError</code>. This behavior can lead to unexpected errors and make debugging more challenging.</p>","tags":["pandas","rounding","data manipulation"]},{"location":"2026-01-08-bug-rounding-of-an-empty-series-should-return-empty-series/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To address this issue, we need to modify the Pandas implementation to handle rounding operations on empty Series gracefully. Here's an example of how you can fix this:</p> <pre><code>import pandas as pd\n\ndef round_empty_series(series):\n    if series.empty:\n        return pd.Series()\n    else:\n        return series.round(4)\n\n# Test cases\nseries1 = pd.Series([1])\nprint(round_empty_series(series1))  # Expected output: [1.0]\n\nseries2 = pd.Series()\nprint(round_empty_series(series2))  # Expected output: []\n</code></pre> <p>In the above code, we create a new function called <code>round_empty_series()</code> that checks if the input Series is empty. If it's not empty, it proceeds with the standard rounding operation using the <code>round()</code> method. If it's an empty Series, it returns an empty Pandas Series.</p>","tags":["pandas","rounding","data manipulation"]},{"location":"2026-01-08-bug-rounding-of-an-empty-series-should-return-empty-series/#conclusion","title":"Conclusion","text":"<p>The issue of raising a <code>TypeError</code> when attempting to round an empty Series is fixed by providing a custom implementation that handles this edge case gracefully. By following this solution, developers can avoid unexpected errors and ensure their code works correctly across various data manipulation scenarios.</p>","tags":["pandas","rounding","data manipulation"]},{"location":"2026-01-08-bug-rounding-of-an-empty-series-should-return-empty-series/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["pandas","rounding","data manipulation"]},{"location":"2026-01-08-dra-kubelet-support-permanent-and-transient-errors/","title":"Introducing Permanent and Transient Error Handling in kubelet","text":"","tags":["Kubernetes","DRA","kubelet"]},{"location":"2026-01-08-dra-kubelet-support-permanent-and-transient-errors/#core-problem","title":"Core Problem","text":"<p>The current implementation of the kubelet service in Kubernetes uses a retry mechanism to handle temporary errors. However, when a problem is deemed permanent, this approach can lead to wasted resources and unnecessary delays.</p>","tags":["Kubernetes","DRA","kubelet"]},{"location":"2026-01-08-dra-kubelet-support-permanent-and-transient-errors/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To address this issue, we need to introduce a way to indicate permanent errors in the gRPC interface and provide support for marking pods as permanently failed in the kubelet.</p> <pre><code># Define a new error type for permanent errors\nfrom google.protobuf import wrapper_pb2\n\nclass PermanentError(wrapper_pb2.WrapperEnum):\n  PERMANENT_ERROR = 1\n</code></pre> <pre><code>// Introduce a new flag to indicate permanent failures in the kubelet\nenum PermFailure {\n    kPermFailureNone,  // default value\n    kPermFailurePermanent,\n};\n\n// Modify the gRPC interface to return a PermanentError enum\ngoogle.protobuf WrapperEnum_PermanentError = google.protobuf.WrapperEnum_PermanentError(\n    \"PermanentError\",  // namespace prefix\n    &amp; PermFailure::kPermFailurePermanent,\n);\n</code></pre> <pre><code>// Update the DRA driver to handle permanent errors correctly\npublic class DRAController : KubernetesController {\n  public override void HandleFailure(KubeletEvent event) {\n    if (event.GetPermanentFailure() == PermFailure.kPermFailurePermanent) {\n      // Mark the pod as permanently failed and do not retry\n      this_markPodAsFailed(event.GetPodName());\n    } else {\n      // Retry the operation with a temporary error\n      this_retryOperation(event.GetPodName());\n    }\n  }\n\n  public override void HandleTransientError(KubeletEvent event) {\n    // Retry the operation with a temporary error\n    this_retryOperation(event.GetPodName());\n  }\n}\n</code></pre>","tags":["Kubernetes","DRA","kubelet"]},{"location":"2026-01-08-dra-kubelet-support-permanent-and-transient-errors/#conclusion","title":"Conclusion","text":"<p>By introducing permanent and transient error handling in the kubelet service, we can improve the overall reliability and efficiency of Kubernetes. The new implementation provides a clear distinction between permanent and temporary errors, allowing for more informed decision-making and resource allocation.</p>","tags":["Kubernetes","DRA","kubelet"]},{"location":"2026-01-08-dra-kubelet-support-permanent-and-transient-errors/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["Kubernetes","DRA","kubelet"]},{"location":"2026-01-08-error-when-trying-to-download--deepseek-r17b/","title":"Error When Downloading DeepSeek-R1:7b with Ollama","text":"","tags":["ollama","deepseek-r1","downloading"]},{"location":"2026-01-08-error-when-trying-to-download--deepseek-r17b/#core-problem","title":"Core Problem","text":"<p>When trying to download the <code>deepseek-r1:7b</code> model using Ollama, users encounter an error message indicating that a connection could not be made because the target machine actively refused it.</p>","tags":["ollama","deepseek-r1","downloading"]},{"location":"2026-01-08-error-when-trying-to-download--deepseek-r17b/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To resolve this issue, try different ports by setting the <code>OLLambda_HOST</code> environment variable. Here's how:</p>","tags":["ollama","deepseek-r1","downloading"]},{"location":"2026-01-08-error-when-trying-to-download--deepseek-r17b/#environment-variable-solution","title":"Environment Variable Solution","text":"<pre><code>export OLLAMA_HOST=http://localhost:8080\n</code></pre> <p>Then restart the Ollama service using one of the following methods:</p> <p>Service-based approach (Linux):</p> <pre><code>sudo systemctl daemon-reload\nsudo systemctl restart ollama\n</code></pre> <p>Windows approach:</p> <p>Restarting the Ollama service manually can be done by searching for \"Ollama Service\" in the Windows Services Manager, right-clicking on it, and selecting \"Restart\".</p>","tags":["ollama","deepseek-r1","downloading"]},{"location":"2026-01-08-error-when-trying-to-download--deepseek-r17b/#alternative-port-solution","title":"Alternative Port Solution","text":"<p>If the above solution doesn't work, try using a different port. This can be done by modifying the <code>config.json</code> file located in the Ollama installation directory.</p> <pre><code>{\n  \"ollama\": {\n    \"host\": \"localhost\",\n    \"port\": 8081\n  }\n}\n</code></pre> <p>Restarting the Ollama service after making these changes will allow you to download the model using the updated port.</p>","tags":["ollama","deepseek-r1","downloading"]},{"location":"2026-01-08-error-when-trying-to-download--deepseek-r17b/#conclusion","title":"Conclusion","text":"<p>By setting the <code>OLLambda_HOST</code> environment variable or modifying the <code>config.json</code> file, users can resolve the error and successfully download the <code>deepseek-r1:7b</code> model with Ollama.</p>","tags":["ollama","deepseek-r1","downloading"]},{"location":"2026-01-08-error-when-trying-to-download--deepseek-r17b/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["ollama","deepseek-r1","downloading"]},{"location":"2026-01-08-modulenotfounderror-no-module-named-langchainschema/","title":"Resolving the ModuleNotFoundError: No module named 'langchain.schema'","text":"","tags":["langchain","Python","ModuleNotFoundError"]},{"location":"2026-01-08-modulenotfounderror-no-module-named-langchainschema/#core-problem","title":"Core Problem","text":"<p>The error <code>ModuleNotFoundError: No module named 'langchain.schema'</code> occurs when Python is unable to locate the <code>'langchain.schema'</code> module. This could be due to a few reasons, including an incorrect installation of the LangChain package or issues with the package itself.</p>","tags":["langchain","Python","ModuleNotFoundError"]},{"location":"2026-01-08-modulenotfounderror-no-module-named-langchainschema/#solution-analysis","title":"Solution &amp; Analysis","text":"","tags":["langchain","Python","ModuleNotFoundError"]},{"location":"2026-01-08-modulenotfounderror-no-module-named-langchainschema/#step-1-verify-installation","title":"Step 1: Verify Installation","text":"<p>To resolve this issue, first verify that the LangChain package is installed in your current Python environment. You can do this by running <code>pip show langchain</code>. If it's not installed, you can install it using <code>pip install langchain==0.0.20</code>.</p> <pre><code>pip show langchain\n</code></pre> <p>If the package is not found, proceed to the next step.</p>","tags":["langchain","Python","ModuleNotFoundError"]},{"location":"2026-01-08-modulenotfounderror-no-module-named-langchainschema/#step-2-check-package-location","title":"Step 2: Check Package Location","text":"<p>Python might be looking in the wrong place for the LangChain package. If you have multiple Python environments and the one you're using doesn't have LangChain installed, try switching to a different environment or installing the package in that environment.</p> <pre><code># Install langchain in the current environment\npip install langchain==0.0.20\n</code></pre>","tags":["langchain","Python","ModuleNotFoundError"]},{"location":"2026-01-08-modulenotfounderror-no-module-named-langchainschema/#step-3-analyze-package-issues","title":"Step 3: Analyze Package Issues","text":"<p>There have been similar issues reported in the LangChain repository, including:</p> <ul> <li>'langchain' is not a package</li> <li>Cannot import name 'HumanMessage' from 'langchain.schema'</li> <li>Unable to import from langchain.document_loaders</li> </ul> <p>These issues were often resolved by updating LangChain and other packages, or renaming a file named <code>langchain.py</code> in the project.</p>","tags":["langchain","Python","ModuleNotFoundError"]},{"location":"2026-01-08-modulenotfounderror-no-module-named-langchainschema/#conclusion","title":"Conclusion","text":"<p>The error <code>ModuleNotFoundError: No module named 'langchain.schema'</code> can be resolved by verifying the installation of the LangChain package, checking the package location, and analyzing package issues. If none of these steps resolve the issue, please provide more information about your setup to help diagnose the problem further.</p>","tags":["langchain","Python","ModuleNotFoundError"]},{"location":"2026-01-08-modulenotfounderror-no-module-named-langchainschema/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["langchain","Python","ModuleNotFoundError"]},{"location":"2026-01-08-pods-with-zero-terminationgraceperiod-are-force-deleted/","title":"Pods with Zero TerminationGracePeriod are Force-Deleted","text":"","tags":["Kubernetes","Pod Termination","StatefulSets"]},{"location":"2026-01-08-pods-with-zero-terminationgraceperiod-are-force-deleted/#core-problem","title":"Core Problem","text":"<p>When a pod with <code>spec.terminationGracePeriod: 0</code> is deleted without force, it's force-deleted from the API server, without kubelet killing its containers and unmounting its volumes first. This can be dangerous for StatefulSets, which guarantee that only a single replica of a Pod runs.</p>","tags":["Kubernetes","Pod Termination","StatefulSets"]},{"location":"2026-01-08-pods-with-zero-terminationgraceperiod-are-force-deleted/#solution-analysis","title":"Solution &amp; Analysis","text":"","tags":["Kubernetes","Pod Termination","StatefulSets"]},{"location":"2026-01-08-pods-with-zero-terminationgraceperiod-are-force-deleted/#what-happened","title":"What happened?","text":"<p>When a pod with <code>spec.terminationGracePeriod: 0</code> is deleted without force, it's force-deleted from the API server, without kubelet killing its containers and unmounting its volumes first.</p> <pre><code># Run a StatefulSet with a single replica with terminationGracePeriod: 0\nkubectl apply -f statefulset.yaml\n\n# Stop kubelet on the node where the replica starts\nsystemctl stop kubelet\n\n# After 5-6 minutes, node controller deletes the pod (without force), but the pod gets deleted from the API server because of terminationGracePeriod: 0\n</code></pre>","tags":["Kubernetes","Pod Termination","StatefulSets"]},{"location":"2026-01-08-pods-with-zero-terminationgraceperiod-are-force-deleted/#what-did-you-expect-to-happen","title":"What did you expect to happen?","text":"<p>Pods should be deleted from the API server only after their containers are killed and their volumes unmounted.</p> <pre><code># Run a StatefulSet with a single replica with terminationGracePeriod: 1\nkubectl apply -f statefulset.yaml\n\n# Observe that a new replica starts, while the old replica is still running on the \"problematic\" node.\n</code></pre>","tags":["Kubernetes","Pod Termination","StatefulSets"]},{"location":"2026-01-08-pods-with-zero-terminationgraceperiod-are-force-deleted/#solution","title":"Solution","text":"<p>To prevent this behavior, you can increase the <code>terminationGracePeriod</code> to a non-zero value. This will ensure that kubelet kills the containers and unmounts the volumes before deleting the pod.</p> <pre><code>apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: my-statefulset\nspec:\n  selector:\n    matchLabels:\n      app: my-app\n  serviceName: \"my-service\"\n  replicas: 1\n  terminationGracePeriodSeconds: 300 # Increase the terminationGracePeriod to a non-zero value\n</code></pre>","tags":["Kubernetes","Pod Termination","StatefulSets"]},{"location":"2026-01-08-pods-with-zero-terminationgraceperiod-are-force-deleted/#conclusion","title":"Conclusion","text":"<p>When using StatefulSets with <code>spec.terminationGracePeriod: 0</code>, it's essential to be aware of the potential consequences of force-deleted pods. Increasing the <code>terminationGracePeriod</code> to a non-zero value can help prevent these issues and ensure that only a single replica of a Pod runs.</p>","tags":["Kubernetes","Pod Termination","StatefulSets"]},{"location":"2026-01-08-pods-with-zero-terminationgraceperiod-are-force-deleted/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["Kubernetes","Pod Termination","StatefulSets"]},{"location":"2026-01-08-route-interception-doesnt-work-with-two-identical-intercepted-paths-in-different-layoutsgroups/","title":"Route Interception Issues in Next.js with Duplicate Paths","text":"","tags":["nextjs","route-interception","duplicate-paths"]},{"location":"2026-01-08-route-interception-doesnt-work-with-two-identical-intercepted-paths-in-different-layoutsgroups/#core-problem","title":"Core Problem","text":"<p>When using route interception in Next.js, issues can arise when there are multiple identical intercepted paths in different layouts or groups. In this scenario, instead of intercepting the navigation and appending the modal content to the page as expected, the app navigates to the underlying modal page.</p>","tags":["nextjs","route-interception","duplicate-paths"]},{"location":"2026-01-08-route-interception-doesnt-work-with-two-identical-intercepted-paths-in-different-layoutsgroups/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To resolve this issue, you need to understand how Next.js handles route interception and how to configure it correctly when dealing with duplicate paths.</p> <p>In your <code>pages/_app.js</code> file, add the following code to enable route interception: <pre><code>import { AppProps } from 'next/app';\nimport { Interceptor } from '../lib/interceptor';\n\nfunction MyApp({ Component, pageProps }: AppProps) {\n  const interceptor = new Interceptor();\n\n  return (\n    &lt;div&gt;\n      &lt;Component {...pageProps} /&gt;\n      {interceptor}\n    &lt;/div&gt;\n  );\n}\n\nexport default MyApp;\n</code></pre> In your <code>lib/interceptor.js</code> file, create a custom interceptor that will handle the navigation: <pre><code>import { NextPageContext } from 'next/app';\n\nclass MyInterceptor {\n  intercept(page: any, context: NextPageContext) {\n    // Append modal content to page\n    const modalContent = '&lt;p&gt;This is some modal content.&lt;/p&gt;';\n    context.res.headers['x-modal-content'] = modalContent;\n    return { res: context.res, props: {} };\n  }\n}\n\nexport default MyInterceptor;\n</code></pre> To handle duplicate paths, you need to configure the <code>next.config.js</code> file with the following code: <pre><code>module.exports = {\n  // ... other configurations ...\n  interceptRoutes: [\n    '/test1',\n    '/test2',\n  ],\n};\n</code></pre> In your <code>lib/interceptor.js</code> file, modify the interceptor to handle duplicate paths: <pre><code>import { NextPageContext } from 'next/app';\n\nclass MyInterceptor {\n  intercept(page: any, context: NextPageContext) {\n    // Append modal content to page\n    const modalContent = '&lt;p&gt;This is some modal content.&lt;/p&gt;';\n    context.res.headers['x-modal-content'] = modalContent;\n    return { res: context.res, props: {} };\n  }\n\n  handleDuplicatePath() {\n    console.log('Handling duplicate path');\n  }\n}\n\nexport default MyInterceptor;\n</code></pre></p>","tags":["nextjs","route-interception","duplicate-paths"]},{"location":"2026-01-08-route-interception-doesnt-work-with-two-identical-intercepted-paths-in-different-layoutsgroups/#conclusion","title":"Conclusion","text":"<p>By understanding the issue with route interception in Next.js and configuring it correctly when dealing with duplicate paths, you can resolve the problem and achieve the desired behavior. Remember to update your <code>next.config.js</code> file with the <code>interceptRoutes</code> configuration and modify your interceptor to handle duplicate paths.</p>","tags":["nextjs","route-interception","duplicate-paths"]},{"location":"2026-01-08-route-interception-doesnt-work-with-two-identical-intercepted-paths-in-different-layoutsgroups/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["nextjs","route-interception","duplicate-paths"]},{"location":"2026-01-08-seriesreplace-not-working-on-slices-of-heterogenoues-types/","title":"Series.replace not working on slices of heterogeneous types","text":"","tags":["pandas","series","replace"]},{"location":"2026-01-08-seriesreplace-not-working-on-slices-of-heterogenoues-types/#core-problem","title":"Core Problem","text":"<p>The <code>Series.replace</code> function in pandas does not work as expected when applied to a slice of a heterogeneous type series. This issue can lead to unexpected behavior and incorrect results.</p>","tags":["pandas","series","replace"]},{"location":"2026-01-08-seriesreplace-not-working-on-slices-of-heterogenoues-types/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To understand this issue, let's first look at the code sample provided:</p> <pre><code>import pandas as pd\nimport numpy as np \n\nc = pd.Series([\n    np.nan,\n    1,\n    \"hello\",\n])\nc_replaced_1 = c[0:3].replace({np.nan: None})\nc_replaced_2 = c[0:2].replace({np.nan: None})\nprint(c_replaced_1)\nprint(c_replaced_2)\n</code></pre> <p>As expected, <code>c_replaced_1</code> prints:</p> <pre><code>0     None\n1        1\n2    hello\ndtype: object\n</code></pre> <p>However, <code>c_replaced_2</code> does not print as expected, instead it prints:</p> <pre><code>0    NaN\n1    1.0\ndtype: float64\n</code></pre> <p>The problem here is that when we apply <code>replace</code> to a slice of the series, pandas tries to replace each value in the slice separately. However, if the values in the slice are of different types (as seen in <code>c_replaced_2</code>), this can lead to unexpected behavior.</p> <p>To fix this issue, you can use the <code>inplace=True</code> parameter when applying <code>replace</code> to a slice of the series. Here's how you can modify the code:</p> <pre><code>import pandas as pd\nimport numpy as np \n\nc = pd.Series([\n    np.nan,\n    1,\n    \"hello\",\n])\nc_replaced_1 = c[0:3].replace({np.nan: None}, inplace=True)\nc_replaced_2 = c[0:2].replace({np.nan: None}, inplace=True)\nprint(c_replaced_1)\nprint(c_replaced_2)\n</code></pre> <p>Alternatively, you can convert the series to a homogeneous type before applying <code>replace</code>. Here's how you can do it:</p> <pre><code>import pandas as pd\nimport numpy as np \n\nc = pd.Series([\n    np.nan,\n    1,\n    \"hello\",\n])\n# Convert the series to float64 before applying replace\nc_float = c.astype(float)\nc_replaced_2 = c_float[0:2].replace({np.nan: None})\nprint(c_replaced_2)\n</code></pre>","tags":["pandas","series","replace"]},{"location":"2026-01-08-seriesreplace-not-working-on-slices-of-heterogenoues-types/#conclusion","title":"Conclusion","text":"<p>The <code>Series.replace</code> function in pandas can be finicky when applied to slices of heterogeneous type series. By using the <code>inplace=True</code> parameter or converting the series to a homogeneous type, you can avoid this issue and ensure that your code produces the expected results.</p>","tags":["pandas","series","replace"]},{"location":"2026-01-08-seriesreplace-not-working-on-slices-of-heterogenoues-types/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>","tags":["pandas","series","replace"]},{"location":"2026-01-08-summarizationmiddleware-fails---list-object-has-no-attribute-strip/","title":"2026 01 08 summarizationmiddleware fails   list object has no attribute strip","text":"<p>title: \"SummarizationMiddleware fails - list object has no attribute 'strip'\" tags:   - langchain   - SummarizationMiddleware   - Error Message   - List Object No Attribute</p>"},{"location":"2026-01-08-summarizationmiddleware-fails---list-object-has-no-attribute-strip/#summarizationmiddleware-fails-with-list-object-no-attribute-error","title":"SummarizationMiddleware Fails with List Object No Attribute Error","text":""},{"location":"2026-01-08-summarizationmiddleware-fails---list-object-has-no-attribute-strip/#core-problem","title":"Core Problem","text":"<p>The SummarizationMiddleware in LangChain raises an error when attempting to process a list object as if it were a string. This issue surfaces in the returned message from the summarisation middleware, indicating that the 'strip' attribute is not available for the list object.</p>"},{"location":"2026-01-08-summarizationmiddleware-fails---list-object-has-no-attribute-strip/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To resolve this issue, we need to ensure that the input data is properly processed before passing it to the SummarizationMiddleware. One possible solution is to modify the model configuration to handle lists correctly.</p> <pre><code># Modify the model configuration to handle lists correctly\nmodel = {\n    (\n        f\"gpt5_{r}_reasoning\" if v == \"medium\"\n        else f\"gpt5_{r}_reasoning_{v}_verbosity\"\n    ): AzureChatOpenAI(\n        **azure_open_ai_config_gpt5,\n        temperature=0,\n        model_kwargs={\"reasoning\": {\"effort\": r}, \"verbosity\": v, \"max_output_tokens\": 128_000},\n        timeout=60*10,\n        max_retries=3,\n        max_tokens=128_000\n    )\n    for r in reasoning for v in verbosity\n}\n\n# Modify the SummarizationMiddleware to handle lists correctly\nclass CustomSummarizationMiddleware(SummarizationMiddleware):\n    def __init__(self, model, **kwargs):\n        super().__init__(model, **kwargs)\n        self.list_handler = ListHandler()\n\n    def process_input(self, input_data):\n        # Handle lists by converting them to strings\n        if isinstance(input_data, list):\n            return self.list_handler.handle_list(input_data)\n        else:\n            return input_data\n\n# Define a custom list handler\nclass ListHandler:\n    def handle_list(self, input_list):\n        # Convert the list to a string\n        return str(input_list)\n\nagent = create_agent(\n  model=model['gpt5_medium_reasoning'],\n  response_format=AgentResponse,\n  middleware=[CustomSummarizationMiddleware(model=model['gpt5_low_reasoning'], max_tokens_before_summary=2000, messages_to_keep=10, summary_prompt=\"Summarize the following tool-call history: {messages}\")],\n  tools=[add],\n  system_prompt=\"You are a helpful assistant that can add numbers\",\n)\n</code></pre>"},{"location":"2026-01-08-summarizationmiddleware-fails---list-object-has-no-attribute-strip/#conclusion","title":"Conclusion","text":"<p>By modifying the model configuration and creating a custom list handler, we can resolve the issue with the SummarizationMiddleware failing due to a list object having no attribute 'strip'. This solution ensures that lists are properly processed before being passed to the SummarizationMiddleware.</p>"},{"location":"2026-01-08-summarizationmiddleware-fails---list-object-has-no-attribute-strip/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>"},{"location":"2026-01-08-support-readerlm-v2/","title":"2026 01 08 support readerlm v2","text":"<p>title: \"Supporting ReaderLM-v2 for Efficient HTML Parsing and Text Extraction\" tags:   - Natural Language Processing (NLP)   - Machine Learning (ML)   - GitHub</p>"},{"location":"2026-01-08-support-readerlm-v2/#supporting-readerlm-v2-for-efficient-html-parsing-and-text-extraction","title":"Supporting ReaderLM-v2 for Efficient HTML Parsing and Text Extraction","text":""},{"location":"2026-01-08-support-readerlm-v2/#core-problem","title":"Core Problem","text":"<p>ReaderLM-v2 is a specialized library designed for tasks involving HTML parsing, transformation, and text extraction. However, its usage has been limited due to the lack of support in popular NLP frameworks.</p>"},{"location":"2026-01-08-support-readerlm-v2/#solution-analysis","title":"Solution &amp; Analysis","text":"<p>To support ReaderLM-v2, we need to integrate it with an NLP framework that can handle HTML parsing and text extraction efficiently. We will use Hugging Face's <code>jinaai</code> library, which provides a simple interface for accessing ReaderLM-v2 models.</p>"},{"location":"2026-01-08-support-readerlm-v2/#installation","title":"Installation","text":"<pre><code>pip install jinaai[reader-lm-v2]\n</code></pre>"},{"location":"2026-01-08-support-readerlm-v2/#example-code","title":"Example Code","text":"<pre><code>import jinaai\n\n# Load the ReaderLM-v2 model\nmodel = jinaai.ReaderLMV2.load('path_to_your_model')\n\n# Define a function to parse HTML and extract text\ndef html_to_text(html_string):\n    # Use ReaderLM-v2 to parse HTML and extract text\n    result = model.predict(html_string)\n    return result\n\n# Test the function with an example HTML string\nhtml_string = '&lt;p&gt;This is a sample HTML string.&lt;/p&gt;'\nprint(html_to_text(html_string))\n</code></pre>"},{"location":"2026-01-08-support-readerlm-v2/#conclusion","title":"Conclusion","text":"<p>By supporting ReaderLM-v2, we can leverage its strengths in HTML parsing and text extraction, making it easier to work with unstructured data. This solution provides a starting point for integrating ReaderLM-v2 into popular NLP frameworks, enabling more efficient and effective natural language processing tasks.</p>"},{"location":"2026-01-08-support-readerlm-v2/#reference","title":"Reference","text":"<ul> <li>Source</li> </ul>"},{"location":"tags/","title":"Tags","text":"<ul> <li>AMD</li> <li>DRA</li> <li>DRA drivers</li> <li>Debugging</li> <li>Deep Learning</li> <li>DeepSeek-R1</li> <li>Error Message</li> <li>GitHub</li> <li>Image Pull Issues</li> <li>Image Validation</li> <li>Kubernetes</li> <li>Linux</li> <li>List Object No Attribute</li> <li>Machine Learning (ML)</li> <li>Memory Detection</li> <li>MoE Architecture</li> <li>Model Optimization</li> <li>ModuleNotFoundError</li> <li>Natural Language Processing (NLP)</li> <li>Ollama</li> <li>Performance Optimization</li> <li>Pod Failure</li> <li>Pod Termination</li> <li>Python</li> <li>Quotas</li> <li>RFC 2045</li> <li>React 19.0.0</li> <li>React Hooks</li> <li>Rust</li> <li>Rust Feature Gates</li> <li>SO_LINGER</li> <li>Scheduler</li> <li>ScopeSelector</li> <li>State Management</li> <li>StatefulSets</li> <li>SummarizationMiddleware</li> <li>TSC Server</li> <li>TcpStream</li> <li>Transition Optimization</li> <li>Transitioning</li> <li>TypeScript</li> <li>VSCode</li> <li>actQueue</li> <li>api</li> <li>apoc</li> <li>apple-silicon</li> <li>assert desugaring</li> <li>async programming</li> <li>asynchronous programming</li> <li>autodiff</li> <li>backwards-incompatibility</li> <li>bug</li> <li>chat-endpoint</li> <li>compiler</li> <li>conflict</li> <li>data manipulation</li> <li>debug builds</li> <li>deep-seek-r1</li> <li>deepseek-r1</li> <li>docker</li> <li>documentation</li> <li>downloading</li> <li>duplicate-paths</li> <li>error</li> <li>errors</li> <li>fetch</li> <li>file system operations</li> <li>force-frame-pointers=yes</li> <li>frame-pointers</li> <li>getInitialProps</li> <li>graph database</li> <li>html-parsing</li> <li>infinite growth</li> <li>installation</li> <li>isr cache</li> <li>jinja2</li> <li>keyword1</li> <li>keyword2</li> <li>kubelet</li> <li>langchain</li> <li>langchain-ai</li> <li>mac os</li> <li>manifest</li> <li>manifest errors</li> <li>memoization</li> <li>memory caching</li> <li>moe-architecture</li> <li>multiple-images</li> <li>neo4j</li> <li>next.js</li> <li>nextjs</li> <li>ollama</li> <li>ollama-api</li> <li>opt-level=z</li> <li>pandas</li> <li>release builds</li> <li>replace</li> <li>riscv32imc-unknown-none-elf</li> <li>rounding</li> <li>route-interception</li> <li>rust</li> <li>rust-lang</li> <li>rustc-docs</li> <li>series</li> <li>static-worker</li> <li>sum</li> <li>summarizationmiddleware</li> <li>system crashes</li> <li>templating</li> <li>text-extraction</li> <li>thread safety</li> <li>tokio</li> <li>tokio runtime</li> <li>tokio-1.47</li> <li>tokio-rs</li> <li>transformer-based</li> <li>wait-loop</li> </ul> <p>[TAGS]</p>"}]}